---+!! *&lt;noop&gt;%SPACEOUT{ &quot;%TOPIC%&quot; }%*



%RED%
WARNING! This page is for an older version of Hadoop.
For newer versions, please visit [[Documentation/Release3.InstallHadoopSE][Hadoop Release 3 Installation]]
%ENDCOLOR%


%DOC_STATUS_TABLE%
%TOC%


---+    Installation

This guide covers installation of the Globus-based Hadoop !GridFTP server using the RPM format.
The version of !GridFTP covered in this guide is compatible with Hadoop 0.20.2. 

%INCLUDE{&quot;Documentation/DocumentationTeam/DocConventions&quot; section=&quot;Header&quot;}%
%INCLUDE{&quot;Documentation/DocumentationTeam/DocConventions&quot; section=&quot;CommandLine&quot;}%

---++   Quick Start

Quickstart for the impatient.
This assumes you already have the *jdk* 1.6.0 RPM installed on all relevant nodes.

&lt;pre class=&quot;rootscreen&quot;&gt;
rpm -ivh http://vdt.cs.wisc.edu/hadoop/osg-hadoop-20-3.el5.noarch.rpm
yum install gridftp-hdfs
vi /etc/sysconfig/hadoop # Edit appropriately.
vi /etc/lcmaps/lcmaps.db # Edit GUMS hostname
service xinetd restart
&lt;/pre&gt;

---++ Prerequisites and Assumptions

To follow this guide, you must first:

   1. Read the [[HadoopUnderstanding][HDFS planning guide]]
   1. %STARTSECTION{&quot;HadoopReq&quot;}%Install the Hadoop RPM on your !GridFTP node, edit =/etc/sysconfig/hadoop=, and verify your installation%ENDSECTION{&quot;HadoopReq&quot;}% (see the [[Hadoop20Installation][installation guide]] for directions).
   1. %STARTSECTION{&quot;GumsReq&quot;}%We assume your site is running a sufficiently recent GUMS server &gt;= 1.3 (grid-mapfiles are not currently tested or supported).%ENDSECTION{&quot;GumsReq&quot;}%

To verify that HDFS core is installed and configured correctly on your system, the following command should return results and have exit code 0:

&lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% hadoop fs -ls /
&lt;/pre&gt;

*IF* the results of that command are the same files as those shown in =ls -l /=, then your site has not been configured; you probably forgot to run =hadoop-firstboot=.

%STARTSECTION{&quot;Prereqs&quot;}%

The !GridFTP server for Hadoop can be very memory-hungry, up to 500MB/transfer in the default configuration.
You should plan accordingly to provision enough !GridFTP servers to handle the bandwidth that your site can support.

The installation includes the latest CA Certificates package from the OSG as well as the fetch-crl CRL updater. *NOTE* the fetch-crl service does not start by default after installing !GridFTP.  To have fetch-crl update automatically, run:

&lt;pre class=&quot;rootscreen&quot;&gt;
%UCL_PROMPT_ROOT% service fetch-crl-cron start
&lt;/pre&gt;

cron will check for CRL updates every 6 hours.  If this is your first time installing you may need to run it immediately:

&lt;pre class=&quot;rootscreen&quot;&gt;
%UCL_PROMPT_ROOT% /usr/sbin/fetch-crl -r 20  -a 24 --quiet
&lt;/pre&gt;

*Note:* You do not need FUSE mounted on !GridFTP nodes,

%ENDSECTION{&quot;Prereqs&quot;}%

---++ Yum-based Installation Method
To configure your local installation for the yum repository, [[Hadoop20Installation#Installing_with_yum][follow the advice here]] to install the =osg-hadoop= package at your site.

After installing the osg-hadoop yum configuration package, you can install the gridftp-hdfs server with:

%STARTSECTION{&quot;Install&quot;}%

&lt;pre class=&quot;rootscreen&quot;&gt;
%UCL_PROMPT_ROOT% yum install gridftp-hdfs
&lt;/pre&gt;

Updates can be installed with:

&lt;pre class=&quot;rootscreen&quot;&gt;
%UCL_PROMPT_ROOT% yum upgrade gridftp-hdfs
&lt;/pre&gt;

%ENDSECTION{&quot;Install&quot;}%

Proceed to the Configuration section.

---+ Configuration

%STARTSECTION{&quot;Config&quot;}%

The installation of gridftp-hdfs and its dependencies creates several directories.
In addition to the Hadoop installation files, you will also find:

| Log files | =/var/log/gridftp-auth.log=, =/var/log/gridftp.log= |
| xinetd files | =/etc/xinetd.d/gridftp-hdfs= |
| runtime config files | =/etc/gridftp-hdfs/*= |
| System binaries | =/usr/bin/gridftp-hdfs*= |
| System libraries | =/usr/lib64/libglobus_gridftp_server_hdfs.so*= |
| GUMS client (called LCMAPS) configuration | =/etc/lcmaps/lcmaps.db= |
| CA certificates | =/etc/grid-security/certificates/*= |

=lcmaps.db= is provided by the globus-mapping-osg package.

gridftp-hdfs reads the Hadoop configuration file to learn how to talk to Hadoop.
As per the prerequisites section, you should have already edited =/etc/sysconfig/hadoop= and run =service hadoop-firstboot start=.
If you did not follow the directions, please do that now.

It is *not* necessary to start any Hadoop services with =service hadoop start= if you are running a dedicated !GridFTP server (that is, no datanode or namenode services will be run on the host).

In =/etc/lcmaps/lcmaps.db= you will need to enter the URL for your GUMS server, as well as the path to your host certificate and key:

&lt;pre class=&quot;file&quot;&gt;
             &quot;--endpoint https://%RED%gums.hostname%ENDCOLOR%:8443/gums/services/GUMSXACMLAuthorizationServicePort&quot;
&lt;/pre&gt;

The default settings in =/etc/gridftp-hdfs/*.conf= should be ok for most installations.
The file =gridftp-inetd.conf= is used by the xinetd service for starting up the !GridFTP server.
The file =gridftp.conf= is used by =/usr/bin/gridftp-hdfs-standalone= for starting up the !GridFTP server in a testing mode.
=gridftp-hdfs-local.conf= contains additional site-specific environment variables that are used by the gridftp-hdfs dsi module in both the xinetd and standalone !GridFTP server.
Some of the environment variables that can be used in =gridftp-hdfs-local.conf= include:

| Option Name | Needs Editing? | Suggested value|
| GRIDFTP_HDFS_REPLICA_MAP | No | File containing a list of paths and replica values for setting the default # of replicas for specific file paths |
| GRIDFTP_BUFFER_COUNT | No | The number of 1MB memory buffers used to reorder data streams before writing them to Hadoop |
| GRIDFTP_FILE_BUFFER_COUNT | No | The number of 1MB file-based buffers used to reorder data streams before writing them to Hadoop |
| GRIDFTP_SYSLOG | No | Set this to 1 in case if you want to send transfer activity data to syslog (only used for the HadoopViz application) |
| GRIDFTP_HDFS_MOUNT_POINT | Maybe | The location of the FUSE mount point used during the Hadoop installation.  Defaults to /mnt/hadoop.  This is needed so that gridftp-hdfs can convert fuse paths on the incoming URL to native Hadoop paths. *Note:* this does not imply you need FUSE mounted on !GridFTP nodes! |
| GRIDFTP_LOAD_LIMIT | No | !GridFTP will refuse to start new transfers if the load on the !GridFTP host is higher than this number; defaults to 20. |
| TMPDIR | Maybe | The temp directory where the file-based buffers are stored.  Defaults to /tmp. |

=gridftp-hdfs-local.conf= is also a good place to increase per-process resource limits. For example, many installations will require more than the default number of open files (=ulimit -n=).

%ENDSECTION{&quot;Config&quot;}%

---++ Running gridftp-hdfs

%STARTSECTION{&quot;Running&quot;}%

If you were not already running the xinetd service (by default it is not installed on RHEL5), then you will need to start it with the command:

&lt;pre class=&quot;rootscreen&quot;&gt;
%UCL_PROMPT_ROOT% service xinetd restart
&lt;/pre&gt;

Otherwise, the gridftp-hdfs service should be configured to run automatically as soon as the installation is finished.%ENDSECTION{&quot;Running&quot;}% %STARTSECTION{&quot;Standalone&quot;}% If you would like to test the gridftp-hdfs server in a debug standalone mode, you can run the command:

&lt;pre class=&quot;rootscreen&quot;&gt;
%UCL_PROMPT_ROOT% gridftp-hdfs-standalone
&lt;/pre&gt;

The standalone server runs on port 5002, handles a single !GridFTP request, and will log output to stdout/stderr.

%ENDSECTION{&quot;Standalone&quot;}%


---+ Next Steps
Congratulations! At this point, you should have a working Hadoop installation and !GridFTP server.
Please proceed to the validation steps or the next guide, [[Hadoop20SRM][Hadoop SRM install]].

&lt;!-- CONTENT MANAGEMENT PROJECT
############################################################################################################
   DEAR DOCUMENT OWNER
   ===================

   Thank you for claiming ownership for this document! Please fill in your FirstLast name here:
   * Local OWNER          = JeffDost

   Please define the document area, choose one of the defined areas from the next line
   DOC_AREA = (ComputeElement|General|Trash/Trash/Integration|Monitoring|Operations|Security|Storage|Trash/Tier3|User|VO)
   * Local DOC_AREA       =  Storage

   define the primary role the document serves, choose one of the defined roles from the next line
   DOC_ROLE = (Developer|Documenter|Scientist|Student|SysAdmin|VOManager)
   * Local DOC_ROLE       = SysAdmin

   Please define the document type, choose one of the defined types from the next line
   DOC_TYPE = (HowTo|Installation|Knowledge|Navigation|Planning|Training|Troubleshooting)
   * Local DOC_TYPE       = Installation
   
   Please define if this document in general needs to be reviewed before release ( %YES% | %NO% )
   * Local INCLUDE_REVIEW = %YES%

   Please define if this document in general needs to be tested before release ( %YES% | %NO% )
   * Local INCLUDE_TEST   = %YES%

   change to %YES% once the document is ready to be reviewed and back to %NO% if that is not the case
   * Local REVIEW_READY   = %NO%

   change to %YES% once the document is ready to be tested and back to %NO% if that is not the case
   * Local TEST_READY     = %NO%

   change to %YES% only if the document has passed the review and the test (if applicable) and is ready for release
   * Local RELEASE_READY  = %NO%


   DEAR DOCUMENT REVIEWER
   ======================

   Thank for reviewing this document! Please fill in your FirstLast name here:
   * Local REVIEWER       = 
  
   Please define the review status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local REVIEW_PASSED  = %IN_PROGRESS%


   DEAR DOCUMENT TESTER
   ====================

   Thank for testing this document! Please fill in your FirstLast name here:
   * Local TESTER         = 
  
   Please define the test status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local TEST_PASSED    = %IN_PROGRESS%
############################################################################################################
--&gt;
