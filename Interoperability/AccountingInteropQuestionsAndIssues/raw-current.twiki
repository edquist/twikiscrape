&lt;!--
   * Set SummaryRecords = [[https://wiki.egi.eu/wiki/APEL/MessageFormat#Summary_Job_Records][Summary Job Records]]
   * Set JobRecords = [[https://wiki.egi.eu/wiki/APEL/MessageFormat#Job_Records][individual Job Records]]
   * Set SummarySyncRecords =[[https://wiki.egi.eu/wiki/APEL/MessageFormat#Summary_Sync_Records][Summary Sync Records]]
--&gt;


---+ Accounting Systems Interoperability Questions And Issues
%TOC%
---++ Introduction
This is where all current questions and issues related to interoperability of the Accounting Systems should be listed.


---++ APEL SSM/ActiveMQ interface
Currently, the Gratia/APEL interface sends the selected Gratia data to WLCG by performing  a direct SQL DML update of a table (OSG_CN_DATA)  in the APEL accounting database.  This will be changing sometime in the future and will be using an SSM/ActiveMQ method to perform this.  There will no longer be any direct access to the APEL database.

This section provides some references/notes/questions on this new interface.

---+++ References
[[https://wiki.egi.eu/wiki/APEL/Server][APEL/Server]]:
This page references a record publisher component which, on the surface, sounds like the capability to retrieve data from APEL.  However, there is no further information about it.%BR%
%BLUE%Will there be the  capability to retrieve data from the APEL database via this new protocol?
%ENDCOLOR%%BR%
%GREEN%(Tanya 10/something) They claim that it is possible but not documented. We will need to increase pressure or a least ask them for examples. 
%ENDCOLOR%%BR%

[[https://wiki.egi.eu/wiki/APEL/SSMOverview][SSM Overview]]:
This messaging system will replace the current direct access SQL DML update/access to the APEL database table for OSG (OSG_CN_DATA).

[[https://wiki.egi.eu/wiki/APEL/SSMInstallation][SSM Installation]] - Questions related to the installation of the necessary software are documented in this [[#SSM_Installation][section]].

[[https://wiki.egi.eu/wiki/APEL/MessageFormat][APEL/SSM Message format]] - Questions related to the new messaging protocol are documented in this [[#APEL_SSM_message_format][section]]

[[https://wiki.egi.eu/wiki/APEL/APELSSMExternalTesting][SSM External Testing]] - Question related to testing are documented in this [[#SSM_External_Testing][section]].
 
[[http://activemq.apache.org/python.html][ActiveMQ]] - purely for reference are this time.

---+++ Release date
%BLUE%Is there a hard &quot;drop-dead&quot; date when the current direct access to the APEL accounting will no longer be supported?%ENDCOLOR%%BR%
%GREEN% (Will Rogers 11/11/11 - The 15th December is not a deadline for when we’ll be moving to the new system.  I’m not actually sure where the date came from.  I think we’ll do well to get the new system operational by then.  After it is operational there’ll be at least a couple of months for transition before we close the access to the DB that you’ve got at the moment.
%ENDCOLOR%

---+++ [[https://wiki.egi.eu/wiki/APEL/SSMInstallation][SSM Installation]]
This section contains some questions specific to this document.

__Prerequisites__  %BR%
* __certificates__ %BR%
 The documentation in the [[https://wiki.egi.eu/wiki/APEL/SSMInstallation#Certificates][Certificates section of SSM Installation page]] implies a host certificate should be used.%BR%
 %BLUE%Can a service certificate be used?%ENDCOLOR%%BR%
%GREEN%(Tanya) Yes, you have to send them DN %ENDCOLOR%%BR%
%GREEN%(John Weigand 11/28/11) We will be using a service cert:
%BR% -  gratia-osg-prod-reports.opensciencegrid.org-hostcert.pem
%ENDCOLOR%%BR%

 * __Stomp__ %BR%
This is the client software which communicates with Apache !ActiveMQ (the message broker).%BR%
%BLUE%Where can we find documentation on this package?%BR%
http://packages.python.org/stompy/introduction.html ? %ENDCOLOR%%BR%
%GREEN%(Will Rogers 11/11/11) - Stomppy – confusingly there is a stompy and a stomppy.  We’re using the latter.  Its page is here: http://code.google.com/p/stomppy/.
%ENDCOLOR%%BR%
%RED%(John Weigand 11/11/11) - Strange, I think the original doc said we could use stomp and I did with no problems.
Need to change test environment to use the pp one (stomppy).
%ENDCOLOR%%BR%

* __lcg-CA__ %BR%
We use the OSG CA certificates.%BR%
%BLUE%Will this suffice?%ENDCOLOR%%BR%
%GREEN% (Tanya) Should be ok %ENDCOLOR%%BR%
%GREEN%(John Weigand 11/28/11) This has been verified.%ENDCOLOR%%BR%
%RED%(John Weigand 11/28/11) Just note/reminder that when !DigiCerts become the CA, we will have to test.
%BR%
Also, we have not had to have certificates on the Gratia reporting node (gr13x0) where this has to run.  This will have to be added.
%BR%
%ENDCOLOR%

* __Installation__ %BR%
Have not got this far so no questions at this time%BR%
%GREEN%(John Weigand 11/29/11) Did make it this far but not sure how to comment on this.  Mostly manual with tarballs. 
Indications are there will be an RPM available but it is unclear when and whether or not it will be useful for us.
%ENDCOLOR%

__Configuration__ %BR%
The last bullet in this section implies that an acknowledgment is performed indicating the success/failure of the communication between the client and consumer.  This implies some level of synchronous communication.%BR%
%BLUE%Is this just at the message level or does this extend to the APEL database update the consumer is performing?%ENDCOLOR%%BR%
%GREEN%(Tanya) Only message level, database operation is completely separate process %ENDCOLOR%%BR%
%GREEN%(Will Rogers 11/14/11) Now, on to feedback from APEL to GRATIA…
As things stand, the new APEL server will give a limited amount of feedback to clients in terms of what information has been accepted. The plan is:
   * A page such as this one which summarises which sites have published what to the server in the past 24  hours:
      - http://goc-accounting.grid-support.ac.uk/apeltest
   * A similar page which lists messages which have been rejected by the SSM in the past 24 hours, and why 
%ENDCOLOR%
%RED%(John Weigand 11/14/11)
A couple things here:
   1 Are the column headings correct or is this a semantics problem I am having?
      * does &quot;newest&quot; mean the last month for which updates were sent/applied?
        That is, does this say the last file I sent up was for September? My logs indicate it should have been for &quot;October&quot;.
      * what does &quot;oldest record&quot; mean?
   1 Number of records?
      * is this the number of records in the last files sent? in the &quot;newest record&quot;? &quot;oldest record&quot;?
   1 Is this a database query? If so, maybe we can put something out there other than number of records. 
%ENDCOLOR%%BR%

__Certificates__ %BR%
This implies a host certificate should be used.  It would be easier to implement if a service certificate could be used as this would facilitate running from multiple hosts as needed.%BR%
%BLUE%Can a service certificate be used?%ENDCOLOR%%BR%
%GREEN%(Tanya) Yes%ENDCOLOR%%BR%
%BLUE%(John Weigand 11/2/11 - Requested service cert from Tanya.%ENDCOLOR%%BR%
%GREEN%(John Weigand 11/28/11) We are now using a service cert: %BR%
 - gratia-osg-prod-reports.opensciencegrid.org-hostcert.pem
%ENDCOLOR%

__Running the SSM__ / __Stopping the SSM__ %BR%
&lt;OL&gt;
&lt;LI&gt;Based on the description, this sounds like a daemon process that is periodically checking a messages directory for files.%BR%
%BLUE%Is there a plan to allow this to be run from init.d services?%ENDCOLOR%%BR%
%GREEN% Yes%ENDCOLOR%%BR%
%BLUE%(John Weigand 11/2/11) - We won&#39;t be running this as a daemon service.  We will be running in a &quot;once and done mode&quot;. 
So, item 2 below regarding having that type argument would be nice.   %ENDCOLOR%%BR%

&lt;LI&gt; __run-ssm__ script%BR%
a. Our mode of operation is to summarize the Gratia data once per day and send it up to APEL/EGI.  It is a cron scheduled job. Although the previous bullet implies it would be nice to have this as an init.d service, this is not the mode we desire.  We would like a &quot;once and done&quot; mode.
%BR%
%RED%(John Weigand 11/2/11) - Can there be a command line argument (or config file option) that allows the script to terminate when the message has been sent and an acknowledgment received?
%ENDCOLOR%%BR%
%GREEN%(Will Rogers 11/11/11) - It seems a reasonable request to allow a run-once configuration for the SSM.  It is just another task to do, though, so not sure how high priority it will be.
%ENDCOLOR%%BR%


b. Associated with this, a &quot;timeout&quot; option/arg would be useful so our interface script is not waiting forever when the transmission is unsuccessful.  This allows us to be aware of a problem (naturally checking for a non-zero return code) and take remedial action, if necessary.
%BR%
%RED%(John Weigand 11/2/11) - Can this also be provided?%ENDCOLOR%%BR%
%GREEN%(Will Rogers 11/11/11) - It seems a reasonable request to allow a run-once configuration for the SSM.  It is just another task to do, though, so not sure how high priority it will be.
%ENDCOLOR%%BR%

c. I noticed, while doing some troubleshooting on our end, that the main module looking for messages (__ssm_master.py__) is reading the messages/outgoing directory every 1 second.  This seems extremely frequent.  Our Gratia probes (which handle talking to Gratia) only check every 10 minutes for files.   If this is intended for cron execution and it will terminate in a &quot;once and done&quot; mode this is ok.  However, if a daemon process, this may consume resource unnecessarily.   The frequency could be a config option or command line argument.  This is just an observation as we won&#39;t be using it in this mode.
%BR%
%RED%(John Weigand 11/2/11) - Although this does not necessarily affect us because of our intended use, I think this could be a problem.%ENDCOLOR%%BR%
%GREEN%(Will Rogers 11/11/11) -The request for &quot;once and done&quot; applies to the frequency of checking the directory for new messages as well.
%ENDCOLOR%%BR%
%GREEN%(John Weigand 11/11/11) - Not really worried about this one since we will operate in &quot;once and done&quot; mode.
%ENDCOLOR%%BR%
&lt;/OL&gt;

%GREEN%(John Weigand 11/28/11) - 
I have modified the code with an SSMInterface class to address these issues from our standpoint.  A method in this class will:
   * start the run-ssm daemon in background
   * check every 10 seconds (hard coded) to see if the file is no longer in the ./messages/outgoing directory (this indicates it has been sent successfully&gt;
   * if gone, kills the run-ssm daemon
   * if not gone after 2 minutes (hard coded), terminates the run-ssm daemon and throws an exception.

This should allow us the control we need, at least as we understand it for the current environment.
%ENDCOLOR%%BR%



---+++ Direct DB Access vs Messaging
The approach taken with the current  interface was to keep it as simple as possible allowing for an easy means of correcting changing data in the OSG Gratia accounting system.  On a daily basis, the interface performs:
   * DELETE from OSG_CN_DATA where Month = mm and Year = yy %BR%
     (this removes all interfaced OSG resource group data for the month)
   * INSERT into OSG_CN_DATA (summarized data) where Month = mm and Year = yy. %BR%
     (for all interfaced OSG resource groups) 
   * commit %BR%
     (this is all one atomic transaction)

This approach could be used for the the following reasons:
   * The current Gratia/APEL interface is performed using a direct SQL DML update of the APEL accounting database. 
   * The required  granularity of the APEL/EGI data is monthly summaries by Site,  VO and DN. 
   * The OSG site&#39;s data is segregated from other EGI sites by being stored in an OSG specific table (OSG_CN_DATA).  

The new interface is a messaging based layer which no longer provides us direct access to our data.  It is our understanding that the messages will result  in a database table update (SQL DML REPLACE)  based on certain key fields.  Since we send summary data by site, vo and user DN, and not detail data, we will be sending 
[[https://wiki.egi.eu/wiki/APEL/MessageFormat#Summary_Job_Records][Summary Job Records]]. 

The problem, from the Gratia end of things, is that this now makes it extremely difficult to correct any changes made in Gratia to correct in the APEL/EGI database.  There are (and have been from the beginning) capabilities in Gratia to make corrections in the accounting data collected for things like site and vo.   Individual job records are collected by Gratia and recorded.  Those records themselves rarely change but how the data collected is reported in terms of site and vo  can be changed.  

A recent example of this (although it does not affect the VOs we are currently reporting) is this request (there is a similar correction table for sites).
&lt;blockquote&gt;
NEES users being mapped to Engage rather than engage.  In the !VONameCorrection table, the VOid is pointing to Engage (92) instead of engage (114).  Can you please change the VOid in the !VONameCorrection table to point to engage for the VOName:
/Engage/NEES/Role=NULL/Capability=NULL 
/Engage/UCSDGrid/Role=NULL/Capability=NULL 
&lt;/blockquote&gt;

The point of this is that when something like this is effected, the summary data we retrieve  reflects the current state.  If a site or vo were to change, we would have no means of knowing what it was yesterday and the data previously sent would still exist in APEL/EGI.   For us to insure the data in APEL/EGI is reflective of the current Gratia data, we would have to  perform some delta between the previous state and the current state and make adjustments accordingly.  This process would add unneeded complexity and be prone to error.

__Request__ : %BLUE%Can there be a message format that would allow for removing (as in our old DELETE) based on site and yr/mos?  This would simplify processing on our end immensely.  We recognize that we would still have to keep track of changes in site but that is something more manageable. %ENDCOLOR%%BR%
%GREEN%(Will Rogers 11/14/11 email) 
The current system means you have a lot of control over what data we hold from GRATIA, so if there’s a correction you can do it and we will reflect that change. The new system would mean that if (for example) a VO were to change its name, you’d have to submit a request to us and we’d have to correct it.
%ENDCOLOR%%BR%
%RED%(John Weigand 11/14/11 - in email reply)
It is not a VO name change specifically that I am concerned about (that would have to be handled procedurally).%BR%
I am concerned about this scenario....%BR%
Since we are reporting at the DN level (and potentially group/role), it is possible that an individual users VO is misidentified in Gratia.%BR%
- Today we send up an update for user(DN) for the cms VO.%BR%
- Tomorrow, we discover the error in Gratia and correct the VO associated with that user. It should have been atlas.%BR%
- So on tomorrow&#39;s update we send up a record for the same user(DN) for atlas VO.%BR%
- Since we are only &quot;replacing&quot; and we are not identifying deltas in our interface, we will have the same user(DN) in APEL under the cms VO and atlas VO when in fact all the usage for that user should have only been for the atlas VO.%BR%

This type of correction does not occur that often but is handled very simply in Gratia by updating a &quot;translation&quot; type table. The affect on the data we send to APEL is not so easy to identify which is why the delete/insert approach we originally took was the most practical. 
%ENDCOLOR%%BR%
%GREEN%(Will Rogers 11/14/11 - same email) 
Now, it’s clear that you’re not very keen on this idea. To put it into perspective, what we achieve with this is cleaning up a number of special cases whereby certain organizations have their own way of submitting to APEL. These are generally similar but subtly different, and we have a fair few inelegant scripts pulling it all together into the summary database. The discovery of two DB tables that neither you nor we knew about was symptomatic of these interfaces. The new system will have no such special cases, simplifying things for us greatly. So we consider the disadvantage in the paragraph above to be worth it.
It appears that your suggestion would be to have a delete-type message so you could correct your data yourself. There are of course consequences of this ability we’d have to think carefully about. 
%ENDCOLOR%%BR%
%RED%(John Weigand 11/14/11 - in same email reply)
Help me understand the consequences. It would surely be better that my current alternative of zeroing out the previous days records which, to me, has many more consequences. 
%ENDCOLOR%%BR%


The only option we see available, to achieve the same result, would be to create 2nd file/message  of %SummaryRecords% with the same set of &quot;keys&quot; with all time/job fields set to zero.  Then, for each update, we would send this 2nd file (from the previous run) up first.  Then we send the &quot;real&quot; updates for the current run.  

%BLUE%The question then is &quot;Will they be processed sequentially on the APEL end?&quot;.%ENDCOLOR%%BR%
%GREEN%(Will Rogers 11/11/11) Messages ARE applied sequentially, with the exception of duplicates.
%ENDCOLOR%%BR%
%RED%(John Weigand 11/11/11)
Subsequently, found out duplicates are identified as having the same hash value as another file.  This seems somewhat reasonable.
Even though it is possible for the same user set (site/vo/dn) will be sent up on subsequent days with zero values for the cpu/wall/jobs attributes, uniqueness will be achieved with the date of the !LatestEndTime attribute in the file.
%ENDCOLOR%%BR% 
%GREEN%(Will Rogers 11/14/11 same email) 
You’ve also experimented with over-writing records so that they contain zeroes. I can’t say for sure right now the effect this would have. The position on this from us has to be that we can’t offer you something new on this, partly because the request is only coming from you, but we’ll bear it in mind as a possible feature. It’s conceivable that other such users would find something like this useful.%ENDCOLOR%%BR%
%RED%(John Weigand 11/14/11 in same email reply) 
I would think this would depend on how many users are sending summary data up and whether or not they are sending deltas or &quot;replaces&quot;. Have any of those updating summary only started testing.
%ENDCOLOR%%BR%

%GREEN%(John Weigand 11/28/11) 
The LCG.py process has been modified to:%BR%
- For each execution, create a YYYY-MM-updates.txt file containing the summarized data for that month.  It will also create a YYYY-MM-deletes.txt file for the same set of &quot;keys&quot; with the cpu/wall/jobs attributes zeroed out.%BR%
 - So, each day, it will first attempt to send the YYYY-MM-deletes.txt from the previous day via SSM to APEL.%BR%
 - If not successful, it will terminate.  This insures we always &quot;zero&quot; out the last update made.%BR%
 - If successful, it will then create/send via SSM to APEL, the YYYY-MM-updates.txt for that day.%BR%
%ENDCOLOR%%BR%

---+++ [[https://wiki.egi.eu/wiki/APEL/MessageFormat][APEL SSM message format]]
Gratia will not be sending individual job records to APEL/EGI.  As today, Gratia will be sending summary data based on site, vo and user DN.   

Questions related to the %SummaryRecords%.
&lt;OL&gt;
    &lt;LI&gt; !WallDuration/CPUDuration%BR%
      Currently, the &quot;times&quot; sent up for these fields are in a time scale of hours.  The %JobRecords%  explicitly state these are to be in seconds. 
%BR%  
%GREEN%(Will Rogers 11/11/11) These will be in Hours.  The documentation now reflects this.
%ENDCOLOR%
%BR%


     &lt;LI&gt; !NormalisedWallDuration/!NormalisedCpuDuration%BR%
      Currently, Gratia is sending normalized data using a !SpecInt value.  The %JobRecords% provide for specifying a  !NormalizationFactorUnit. The %SummaryRecords% do not.     We can provide either but would prefer !HepSpec as that is what all new processors are evaluated with.  
%BR% 
%BLUE%Can we assume it is the !HepSpec value that is required? Can the document reflect this?%ENDCOLOR%
%BR% 
%GREEN%(Will Rogers 11/11/11) - Use !HepSpec06 NF factor.  The documentation now reflects this.
%ENDCOLOR%



     &lt;LI&gt;Group/Role%BR%
      In the %SummaryRecords%, there are 2 new fields that we have not been required to populate with the current interface: Group and Role.  We are assuming these are optional and at the discretion of the VOs which, in our case, are cms/atlas/alice.  The documentation indicates that if these are not &quot;published&quot;, they will set to &quot;None&quot; in the database. %BR%
%BLUE%Is there any problem if we always &quot;publish&quot; them with a string value of &quot;None&quot;?%ENDCOLOR%
%BR% 
%GREEN%(John Weigand - 11/2/11) -  Testing has shown this to be true.%ENDCOLOR%
&lt;/OL&gt;

Questions related to the %SummarySyncRecords%:&lt;OL&gt;
    &lt;LI&gt; %BLUE%Is this file/message also required?%ENDCOLOR%%BR%
    %GREEN%(Tanya) Don&#39;t know%ENDCOLOR%%BR%
   %RED%(John Weigand - 11/2/11) - Would be nice to know if we need to be concerned with this and, if so, what is it????%ENDCOLOR%%BR%
   %GREEN%(Will Rogers 11/11/11) - Sync records - these aren’t required if you’re just sending summaries to us.  I’ll update the wiki documentation to make this clearer.
%ENDCOLOR%%BR%
&lt;/OL&gt;


---+++ SSM External Testing
Link: [[https://wiki.egi.eu/wiki/APEL/APELSSMExternalTesting][SSM External Testing]]%BR%
We have subscribed to the mailing list but have gone no further as yet but do have some preliminary questions.
&lt;OL&gt;
  &lt;LI&gt;In the Usage section, the interface sounds like it is an asynchronous protocol. %BR%
        %BLUE%Are there plans for this to be synchronous in nature when it goes to production? (in terms of both the message and, more importantly, the database update)?%ENDCOLOR%%BR%
%GREEN%No, it will be completely asynchronous%ENDCOLOR%%BR%
%RED%(John Weigand 11/2/11) - This makes the ability to retrieve data from the EGI portal critical to verifying if the interface worked.%ENDCOLOR%%BR%


&lt;LI&gt;It appears the test environment is limited to just the messaging and database update.%BR%
%BLUE%Will there be an environment which tests the complete data flow inclusive of the EGI portal UI?%ENDCOLOR%%BR%
%RED%(John Weigand 11/2/11) - How then do we actually test?%ENDCOLOR%%BR%

&lt;/OL&gt;
 

---+++ Retrieval/Publishing of APEL/EGI data
Currently, after the daily update of APEL is performed, we do a retrieval of the data using a SQL select of the data for the following tables:
   * OSG_CN_DATA
   * org_Tier1
   * org_Tier2

This retrieval uses the SQL client capability to output the table data in html, dat and xml formats for access by other OSG applications.  This data is currently used in these OSG site pages:
   * [[http://red-web.unl.edu/gratia/wlcg_reporting#atlas][OSG WLCG Reporting]]
   * [[http://gratia-osg-prod-reports.opensciencegrid.org/gratia-data/interfaces/apel-lcg/][Gratia-APEL WLCG Interface]] (also accessible from the main [[http://gratia-osg-prod-reports.opensciencegrid.org/gratia-reporting][Gratia reporting page]] menu on the left side.)

---++++ Topology data (aka org_Tier1/2 tables)
It is our understanding that the org_Tier1/2 tables are being replaced by the [[http://wlcg-rebus.cern.ch/apps/topology/][WLCG REBUS Topology]].  This site has the capability to &quot;export&quot; the data is a csv format.  This will probably be adequate since the amount of data is relatively small.

There are still a couple questions relative to how this topology data is used. 
It is our understanding that for the data to be reflected in the Tier1/2 views a WLCG Site (OSG resource group) must be registered with LCG accounting and an MOU agreement in effect.
The site will then be populated in the WLCG Topology and only those Sites will have their data reflected in that view under the appropriate Country/Federation Name/Federation Accounting Name in the hierarchy.  Some of these questions have come up as the WLCG Topology does not appear to be time sensitive and Sites can come and go over time.
&lt;OL&gt;
&lt;LI&gt;If a site (OSG resource group) is being removed from service, we assume that site must remain in the topology or any historical data associated with its contribution toward the Federation Accounting Name will be lost.  We recently had this case with a site MWT2_IU being replaced by site MWT2.   We advised them __not__ to have the MWT2_IU removed.%BR%
%BLUE%Were we correct in this assumption?%ENDCOLOR%%BR%
%GREEN%(Tanya) No clue %ENDCOLOR%%BR%
%RED%(John Weigand 11/2/11) - It would be nice to get this answered so we understand how OSG sites should handle deprecated sites in &lt;nop&gt;MyOSG/OIM.  In the old interface, there did exists files/tables that masked some of this.%ENDCOLOR%%BR%

&lt;LI&gt;In the past (or maybe still), the org_Tier1/2 tables determined if a site was displayed in the EGI portal under the appropriate view/hierarchy.  There were also 1 or 2 other tables/configuration files (not viewable by us) that took care of this &quot;removal of a site&quot; from service but allowed the historical data to still be visible.  An example of this was a Purdue-Lear site back in 2008 and its data was still viewable by using these other tables/files.%BR%
%BLUE%Are any other tables/configuration files still being used or is the WLCG Topology the sole driver of the data?%ENDCOLOR%%BR%
%RED%(John Weigand 11/2/11) - It would be nice to get this answered so we understand how OSG sites should handle deprecated sites in &lt;nop&gt;MyOSG/OIM.  In the old interface, there did exists files/tables that masked some of this.%ENDCOLOR%%BR%

&lt;LI&gt;%BLUE%When a site is registered in LCG and an MOU agreement reached, should the data for past periods be sent up or does the date of the registration mark the start of the data requirement?%ENDCOLOR%%BR%
%GREEN%(Tanya) No clue %ENDCOLOR%%BR%
%RED%(John Weigand 11/2/11) - Need to know so we can establish the correct procedures.%ENDCOLOR%%BR%

&lt;LI&gt;While documenting all this and in viewing the data on the EGI portal, there appears to be no data prior to April 2009.  We have been sending data up since at least March 2008. %BR%
%BLUE%Is there an &quot;archival&quot; process in effect that we should be aware of?%ENDCOLOR%%BR%
%GREEN%(Tanya) No clue %ENDCOLOR%%BR%
%RED%(John Weigand 11/2/11) - Another &quot;good to know&quot; point.  It should be noted that both links at the bottom of the EGI Accounting Portal that seem to intend to describe this, don&#39;t work (for me anyway)%ENDCOLOR%%BR%
&lt;/OL&gt;
%GREEN%(Will Rogers 11/11/11) Topology data – we haven’t looked at this recently, so at least I am not sure of the status.  If you think this is urgent, give us another nudge and we’ll have a look.
%ENDCOLOR%%BR%
%RED%(John Weigand 11/11/11) Not urgent but we need to nudge them as we need to understand the procedures to follow.
%ENDCOLOR%%BR%

---++++ OSG site data (aka OSG_CN_DATA)
As mentioned in the  earlier, Gratia needs visibility to the APEL data we publish.  It has been mentioned that the EGI portal allows for the downloading of the data in a csv format using the link at the bottom of the currently displayed table.  However, there does not appear to be a programmatic means of doing this.  The link executes a javascript that apparently access what ever criteria was used to display the page. %BR%
%BLUE%Are there any plans to provide an API for data retrieval? With some criteria?  This is a really much needed requirement.%ENDCOLOR%%BR%
%GREEN%yes, it is possible but not documented yet %ENDCOLOR%%BR%
%RED%(John Weigand 11/2/11) - CRITICAL  Otherwise we have to find a way to accommodate our requirements as described in this section. %ENDCOLOR%%BR%
%GREEN%(Will Rogers 11/11/11) - Feedback from APEL system and / or portal – I’ll send another email about this.
%ENDCOLOR%%BR%
%RED%(John Weigand 11/11/11) - Without this capability, I am thinking we will have to modify the code to do a 2nd query summarized by VO so we can provide Nebraska with the data we need and, at the least, we then have a record of what we sent up to validate against the monthly MOU pdf.   Won&#39;t be exact but it is better than adding the code to summarize the query by DN.
%ENDCOLOR%%BR%
%GREEN%(Will Rogers 11/14/11)
There’s been some talk about being able to download data from the accounting portal in CSV format, but this is hazy for us too – I’d recommend asking the portal people themselves about the status of this and what they plan, because it’s not really under our control.
%ENDCOLOR%%BR%
%RED%(John Weigand 11/28/11)
Since I am not sure this will be resolved in the near future, The interface program has been modified to summarize the data by site/vo and create 2 files: YYYY-MM-summary.dat and YYYY-MM-summary.html.  This will allow the Nebraska WLCG portal access to the data provided today.%BR%
The caveat is that this is what we &quot;think&quot; is in APEL.  Not necessarily what is in APEL/EGI portal.  We can only verify this manually at this time.
%ENDCOLOR%%BR%

---++ SSM Testing
1. See  [[ https://wiki.egi.eu/wiki/APEL/SSMInstallation][SSM Installation Instructions]]

__Configuration section__
   * A general statement in the beginning when setting SSM_HOME variable might be useful saying it can be used in the ssm.cfg file but not in the ssm.log.cfg file. 

   * ssm.cfg - Since this in an ini format, might be useful to mention the section. Some were more obvious than others with the wording used. &quot;the topic to send..&quot; was not.  It is in the [producer] section.

__Running the SSM section__ 
   * I think the cd should be to $SSM_HOME/bin not $HOME/bin

   * In the configuration section, for the message store, you suggest using $SSM_HOME/messages but never mention it needs to be created. In addition in this section, you mention putting files to send in $SSM_HOME/messages/outgoing and never mention is obviously needs to be created.   I see where it gets creates on execution of run-ssm Other dirs are too but no mention of what they are for.

2. Testing documented here http://home.fnal.gov/~weigand/SSM/
 
3. Will told me they have a bug such that if the interface detects a problem on their end, it stops.  This is why I could not send yesterday.  They restarted it and the latest file went up.

4. Other issues;
   * They loop in the messages/outgoing directory every 1 sec. This is too much.  If no messages, there should be some sleep period. 
     This should be settable by the user.  
         This could easily be set in ssm-master.py here.. time.sleep(1.0) as the while loop will process all records until there are none.  
      
   * For sites like us sending summary records periodically it would be nicer if we could have a &quot;once and done&quot; option.  
     Maybe it would specify a &quot;retry period&quot; in the event of intermittent failures but would still terminate so we can indicate to our admins the state of the interface.
    This could also be done right in ssm-master.py. It could even have a retry arg/setting.

   * in messages_db.py (_get_message), there is a sort of the messages.
        Why?  This means that to insure an order, I have to be aware of this
        and reflect the order in the file name.  I would expect the
        receiving end to process my files in the order received.
        If, for whatever reason, I have 2 days data in the directory, the 2nd
        days has to go up last or I have to insure I always have only one file.

   * ssm_master.py
          log.debug(&#39;Ready for service. Listening for incoming messages.&#39;)
        .. should be &#39;outgoing&#39; as that is the directory we are looking in.
           There is an incoming one and this confuses the issue.


---++ *Comments*

%COMMENT{type=&quot;tableappend&quot;}%

