
Feedback from Science Advisory Group members

Jack Dongarra – met at SC2009&lt;br&gt;
Marjorie Shapiro – phone discussion &lt;br&gt;
Thomas Ullrich – phone discussion. Kent and Ruth. &lt;br&gt;


---+++ Dongarra:

First and foremost make strong science cases - 3-5 cases are needed.    - For example have workshops for the science communities to give their needs and help drive the future.   - Could perhaps look through the exascale workshop information to identify science cases for distributed mid- to low-end high throughput computing.
  - Could provide an update from the blue ribbon panel showing progress and benefits to date.
  - Technology and infrastructure arguments do not make a case for continuation without the science cases there first.

Computer Science as a driving science does not make the case.

Tell a simple story. Change the word &quot;Grid&quot;. Grid turns people off based on not meeting previous expectations.

Image processing and visualization increasingly important as part of the science needs.

---+++ Shapiro:
Hears from the users she knows that there are issues with being able to run across many sites. Each time a site is added, or a site is changed, there are problems 

How you make sure there is an appropriate environment and configuration?

What are the potentials for virtualization to solve this? 

Are there sufficient/usable technologies to make sure that when you send the job to the machine all the right information is there.


---+++ Ullrich:
The one thing that puzzled me most is the lack of a grid specific &quot;measures&quot;. May be it&#39;s me but I had a hard time extracting some feeling for this from the available diagrams and graphs. The documents are not short on hours spent and throughput etc. but these are measures typical for every computing farm and center.

As I understand it (?) the main benefit of the OSG is the distribution of tasks. Groups that have large fluctuations in their needs can tap in large resources for a short time (exceeding those available through their own funding) by using idle resources and more or less giving back when their needs are temporarily low – (Ruth subsequently sent the “Value of OSG” document listing 6 areas where the Consortium members see the benefits from OSG. This document has been endorsed by the Council.)

There&#39;s a number of 20-30%  mentioned a couple of times (meaning resources used by X owned by Y), but this is pretty much it. May be I missed something but I would think that this is the key. The benchmark would be what can be achieved if I take all the OSG resources and divide them up (meaning do not share them). Everything beyond what I get out of this scheme is pure OSG benefit. Are there plots/measures of this kind around? (Ruth subsequently sent the “Usage of OSG” paper from Brian at the ISGC workshop ’09. )

It appears that the OSG is heavily dominated by HEP group CMS/ATLAS/D0/CDF. Tevatron will shut down at some point and the LHC folks will need to ramp up big time (soonish one would think). From what I see HEP takes ~80 of the resources and I&#39;m sure they put at least this amount in. At some point the LHC folks will have their job queues filled up to 100% and will remain like this for years to come, implying there are no (or less) fluctuations or peaks in their needs. It&#39;s a steady level. The can fill up whatever they got. At some point the benefit of being in the OSG must be lower than they are now. Again, how do I measure the benefit to be on the grid then? With other words what would collaboration A lose or gain when they take all the resources out of the OSG and do their own net? What would others lose or gain - now and when the load of A exceeds/saturates available resources?

I haven&#39;t thought a lot about what would be a solid measure but one could imagine things like for a sample of VO&#39;s the CPU h gained versus the CPU h invested in. For a standalone computing farm one would expect large fluctuations for a typical mid-size science project while with OSG this should be much more leveled. Fluctuations of needs must be a key here?!

The reason I&#39;m interested in these kinds of statistics has to do with my second question. What is the criterion a science project should use to decide to join the OSG or not. Are there measures that allow them to judge if it is beneficial for them to become part of OSG or rather wire a stand alone farm together. [Here I have a bit STAR in mind which is using low level grid tools but otherwise is using dedicated facilities].

 My 3rd question is more related to the administrative efforts a single VO has to provide. From the documents it appears that the VO&#39;s have to fill quite some roles (VO manager, admin, security contact etc.). While large VO&#39;s most certainly have no problem with that, smaller groups might not be able to cope with that. It would be nice to see a plot that shows the distribution of users/VO. How big a road block is the FTE count needed to get into the OSG and work successfully with it. I see theory but this might be a special case? (We discussed the Engage VO where services and administration is provided by OSG, and the ability to aggregate and delegate some administrative services. We have not generated the plot).

Interested in the relationship to our European counterparts – Ruth noted that this is one of our successes in collaboration and adding value. Europeans migrating to more of a federation model like the OSG.

Interested in collaborations with with ASIA – Ruth noted that Asia not developed yet a coherent grid model, several Asian sites on the OSG.

Interested in plans for VM and Clouds in the near future?





-- Main.RuthPordes - 11 Jan 2010
