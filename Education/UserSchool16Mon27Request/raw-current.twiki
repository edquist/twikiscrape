&lt;style type=&quot;text/css&quot;&gt;
pre em { font-style: normal; background-color: yellow; }
pre strong { font-style: normal; font-weight: bold; color: #008; }
&lt;/style&gt;

---+ Monday Bonus Exercise 2.7: Declare Resource Needs

The goal of this exercise is to demonstrate the use of the =request_&lt;i&gt;X&lt;/i&gt;= statements in a submit file, for when you know what resources your job needs.

This is an optional exercise, so do it if you have time and interest.


---++ Determining Resource Needs

There are three special resource request statements that you can use (optionally) in an HTCondor submit file:

   * =request_memory= for the maximum amount of run-time memory your job uses
   * =request_disk= for the maximum amount of disk space your job uses in the sandbox directory (including your executable, input, and output files)
   * =request_cpus= for the number of CPUs your job takes (useful mostly for MPI jobs)

HTCondor defaults to certain reasonable values for these request settings, so you do not need to use them to get your job to run. So why care at all? Well, on some pools, if your job goes over the request values, it may be removed from the execute machine and either held (awaiting action on your part) or rerun later. So it can be a disadvantage to you if you do not declare your resource needs. Further, if you tell HTCondor accurate request needs, it can better match your job to an execute slot that will be able to run it effectively. In the long run, it works better for all users of the pool if you declare what you really need. Finally, on some advanced pools, HTCondor can actually join together single slots on an execute machine to create a slot just for your job with the resources it needs. Pretty cool, huh?

But how do you know what to request? In particular, we are concerned with memory and disk here; requesting multiple CPUs and using them effectively is beyond the scope of the School.

---+++ Determining Memory Needs

It can be very difficult to determine the memory needs of your running program. Typically, the memory size of a job changes over time, making the task even trickier. If you have knowledge ahead of time about your job’s memory needs, use them! If not, probably the best you can do is run your program locally (i.e., not with HTCondor) and observe its behavior over time.

On a Linux system, you can use the =ps= command or the =top= command to watch a running program and see (roughly) how much memory it is using. Full coverage of these tools is beyond the scope of this exercise, but here are two quick examples:

Using =ps=:

&lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT_SHORT% &lt;strong&gt;ps ux&lt;/strong&gt;
USER       PID %CPU %MEM    VSZ   &lt;em&gt;RSS&lt;/em&gt; TTY      STAT START   TIME COMMAND
cat      24342  0.0  0.0  90224  &lt;em&gt;1864&lt;/em&gt; ?        S    13:39   0:00 sshd: cat@pts/0  
cat      24343  0.0  0.0  66096  &lt;em&gt;1580&lt;/em&gt; pts/0    Ss   13:39   0:00 -bash
cat      25864  0.0  0.0  65624   &lt;em&gt;996&lt;/em&gt; pts/0    R+   13:52   0:00 ps ux
cat      30052  0.0  0.0  90720  &lt;em&gt;2456&lt;/em&gt; ?        S    Jun22   0:00 sshd: cat@pts/2  
cat      30053  0.0  0.0  66096  &lt;em&gt;1624&lt;/em&gt; pts/2    Ss+  Jun22   0:00 -bash
&lt;/pre&gt;

The Resident Set Size (=RSS=) column, highlighted above, gives a rough indication of the memory usage (in KB) of each running process. If your program runs long enough, you can run this command several times and note the greatest value.

Using =top=:

&lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT_SHORT% &lt;strong&gt;top -u &lt;em&gt;userid&lt;/em&gt;&lt;/strong&gt;
top - 13:55:31 up 11 days, 20:59,  5 users,  load average: 0.12, 0.12, 0.09
Tasks: 198 total,   1 running, 197 sleeping,   0 stopped,   0 zombie
Cpu(s):  1.2%us,  0.1%sy,  0.0%ni, 98.5%id,  0.2%wa,  0.0%hi,  0.1%si,  0.0%st
Mem:   4001440k total,  3558028k used,   443412k free,   258568k buffers
Swap:  4194296k total,      148k used,  4194148k free,  2960760k cached

  PID USER      PR  NI  VIRT  &lt;em&gt;RES&lt;/em&gt;  SHR S %CPU %MEM    TIME+  COMMAND
24342 cat       15   0 90224 &lt;em&gt;1864&lt;/em&gt; 1096 S  0.0  0.0   0:00.26 sshd
24343 cat       15   0 66096 &lt;em&gt;1580&lt;/em&gt; 1232 S  0.0  0.0   0:00.07 bash
25927 cat       15   0 12760 &lt;em&gt;1196&lt;/em&gt;  836 R  0.0  0.0   0:00.01 top
30052 cat       16   0 90720 &lt;em&gt;2456&lt;/em&gt; 1112 S  0.0  0.1   0:00.69 sshd
30053 cat       18   0 66096 &lt;em&gt;1624&lt;/em&gt; 1236 S  0.0  0.0   0:00.37 bash
&lt;/pre&gt;

The =top= command (shown here with an option to limit the output to a single user ID) also shows information about running processes, but updates periodically by itself. Type the letter =q= to quit the interactive display. Again, the highlighted =RES= column shows an approximation of memory usage.

---+++ Determining Disk Needs

Determining disk needs may be a bit simpler, because you can check on the size of files that a program is using while it runs. However, it is important to count all files that HTCondor counts to get an accurate size. HTCondor counts *everything* in your job sandbox toward your job’s disk usage:

   * The executable itself
   * All input files
   * All output files, including the captured standard output and error
   * All temporary files created in the sandbox

If you can run your program within a single directory on your local system (i.e., not via HTCondor), you should be able to view files and their sizes with the =ls= command.

---+++ Running a Test Job

Despite the techniques mentioned above, by far the easiest approach to measuring your job’s resource needs is to run one or a small number of sample jobs and have HTCondor itself tell you about the resources used during the runs.

For example, here is a strange Python script that does not do anything useful, but consumes some real resources while running:

&lt;pre class=&quot;file&quot;&gt;
#!/usr/bin/env python
import time
import os
size = 1000000
numbers = []
for i in xrange(size): numbers.append(str(i))
tempfile = open(&#39;temp&#39;, &#39;w&#39;)
tempfile.write(&#39; &#39;.join(numbers))
tempfile.close()
time.sleep(60)
os.remove(&#39;temp&#39;)
&lt;/pre&gt;

Without trying to figure out what this code does or how many resources it uses, just create a submit file for it, and run it once with HTCondor. When it is done, examine the log file. In particular, we care about these lines:

&lt;pre class=&quot;file&quot;&gt;
	Partitionable Resources :    &lt;em&gt;Usage&lt;/em&gt;  Request Allocated
	   Cpus                 :                 1         1
	   Disk (&lt;em&gt;KB&lt;/em&gt;)            :     &lt;em&gt;6739&lt;/em&gt;        1   8022934
	   Memory (&lt;em&gt;MB&lt;/em&gt;)          :        &lt;em&gt;3&lt;/em&gt;        1         1
&lt;/pre&gt;

So, now we know that the job used 6,739 KB of disk (= about 6.5 MB) and 3 MB of memory!

This is a great technique for determining the real resource needs of your job. If you think resource needs vary from run to run, submit a few sample jobs and look at all the results. And it never hurts to round up your resource requests a little, just in case your job occasionally uses more resources.


---++ Setting Resource Requirements

Once you know your job’s resource requirements, it is easy to declare them in your submit file. For example, taking our results above as an example:

&lt;pre class=&quot;file&quot;&gt;
request_memory = 3MB
request_disk = 7MB   &lt;span style=&quot;font-style: italic; color: blue;&quot;&gt;# rounded up from 6.5 MB&lt;/span&gt;
&lt;/pre&gt;

Pay close attention to units:

   * Without explicit units, =request_memory= is in MB (megabytes)
   * Without explicit units, =request_disk= is in KB (kilobytes)
   * Allowable units are =KB= (kilobytes), =MB= (megabytes), =GB= (gigabytes), and =TB= (terabytes)

HTCondor translates these requirements into expressions that become part of the =requirements= expression. However, do not put your CPU, memory, and disk requirements directly into the =requirements= expression; use the =request_&lt;i&gt;XXX&lt;/i&gt;= statements instead.

Add these requirements to your submit file for the Python script, rerun the job, and confirm in the log file that your requests were used.
