&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;%PUBURL%/%WEB%/WorkshopTutorialModules/exercises.css&quot;&gt;

---+!! Immediate (fork) and Batch (scheduled) Job managers

%STARTINCLUDE%
%EDITTHIS%

Notice that we follow the system name that you want to run the command on with the qualifier =/jobmanager-fork=. GRAM, the Globus protocol for running remote jobs, supports the concept of a &quot;job manager&quot; as an adapter to local job management environments.  Each &quot;Grid site&quot; - or collection of resources - can support one or more such job managers. The &quot;fork&quot; job manager runs an immediate job through the UNIX fork() interface. Another job manager we have installed on the workshop hosts, =jobmanager-condor= acts as an interface to the Condor batch scheduling system.

Which do you think will be faster?  Lets find out: use the command =time= to test which jobmanager is faster.

To time a command, just enter =time &lt;em&gt;commandname&lt;/em&gt;=:

&lt;pre class=&quot;screen&quot;&gt;
%LOGINHOST%$ &lt;userinput&gt;time sleep 3&lt;/userinput&gt;
&lt;/pre&gt;

Use this to time a few trvial Grid jobs to compare =jobmanager-fork= and =jobmanager-condor=.

The &quot;fork&quot; job manager is very fast - it has rather low &quot;scheduling latency&quot;.  It runs trivial commands very quickly.  But it also has no compute power - its usually just a single CPU on a cluster-controlling computer called the _gatekeeper_ or _headnode_.  A batch job manager, on the other hand, has a higher scheduling overhead.  But it gives you access to all computers in a cluster, and the opportunity to do real parallel computing.

It turns out that each of our workshop machines is just an ordinary single-processing machine. We&#39;ve just &quot;tricked&quot; Condor onto thinking that it had a real &quot;cluster&quot; there with a set of CPUs. (We configured each of the workshop hosts with 16 such virtual CPUS).

While our four workshop hosts use the Condor scheduler, and thus =jobmanager-condor=, other systems use other schedulers. For example, systems using _PBS_ (Portable Batch System) require that you use =jobmanager-pbs=.  You&#39;ll get a chance to try this later in this lab.

Now try running a few jobs at a remote grid site which does have a real cluster:

&lt;pre class=&quot;screen&quot;&gt;
%LOGINHOST%$ &lt;userinput&gt;globus-job-run skynet-login.isi.edu:/jobmanager-pbs /bin/hostname&lt;/userinput&gt;
&lt;/pre&gt;

Next try starting five such jobs on the skynet cluster at once: put an &quot;&amp;&quot; at the end of the line, and either use cut-and-past, or shell command history, or a simple shell script to run five of these commands at once.  

Can you see multiple hostnames being used?  Are any of these the skynet-login &quot;gatekeeper&quot; hostname?


%STOPINCLUDE%
&lt;!--                                                                            
      * Set LOGINHOST = workshop1.lac.uic.edu
      * Set LOGINIP = 131.193.181.56
      * Set GRIDHOST = tg-login.sdsc.teragrid.org
      * Set OTHERHOST = workshop2.lac.uic.edu
      * Set CERTSUBJECT = /O=Grid/OU=OSG/CN=Training User 99
      * Set LOGINNAME = train99
      * Set HOMEDIR = /home/%LOGINNAME%
--&gt; 

%BOTTOMMATTER%

-- Main.ForrestChristian - 29 Jan 2007: edited from original  %BR%
-- Main.ForrestChristian - 24 Mar 2007 - Added VARIABLES      %BR%
