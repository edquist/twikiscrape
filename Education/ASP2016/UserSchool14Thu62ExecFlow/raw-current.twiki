&lt;style type=&quot;text/css&quot;&gt;
pre em { font-style: normal; background-color: yellow; }
pre strong { font-style: normal; font-weight: bold; color: #008; }
&lt;/style&gt;

---+ Thursday Exercise 6.2: Execute a Production Workflow

In this portion, you will finish testing workflow steps, write the DAG for the workflow you planned, and submit this workflow to the Open Science Grid. There are bonus tasks in Exercise 6.3.

---+++*Before moving on, copy all files to School glidein server, and run jobs on the OSG for the remainder of the exercise!*


1) For both the Permutation and QTL steps (and after the QTL tests complete), estimate the necessary disk, RAM, and run time requirements by scaling the values from your test log files. You may wish to move all outputs and log files created to another folder so as not to confuse the optimized tests in the next steps.

2) Modify the Permutation submit file for each trait according to the optimal number of job processes and permutations per process that you determined in the last exercise (# job processes X # permutations = 10,000 total permutations per trait). Submit one of these newly modified Permutation submit files in preparation for an optimized QTL test. If your estimate of the necessary permutations per process (for a ~10-minute run time) was not close enough, modify and test the Permutation job again.

3) To prepare an optimized QTL step, use =tarit.sh= to package the output from the test Permutation step from before. As above, you will only need to submit one of the QTL submit files to confirm the approximate RAM, disk, and run time needed. 

4) Don&#39;t forget to test taritall.sh after a successful QTL job to make sure it works as expected. After the optimized Permutation and QTL tests, move all output, error, and log files to a new directory to prepare for the production workflow.

5) Re-draw your workflow, now with more details and &#39;boxes&#39; for _each job process_ within the Permutation step of each trait. Indicate the optimized number of processes, the number of permutations per process, and the approximate disk, RAM, and run time requirements for each process. You may also wish to include information about the names and size of input and output files. 

6) Additionally, modify all of the submit files with adequate request_memory and request_disk lines based upon the log files of your full-scale tests.

7) Write a single DAG file for the workflow, including:
   * =JOB= lines for each submit file
   * =PARENT x CHILD y= lines as necessary
   * =SCRIPT PRE= and/or =SCRIPT POST= lines for the tar steps
*Note:* You may need to think about how each tar step works for deciding on &quot;PRE&quot; or &quot;POST&quot; scripts for each.

8) Run your full-scale DAG and determine the total run time. If you have any issues, consult the log and out files for the DAG and jobs, and modify your approach at any of the previous steps. While the full-scale DAG is running, you may wish to further detail your drawn workflow. Share all files with one another so everyone has a copy.

If you have time, move on to the Bonus Tasks in [[https://www.opensciencegrid.org/bin/view/Education/UserSchool14Thu63BonusFlow][Exercise 6.3]]



-- Main.LaurenMichael - 06 Jul 2014
