%LINKCSS%

---+!! Tracking the Progress of the Workflow and Debugging the Workflows
%STARTINCLUDE%
%EDITTHIS%

In this exercise we are going to list ways to track your workflow, and give some debugging hints when something goes wrong.

We will change into the directory, that was mentioned by the =vds-run= command.

&lt;pre class=&quot;screen&quot;&gt;
$ &lt;span class=&quot;in&quot;&gt;cd /nfs/home/@USER@/tutorial/master/PEGASUS/dags/ivdgl1/QuarkCode/run000X&lt;/span&gt;
&lt;/pre&gt;

In this directory you will see a whole lot of files. That should not scare you. Unless things go wrong, you need to look at just a very few number of files to track the progress of the workflow.

At the first go you should be concerned with only one file: =jobstate.log=. This is the output file of the monitoring daemon that is parsing all the condor log files to determine the status of the jobs. It logs the events seen by Condor into a more readable form for us.
      &lt;pre class=&quot;screen&quot;&gt;
$ &lt;span class=&quot;in&quot;&gt;more jobstate.log&lt;/span&gt;
&lt;span class=&quot;out&quot;&gt;1149911774 INTERNAL *** TAILSTATD_STARTED ***
1149911773 INTERNAL *** DAGMAN_STARTED ***
1149911773 QuarkCode_0_pegasus_concat UN_READY - - -
1149911773 Plot_ID000008 UN_READY - - -
1149911773 Lifetime_ID000005 UN_READY - - -
1149911773 WireDelay_ID000002 UN_READY - - -
1149911773 rc_tx_WireDelay_ID000002_0 UN_READY - - -
[..]&lt;/span&gt;
 &lt;/pre&gt;


In the starting of the jobstate.log, when the workflow has just started running you will see a lot of entries with status =UN_READY=. That designates that DAGMan has just parsed in the .dag file and has not started working on any job as yet. Initially all the jobs in the workflow are listed as =UN_READY=.

After sometime you will see entries in =jobstate.log= that show a job is being executed, etc.

&lt;pre class=&quot;programlisting&quot;&gt;
1149911774 QuarkCode_0_isi_skynet_cdir SUBMIT 264.0 isi_skynet -
1149911789 QuarkCode_0_isi_skynet_cdir EXECUTE 264.0 isi_skynet -
1149911789 QuarkCode_0_isi_skynet_cdir GLOBUS_SUBMIT 264.0 isi_skynet -
1149911789 QuarkCode_0_isi_skynet_cdir GRID_SUBMIT 264.0 isi_skynet -
1149911794 QuarkCode_0_isi_skynet_cdir JOB_TERMINATED 264.0 isi_skynet -
1149911794 QuarkCode_0_isi_skynet_cdir POST_SCRIPT_STARTED - isi_skynet -
1149911799 QuarkCode_0_isi_skynet_cdir POST_SCRIPT_TERMINATED 264.0 isi_skynet -
1149911799 QuarkCode_0_isi_skynet_cdir POST_SCRIPT_SUCCESS - isi_skynet -
&lt;/pre&gt;

The above shows the create dir job being submitted and then executed on the grid. In addition it lists that job is being run on the grid site =isi_skynet=. The various states of the job while it goes through submission to execution to postprocessing are in UPPERCASE.

To see which job of yours is being executed, you can also use =condor_q=. By default, &lt;em&gt;condor_q&lt;/em&gt; list all the jobs on the submit host. However, we are just interested in our own respective jobs. So we will use some classad magic to narrow the results.

Run command &lt;tt&gt;condor_q -const &#39;(Owner == &quot;@USUER@&quot;)&#39;&lt;/tt&gt; replacing =@USER@= with your the username.

&lt;pre class=&quot;screen&quot;&gt;
$ condor_q -const &#39;(Owner == &quot;vdsuser-4&quot;)&#39;&lt;/span&gt;
&lt;span class=&quot;out&quot;&gt;252.0   vdsuser-4       6/9  17:04   0+00:11:21 R  0   9.8  condor_dagman -f -
260.0   vdsuser-4       6/9  17:15   0+00:00:00 I  0   9.8  kickstart -n Quark&lt;/span&gt;
&lt;/pre&gt;

The above indicates that currently we have two jobs running.


Keep a lookout on the &lt;em&gt;condor_q&lt;/em&gt; to track whether a workflow is running or not. If you do not see any of your job in the condor_q for sometime (say 30 seconds), we know the workflow has finished. We need to wait, as there might be delay in CondorDAGMAN releasing the next job into the queue after a job has finished successfully.

If condor_q is empty, then either your workflow has:
   * successfully completed
   * stopped midway due to non recoverable error

---++++ Successfully Completed
Let us again look at the =jobstate.log=. This time we need to look at the last few lines.

&lt;pre class=&quot;screen&quot;&gt;
$ &lt;span class=&quot;in&quot;&gt;tail jobstate.log &lt;/span&gt;
&lt;span class=&quot;out&quot;&gt;1149894263 new_rc_tx_Plot_ID000008_0 POST_SCRIPT_TERMINATED 248.0 local -
1149894263 new_rc_tx_Plot_ID000008_0 POST_SCRIPT_SUCCESS - local -
1149894268 new_rc_register_Plot_ID000008 SUBMIT 249.0 local -
1149894273 new_rc_register_Plot_ID000008 EXECUTE 249.0 local -
1149894273 new_rc_register_Plot_ID000008 JOB_TERMINATED 249.0 local -
1149894273 INTERNAL *** DAGMAN_FINISHED ***
1149894274 INTERNAL *** TAILSTATD_FINISHED 0 ***&lt;/span&gt;
&lt;/pre&gt;

Looking at the last two lines we see that DAGMAN finshed, and tailstatd finished successfully with a status 0. This means workflow ran successfully. Congratulations you ran your workflow on the grid successfully.

The output plot generated by the workflow is =.png file= that resides in the directory =/nfs/storage01/trainXX/vdsuser-Y_plot.png= where =XX= is the 2 digit version of Y.  (e.g, if user is =vdsuser-4= then the path will be =/nfs/storage01/train04/vdsuser-4_plot.png=

To view the plot, you can copy =vdsuser-Y_plot.png= to your skynet webspace, and view it in your web browser:&lt;/p&gt;

&lt;pre class=&quot;screen&quot;&gt;
$ &lt;span class=&quot;in&quot;&gt;cp /nfs/storage01/train04/vdsuser-4_plot.png ~/public_html/newplot.png&lt;/span&gt;
&lt;/pre&gt;

Point your web browser to: =http://skynet-login.isi.edu/~@USER@/newplot.png= where =@USER@= is your userid.


---++++  Unsuccessfully Completed (Workflow execution stopped midway)
Let us again look at the jobstate.log. Again we need to look at the last few lines.

&lt;pre class=&quot;screen&quot;&gt;
$ &lt;span class=&quot;in&quot;&gt;tail jobstate.log&lt;/span&gt;
&lt;span class=&quot;out&quot;&gt;1149912756 Frequency_ID000006 SUBMIT 277.0 isi_skynet -
1149912766 Frequency_ID000006 GLOBUS_SUBMIT 277.0 isi_skynet -
1149912766 Frequency_ID000006 GRID_SUBMIT 277.0 isi_skynet -
1149912861 Frequency_ID000006 EXECUTE 277.0 isi_skynet -
1149912901 Frequency_ID000006 JOB_TERMINATED 277.0 isi_skynet -
1149912901 Frequency_ID000006 POST_SCRIPT_STARTED - isi_skynet -
1149912906 Frequency_ID000006 POST_SCRIPT_TERMINATED 277.0 isi_skynet -
1149912906 Frequency_ID000006 POST_SCRIPT_FAILURE 1 isi_skynet -
1149912906 INTERNAL *** DAGMAN_FINISHED ***
1149912911 INTERNAL *** TAILSTATD_FINISHED 1 ***&lt;/span&gt;
&lt;/pre&gt;

Looking at the last two lines we see that DAGMAN finshed, and tailstatd finished unsuccessfully with a status 1.

We can easily determine which job failed. It is =Frequency_ID000006= in this case.

To determine the reason for failure we need to look at it&#39;s kickstart output file which is =$JOBNAME.out= (i.e., [[http://skynet-login.isi.edu/~vdsuser-4/Frequency_ID000006.out][Frequency_ID000006.out]])

Looking at it&#39;s output we see it failed because of a perl library not installed on isi_skynet!.

We correct that and submit the workflow again.


%STOPINCLUDE%

%BOTTOMMATTER%
-- Main.ForrestChristian - 27 Feb 2007
