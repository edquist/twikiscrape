&lt;style type=&quot;text/css&quot;&gt;
pre em { font-style: normal; background-color: yellow; }
pre strong { font-style: normal; font-weight: bold; color: #008; }
&lt;/style&gt;

---+ !!HTCondor File Transfer
%TOC%

The objective of this exercise is to refresh yourself on the basic techniques for transferring data on OSG.

Recall that OSG does not have a shared filesystem! With that in mind, we&#39;ll show how to transfer input data for a sample application. 

We&#39;ll also look at how compression and archival can be used to effectively transfer files.

---++ Setup

&lt;center&gt;
&lt;img src=&quot;%ATTACHURLPATH%/data_tranfer_1.jpg &quot; alt=&quot;data_tranfer_1.jpg &quot; width=&#39;400&#39; height=&#39;150&#39;/&gt;
&lt;/center&gt;

In the exercise we&#39;ll use the same Blast that we used previously.  We&#39;ll write a job that transfers the required Blast files (as you discovered in [[UserSchool16Thurs21][Exercise 1.1]]) from the submit host to the worker node via the HTCondor file transfer mechanism.

In a previous [[UserSchool16Thurs21][exercise]], you discovered all of the files required for Blast to run.  Now we are going to make an HTCondor submit file to run blast on a remote worker node.

---++ Create and submit the job

We&#39;ve started a submit script for you below, but you will need to fill out the =transfer_input_files= section. For ==blastx== to successfully run, you&#39;ll need all of the input files.

*HINT*: =transfer_input_files= accepts a comma separated list of files.

&lt;pre class=&quot;file&quot;&gt;
universe = vanilla
executable = blastx
arguments = -db pbdaa -query mouse.fa
transfer_input_files = 
output = job.out
error = job.error
log = job.log
queue
&lt;/pre&gt;

Once you have finished creating the submit file, go ahead and submit the job.
&lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT_SHORT% condor_submit blast_run.submit
&lt;/pre&gt;

The job should take a minute or two to complete. Once finished, look at the job output (in our case, =job.out=).  Is it the expected output?  Does it look the same as if you ran blast on your own?  

---++ Compressed input files

Sometimes when you have a lot of input files it makes more sense to compress them before sending them with a job. For this exercise, we want to compress our blast input files and send them to the remote worker node. 

For this part of the exercise, you will need to:

   1. Compress the input files using the =tar= command, as you did in exercise [[UserSchool16Thurs12rsync][1.2]]
   1. Modify =transfer_input_files= in the file =blast_run.submit= to transfer your compressed file
   1. Create a wrapper script which will decompress the input files, then run blast.

*HINT*: Here&#39;s a pattern for the =tar= command:
&lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT_SHORT% tar -cvzf [compressed filename] [list of files]
&lt;/pre&gt;

Replace =-c= with =-x= to decompress.

The wrapper script should uncompress the files, then run blast as usual.  Create a new file, called ==blast_wrapper.sh==
&lt;pre class=&quot;file&quot;&gt;
#!/bin/sh

tar xvzf %RED%[compressed filename]%ENDCOLOR%

exec ./blastn &quot;$@&quot;
&lt;/pre&gt;

The submit file will need to be updated to be the executable, rather than blast itself.

&lt;pre class=&quot;file&quot;&gt;
universe = vanilla
executable = blast_wrapper.sh
arguments = -db pdbaa -query mouse.fa
transfer_input_files = 
output  = job.out
error = job.error
log = job.log
queue
&lt;/pre&gt;

Submit the job.  Does it work as expected?

Run a ==du -sh== on the directory with this job&#39;s input.  Did it decrease the size of the input data compared to the first exercise in [[UserSchool16Thurs21][1.1]]




-- Main.LaurenMichael - 06 Jul 2016
