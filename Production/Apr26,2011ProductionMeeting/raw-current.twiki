-- Main.DanFraser - 08 Apr 2011
---++ Action/Significant Items:
   * LIGO/BNL,AGLT2 Issues: This needs to be looked at closer and is preventing LIGO from fully utilizing ATLAS resources. Rob will chat with Dan about this and give him the details. 
   * UCSD Glide-In factory Outage affected Analysis not Production, and this was recovered relatively quickly. Request for second Glide-In Factory reiterated.
   * Upcoming testing of new DOEGrids Certificate format in production is about a month away. 

---++ Attendees: Rob Q., Scott T., Brian, Suchanda, Armen, Chander, Burt, Xin, Robert E., Mine, 
   * (to be updated after the meeting) Mats, Xin, Armen, Britta, Robert E., Brian, Suchandra, Burt, Marco, Rob Q., Scott T., Mine, Chander, Dan
 
---++ CMS (Burt)
   * Machine: LHC setting instantaneous luminosity records.  100 pb^-1 delivered to CMS in just the _last week_.  50 ns bunch spacing + larger numbers of bunches per fill equates to more pile-up -- longer jobs that take more memory
   * 400 khour, 89% success.
   * Getting practice prioritizing global workflows using glideinWMS


---++ Atlas (Armen &amp; Xin)

   * General production status
      * LHC continues its successful run. Thu-Fr running at record beam intensity and set a new world record for luminosity at 4.67 x 1032cm-2s-1. The previous record was from Fermilab at 4.024 x 1032cm-2s-1. The 2011 integrated luminosity for ATLAS is now ~160pb-1, about half of which was collected since Friday.
      * US ATLAS production was relatively stable at the beginning and end of the week (running out of jobs at the middle of the week) at the average level of about 10k running jobs. Waiting for the new MC production release, then will have full load for at least couple of months. 
   * Job statistics for last week. 
      * Gratia report: USATLAS ran 2.7M jobs, with CPU/Walltime ratio of 85%. 
      * Panda world-wide production report (real jobs): 
         * completed 1.3M managed group, MC production, validation and reprocessing jobs 
         * average 184K jobs per day
         * failed 84K jobs 
         * average efficiency:  jobs - 94%, walltime - 97%
      * Panda jobs processed, as reported by Panda monitor, on USATLAS sites:
         * 692K panda jobs processed for last week. 
   * Data Transfer statistics for last week
      * BNL T1 data transfer rate was around 300TB/day in last week. 
   * Issues
      * HCC opportunistic access to USATLAS sites: general agreement reached, implementation details (group quota) are in work progress.
      * LIGO jobs excessive accessing BNL srm server causing problems
         * access rate too high, causing high load on pnfs server
         * job ran at AGLT2, checking pointing to BNL srm
         * a lot of LIGO jobs were preempted at the same time
         * suggested change of job workflow to avoid this in the future: basically saving files locally first, then orderly and asynchronously staging them to destination.

      * ATLAS asks for updating LFC packages in VDT/OSG client.  Meeting with VDT this week to flesh out details. 

---++ LIGO (Britta, Robert E.)


---++ Grid Operations Center (Rob Q.)
---+++ Operations Last Week 
   * [[http://tinyurl.com/27fknc6][GOC Services Availability/Reliability]]
      * Display Issue has been turned over to Ashu. [[https://ticket.grid.iu.edu/goc/viewer?id=9245][Ticket]]
   * [[http://myosg.grid.iu.edu/miscstatus/index?datasource=status&amp;count_sg_1=on&amp;count_active=on&amp;count_enabled=on][Current Status]]
   * No ITB changes for this week.
   * !MetricDescription upload to SAM turned off, no effects observed.
   * Gratia
      * The ITB and Production databases are shared and there was a slowdown due to an itb site in Columbia that dumped all of their unknown VO data.
      * This more than likely contributed to the Display Issues.
   * WMS Glide In Factory
      * Campus wide network outage at UCSD Tues April 19 5:45 pm to about 7:30 pm (pacific).
         * Believed to be caused by damaged fiber optic connection connecting campus to WAN
         * During this time the Factory was unreachable by off-campus Frontends
         * Igor notified Frontend admins with his FNAL email (UCSD mail servers were unreachable as well)
         * Did not affect running glideins for off-campus Frontends, only prevented new ones from starting in this time period
         * CMS glideins failed however since glideins could not reach the CMS Frontend at UCSD

---+++ Operations This Week
   * Currently 1/5 BDIIs at CERN is having slowness
   * No production release this week
   * Request to stop monitoring SAM-BDII at CERN
      * Approved by Xin and Alessandro
   * Will be modifying format of data to be sent to SAM
   * SURAGrid Support during AHM next week


---++ Metrics
   * We&#39;re currently stable with respect to the ATLAS normalization constants being sent to WLCG.
   * Karthik is beginning to work through the accounting of hyper-threading.  It turns out this is partially a WLCG issue: we&#39;re not sure whether or not the WLCG wants us to have the correct values.  At least one document explicitly says to normalize on cores, not batch slots.  We&#39;ll bring this up with the interop group to get a firm signal.

---++ Engage (Mats, John)


---++ Integration (Suchandra)
   * Testing
      * Waiting on VDT release, 1-2 weeks away
   * HTPC 
      * 2 ITB sites support HTPC
      * 2 other sites will probably support it, but not in near term
   * Documentation
      * Released several documents last week, will start working on a new batch this week

---++ Site Coordination (Marco)


---++ Virtual Organizations Group (Chander)


---++ Security (Mine)
   * CERN Single-sign-on ticket has been resolved. Rob Q is leading the effort to work with CERN IT and DOEGrids to ensure they won&#39;t be affected if this occurs again. 
   * An important security incident happened at oak ridge national lab. May have involved some Teragrid resources at oak ridge. Our talks with Teragrid did not reveal how/if grid users are affected. 
   * Incident involving CERN and ESA concluded that it has no OSG consequences. EGI continues with response concerning CERN accounts. 
   * Production testing of the new certs. Security team prepared a new set of action items. We will need help from GOC, Burt and Xin with initial testing. To get to the testing point we first need approval of our working group (Mine, Dan, Rob, Suchandra, Marco, Steve, Anand)


---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings
