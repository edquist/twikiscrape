-- Main.DanFraser - 02 Jun 2009
---++ Action Items
   * How to handle GIP information not being maintained by users.
      * Abhishek to provide a detailed report for Burt and file a ticket.
   * NanoHub highest priority issue (handling the Purdue CA)
      * An RSV probe has been developed that checks to see which CAs are set up and configured on a particular site (Mine)
      * There seemed to be consensus on the call that this probe could be used to update this information directly in the site database so that it would be available to GIP as well.
         * This is a slightly new direction for RSV to have the role of updating tables however, so we should have more discussion before implementing this type of change. Discussion team to include (Mine, Rob Q [Arvin], software, and STG)
---++ Attendees:
   * Xin, Mats, Marco, Brian, Suchandra, Burt, Abhishek, Rob Q, Mine, Dan
---++ CMS (Burt)
   * 120 khours/day consumed, job efficiency of 92% -- this is incomplete (missing MIT and some Nebraska data).   Step09 is starting -- we will be doing heavy MSS I/O as we clear data off disk to exercise the tape-&gt;disk rereconstruction across OSG and EGEE.

---++ Atlas (Armen &amp; Xin)

   * job statistics for last week. 
      * Gratia report: USATLAS ran 1.3M jobs, with CPU/Walltime ratio of 74.1%
      * PanDA world-wide production report (real jobs):
         * completed successfully 344,634 managed MC production, validation and reprocessing jobs
         * average  ~49,233 jobs per day
         * failed   90,731  jobs
         * average efficiency: 79.2% for jobs and 89.8% for walltime

   * STEP09 starts this Tuesday, June 2.  

---++ LIGO (Britta)


---++ Site Integration (Suchandra)
   * Almost back on [[https://twiki.grid.iu.edu/bin/view/Trash/Trash/Trash/Trash/SoftwareTools/OSG12Plan][schedule]] outlined
   * Will have a meeting to wrap up vtb testing
   * Will start itb testing this week

---++ Site Coordination (Marco)
OSG Site Administrators meeting Aug 6-7 2009. 
   * planning for lodging (Rob Quick)
   * &quot;faculty meting&quot; to plan sessions

Survey about sites updating to OSG 1.0.1 (&lt;a href=&quot;http://www.surveymonkey.com/MyCollector_Detail.aspx?sm=yzJizU8aQ6JuSg3qsf3tfEMsuID6CMHuBzSd0Ezuq3nErKeMDM2Wsm8Nny2p%2fWa5&quot;&gt;link here&lt;/a&gt;):
   * verify update/install experiences
   * ask for date for planned update (if not updated)
Very few answers: 8 system administrators (for a total of 14 sites).
Generally the update/install procedure was rated difficult: sysadmin were able to complete it only thanks to help/support                                                                                          

Some comments from site administrators  below:
        &lt;p&gt;Bestman would not work, it did not maintain the gums support. Alex Sims helped me out. GUMS didn&#39;t work at all, the config file wasn&#39;t using the new mysql database. CEMon is broke, and still is. Not reporting to BDII and ReSS servers. No idea why not.&lt;/p&gt;
        &lt;p&gt;I was having problems with my current 1.0.0 install (not reporting to RSV) just in the days of version transition, and I had not noticed the &quot;don&#39;t upgrade now&quot; email, so when I tried to uninstall and reinstall some packages, pacman got confused. At that point I just did a full clean install, which happened to fetch 1.0.1; I only had to do some minor modifications to the config.ini, which were anyway very easy. In general I like that the pacman installs are nicely automated, but I&#39;m not happy that it does not keep a local cache of the installed packages (bandwidth is not abundant in South Africa; I had to install a special squid to cache the large package files), and that it does not integrate with the OS packaging system for conflict/dependency checks. It&#39;s also more difficult to recover a failed/incomplete install (than with YUM as used by gLite). On the positive side, it does not suffer from the &quot;package dependency nightmares&quot; that I&#39;m seeing with gLite.&lt;/p&gt;
        &lt;p&gt;The vdt-updater was a little too picky when processing user input (&#39;y&#39; vs. &#39;yse&#39;). cemon had some stale data that did not get cleaned up until I randomly                                                  
removed some cached files and waited several hours for it to clean itself up. GIP bugs prevented proper associations between my two CEs and SEs. Other issues were posted to the osg mailing list and got responses very quickly.&lt;/p&gt;

Other notes:
   * Some site admin did not answer because they have no plans about the update and are waiting to answer the survey                                                                                                             
   * This week I&#39;ll send a reminder and close the survey.

---++ Engagement (Mats)

&lt;verbatim&gt;
-------------------------------------------------------
| VO             | # of Jobs | Wall Dur. | Cpu / Wall |
-------------------------------------------------------
| engage         |    14,782 |    50,248 |       86.2 |
&lt;/verbatim&gt;

Good week for Engagement. Only production issue was a VO member staging
larger input data using the Condor-G file staging mechanism. The result
was quota overages and a ticket from FNAL. The Trash/Engagement Team helped
the user improve his data staging and caching.



---++ Metrics (Brian)
   * End of month metrics available here: http://t2.unl.edu/gratia/jot_reporting.  This is missing 1/2 month&#39;s data from MIT (GOC #6957) and 2 days of data from Nebraska (GOC #6958).  Chris is following up on the missing data.
   * RSV Reports haven&#39;t gone out in a day or two; got a note from Arvind stating that he was debugging the issue.  I think I&#39;ve tracked down the issue to database slowness at the GOC.  Last time, I got around this by increasing timeouts; it will hopefully be fixed in time for tonight&#39;s report.
   * Ongoing projects:
      * OIMv2: Migration of all my projects to OIMv2 is complete; only remaining known error is the above RSV reports
      * Installed Capacity: Karthik is restarting some of this work as OIMv2 is now functioning.
      * Gratia: Some folks missed my previous live display link.  Currently at http://gratia.fnal.gov/Files/osg_gratia_display/today/live_display.png .

---++ Virtual Organizations Group (Abhishek)

   * D0 
      * D0 !MonteCarlo production is at an average consumption of 100,000 wall hours per day. Usual efficiencies except job efficiency - dropped to 60% last week. Causes are likely internal to D0 submission system.
      * D0 Event production is at 11 million events per week. 
      * New annual peak achieved in weekly MC production rate. Peak is 12.6 ~ 13.0 million events per week, in third week of May&#39;09. 
      * No recent update on bugfix for Globus LSF Manager.
     
   * Fermi-VO
      * No production issues at the moment.
      * Multiple communities/subgroups running production.
      
   * !CompBioGrid
      * [[https://twiki.grid.iu.edu/bin/view/Trash/Trash/Trash/Trash/VirtualOrganizations/CompBioGrid_OSG][Blog now ready]]
      * VO-group, GOC, Sites groups to help prioritize.
   
   * !IceCube
      * Looking to understand storage solutions on OSG. Has been active at local GLOW campusgrid, and is now trying to expand to remote OSG sites. Likely, it can adopt an SRM usage model similar to D0.
      * To get input from OSG Storage, !IceCube has agreed to provide a document listing needs and requirements.
   
   * CDF
      * To formulate a plan for opportunistic storage usage, CDF will also try to provide a similar document for OSG Storage.
      
   * nanoHUB 
      * [carryover items in last week&#39;s minutes]
      

---++ Grid Operations Center (Rob Q.)

  * OIMv2 Released
      * New Installed Capacity fields available
      * More detailed list of sciences for VOs to choose
      * Several other pieces requested from collaborators [[http://osggoc.blogspot.com/2009/05/oimv2-released.html][Details]]
   * This release caused an short outage to the public ticket and submission interfaces (~15 minutes)
   * !MyOSG 1.2 Released 
      * Several minor bug fixes [[http://osggoc.blogspot.com/2009/05/myosg-12-release.html][Details]]
   * VORS Deprecation
      * Working with LIGO and Pegasus, looks like their needs are met by MyOSG, though they&#39;ve requested a new SRM probe. 
      * Keith at FNAL has been too busy to investigate, but hope to have free time soon.
      * Marco at ATLAS has what he needs.
      * We&#39;ve also been in contact with Steve Clark and Maxim at BNL.
   * BDII SLA has been approved by several members of CMS but is waiting for sign off from Ian Fisk and Miron
   * Ticket resolution rate graphs will be updated today to include May [[http://www.grid.iu.edu/reports/six_months_resolution_rates.jpg][Link]]


---++ Security (Mine)
