---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings

---++ Action/Significant Items:
   * Plan is to continue monitoring the BDIIs 

---++ Attendees:
   * Xin, Armen, Britta, Rob E., Suchandra, Burt, Marco, Abhishek, Rob Q., Chander, Dan
 
---++ CMS (Burt)
   * Computing: 210 khour/day, 95% success. CPU/wallclock at 55% (excluding T1: 85%).  I think I may have been summing daily averages for the CPU/wallclock number (including today&#39;s report) -- OK if the usage is constant, but it was highly variable this week.  I&#39;ll try to make this accurate for next week.
   * Storage: 3.1 PB xfer (T1), 85 TB (others)
   * Current queue of physics simulation results fulfilled. Enjoy your opportunistic cycles for now!
   * Ran some intense skim runs at the Tier 1 over the next week; may be reproducing this week.

---++ Atlas (Armen &amp; Xin)
   * General production status
      * During the last week USATLAS production was quite stable at the level of 8~10K running jobs, mainly MC jobs. 
   * Job statistics for last week. 
      * Gratia report: USATLAS ran 1.5M jobs, with CPU/Walltime ratio of 85%. 
      * Panda world-wide production report (real jobs): 
         * completed successfully 583K managed MC production, validation and reprocessing jobs 
         * average 83K jobs per day
         * failed 59K jobs
         * average efficiency:  jobs  - 91%,  walltime - 96%       
   * Data Transfer statistics for last week
      * Transfer rate stays the same as previous weeks. BNL T1 transferred ~75 TB/day data last week, with peak at 150 TB/day.  
   * Issues and GOC Tickets
      * GOC ticket 7772: Issues with WLCG BDII periodically loses information about some USATLAS Tier2 sites. 
      * Opening more USATLAS T2 sites to D0 VO as opportunistic storage:  no update this week. 


---++ LIGO (Britta, Rob E.)
   * 100k cpu hours/day
   * 8k..10k jobs/day
   * 25 sites for E@H
   * Gratia reports:
   *  Current week&#39;s total usage: 5 users utilized 37 sites
      * 39869 jobs total (34898 / 4971 = 87.5% success)
      * 395944.0 wall clock hours total (383453.0 / 12490.9 = 96.8% success)
   * Last week&#39;s total usage: 3 users utilized 33 sites
      * 2675 jobs total (2601 / 74 = 97.2% success);
      * 34.9 wall clock hours total (28.8 / 6.1 = 82.5% success);
 
   * E@H reports
      * last day: 1.58M credits
      * Recent Average Credit (RAC):  605k Last week: 470k
      * E@H rank based on RAC: 4 (+-0)
      * E@H rank based on accumulated Credits: 11 (+-0)
 
   * Robert is working on code changes required to expand to Fermilab sites and Sprace

 
---+++ Binary Inspiral
    
      * 3 day test work-flow on Firefly: 

      * Gap in data error ticket remains open

      * test run on different 3 data set succeeds
      
      * Submitted test run on one week of data

---++ Engage (Mats, John, Chris)


---++ Integration (Suchandra)
   * Working on OSG 1.2.6 release
      * In ITB testing
      * A few issues have appeared and are being investigated
   * Panda ITB framework
      * Have 2 sites accepting pilots, 2 more should be added soon
      * All 4 sites should be ready in time to run test jobs on the sites for current ITB testing round

---++ Site Coordination (Marco)
Note that this report lists the currently active resources in OSG.
If a site is down or not reporting it will not be counted.
Therefore there may be fluctuations.
   * Site update status (from !MyOSG as of today):
      * Most recent production version is OSG 1.2.5
      *       62 OSG 1.2.X resources (       7 are 1.2.5)
      *        9 OSG 1.0.X resources (       1 is 1.0.5)
      *       17 OSG 1.0.0 resources
      *        2 OSG 0.8.0 resources
         * OU_OCHEP_SWT2, tier2-01.ochep.ou.edu , Contact: Horst Severini
         * UIC_PHYSICS mstr1.cluster.phy.uic.edu , Contact: John Wolosuk


---++ Metrics (Brian)


---++ Grid Operations Center (Rob Q.)

---+++ Operations Last Week 
   * Last week&#39;s status history 
      * [[http://tinyurl.com/yejwd2j][GOC Services: BDII, MyOSG, RSV Collector]] 
      * [[http://tinyurl.com/ybo4sjd][GOC hosted Security services managed by OSG security team]]

---+++ Operations This Week
   * [[http://osggoc.blogspot.com/2010/01/goc-service-update-tuesday-january-26th.html][New ITB Releases]] this week of services set for production next Tuesday. 
      * Applied apache2 license
      Updated code so SC assignees are added FP ticket created for resource and VO registration (https://ticket.grid.iu.edu/goc/viewer?id=7850) 

---+++ Outstanding Tickets
   * [[https://ticket.grid.iu.edu/goc/viewer?id=7772][7772]] - ATLAS BDII Disappearances and BNL Monitoring
      * Testing from IUPUI to OSG BDII
         * Number of tests VS the OSG BDII: 43120
         * Number of failures VS OSG BDII: 30
         * Percentage of Failures: 0.06%
      * Testing from IUPUI to EGEE BDII
         * Number of tests VS the EGEE BDII: 43120
         * Number of failures VS EGEE BDII: 65
         * Percentage of Failures: 0.15%
   * [[https://ticket.grid.iu.edu/goc/viewer?id=7837][7837]] - WQCG-Harvard-OSG C,C++ Compiler Installation Request


---++ Virtual Organizations Group (Abhishek)

   * D0 MC production minimal; waiting on new D0 application software release. 
      * Workload very low in past 3 weeks; less than 1 M Evts/week.
         
   * SBGrid/NEBioGrid  
      * Immediate focus: throughput of how fast MM can match jobs to handle SBGrid&#39;s submission rate.
      * Sustained a new peak of 1200 simultaneous jobs. 
      * 12,000 wall hours/day at 64% efficiency. 
      * 60,000 jobs at 82% efficiency (OSG Gratia view), at 75% efficiency (SBGrid view).
      * Over last week, successfully used 57,000 wall hours.
      * Currently, investigating any patterns in job failures. 
         * Caltech and UNL sites have high job failure rates of 15-25%. 
         * Have requested access to accounting logs from Gratia team.
      
   * Fermi-VO 
      * 2 new subVOs: 
         * LBNE / Long Baseline Neutrino Experiment. URL -- http://lbne.fnal.gov/. 
         * !ArgoNeuT Experiment. URL -- http://t962.fnal.gov/
            * To expose a small-scale liquid argon time projection chamber (!LArTPC) to the !NuMI neutrino beam. 
            * Neutrino source is !NuMI (Neutrinos at the Main Injector). 
   
   * !CompBioGrid
      * Issue with firewall and CE on site upgrade from OSG 1.2.3 to 1.2.4. Investigation ongoing with VDT team.
      * Ticket -- https://ticket.grid.iu.edu/goc/viewer?id=7870
   
   * NYSGrid 
      * Site based on GPU cluster being used now in production. LIGO is an active user.
      * Portal under development. Based on HUBzero. 
      * HPC2: New York State High Performance Computing Consortium. URL -- http://hpc2.org/
   
   * GLUE-X
      * Site now up, being used by LIGO and SBGrid.
      * Issues: 
         * Site UCONN_OSG is not visible in !ReSS. Available in RSV.
         * Gratia accounting is not reporting usage.
   
   * !IceCube
      * Work ongoing to integrate and evaluate HTTP cache/Squid for data staging. Phone meeting being arranged.


---++ Security (Mine)
