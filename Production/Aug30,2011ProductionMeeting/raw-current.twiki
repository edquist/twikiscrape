-- Main.DanFraser - 05 Aug 2011
---++ Action/Significant Items:
   * The BNL Atlas Tier-1 was shut down for Hurricane Irene for roughly two days running Aug 27 - 29. This meant that data for the Tier-2s was also unavailable from the BNL FTS server. Overall US Atlas usage was down to a trickle during this time. (Xin)
   * This week we discovered a security problem in Apache that could result in a DNS attack. Biggest risk is a DoS attack against a site&#39;s GUMS server. We classified it as moderate-to-low level risk. Apache is running late on the patch. We will immediately announce when the release is ready. VDT team is ready to upgrade and release the patch when it is available. (Mine)
   * Teragrid had a security compromise this week. Do not know yet if it is bitcoin related or a brand new case. The compromised site also runs osg resources. We are still investigating as to whether or not OSG is affected.  (Mine)
   * Recently, the OSG display and Gratia graphs have been showing an overstated value for CPU hours because of a misconfiguration of the gratia probe at the Purdue Steele site (and I have opened a ticket to get this particular issue fixed).  The graph has included local users at Steele running with a !TeraGrid (dates: 8/24 to 8/26; userid TG-PHY100030; total error of 154K hours). It still looks like some TG jobs are showing up so this is still under investigation. (Chander)

---++ Attendees:
   * Xin, Armen, Burt, Marco, Kyle for Rob Q., Mine, Chander, Dan
 
---++ CMS (Burt)
   * LHC: currently no collisions for physics .. will recommission in a few days.
   * 405 khour/day, 92% success
   * CMS T1 had a scheduled downtime for power work in computer room.
   * glideinWMS 3.0 (cloud-capable) moving forward -- release by November?

---++ Atlas (Armen &amp; Xin)

   * General production status
      * LHC is in machine development and technical stop since last Tuesday. Will restart at the end of the week. Total collected luminosity for ATLAS now is 2.55fb-1. 
      * US ATLAS production during the week was stable, with mixture of simulation and reprocessing activities, up to Saturday when BNL went offline as a precaution due to hurricane. Late Monday back online. Reprocessing progress is quite good, without problems.
   * Job statistics for last week.      
      * Gratia report: USATLAS ran 2.6M jobs, with CPU/Walltime ratio of 85%. 
      * Real Jobs processed by US sites for last week, reported from PanDA monitor 
         * 1M 
   * Data Transfer statistics for last week
      * Data transfer rate was 300TB~400TB last week at BNL T1. 
   * BNL T1 shutdown due to hurricane Irene, Aug 27~29. 
   * Issues
      * OSG opportunistic access to USATLAS sites
         * GLOW VO: work in progress on MWT2/UTA/WT2, other T1/T2 sites already support it.    


---++ LIGO (Britta, Robert E.)

---+++ Gratia Reports

   * Current week&#39;s total usage: 3 users utilized 29 sites
      * 55139 jobs total (33250 / 21889 = 60.3% success)
      * 440940.9 wall clock hours total (264308.2 / 176632.8 = 59.9% success)
   * Previous week&#39;s total usage: 3 users utilized 29 sites
      * 58716 jobs total (42707 / 16009 = 72.7% success)
      * 337276.7 wall clock hours total (284102.9 / 53173.8 = 84.2% success)

---+++ LIGO / E@OSG

   * Recent Average Credit (RAC): 808,022.63851, Last Week: 892,703.27924
   * E@H rank based on RAC: 2 (+-0)
   * E@H rank based on accumulated credits: 2 (+-0)


---+++ LIGO/PULSAR
   * 50000 job dag submitted to frontend, running over 32 OSG sites, continually cleaning up file system that fills up on daily basis
   * Monitoring 5 work-flows resubmitted via Corral glidein service after cleaning up directories on hadoop file system

---++ OSG Operations (Rob Q.)

---+++ Operations Last Week 
   * [[http://tinyurl.com/3k3lqjh][GOC Services Availability/Reliability]]
   * [[http://myosg.grid.iu.edu/miscstatus/index?datasource=status&amp;count_sg_1=on&amp;count_active=on&amp;count_enabled=on][Current Status]]
   * TWiki moves to Bloomington host.
   * Production release, [[http://osggoc.blogspot.com/2011/08/goc-service-update-tuesday-august-23rd.html][release note]]
      * RSV-SAM Uploader, Minor update to the logging &amp; monitoring script
      * Gratiaweb, Updated graphtool RPM, ticket: [[http://jira.opensciencegrid.org/browse/METRICS-3][METRICS-3]]
   * !FermiGrid Ops
      * Slowdown in Display Queries due to Gratia Housekeeping - [[OSG Display Data Stale][Ticket]]
      * New version of Gratia which should fix these issues is still a few weeks away. 
   * WMS Glide In Factory
      * Successfully cloned UCSD factory configuration into ITB instance.  During testing we had no performance issues.
         * Submitted to ~160 cms glidein entry points
         * Submitted 2 test jobs to each cms entry
         * We peaked at 80 glideins running at one time with no problems


---+++ Operations This Week
   * Apache DOS - [[https://ticket.grid.iu.edu/goc/10917][Ticket]]
      * Expect a VDT Update this week
   * No meeting next Monday due to Holiday
   * Fifth Tuesday No Changes made this week
   *  WMS Glide In Factory
      * Plan to upgrade UCSD factory glideinWMS to version 2.5.2.
   * Investigating DNS Outage
      * From IU Messaging - &quot;The outage was caused by a bug in BIND, the DNS software we use.The typo revealed the bug. BIND is very good at not accepting a file with bad data. In this case BIND should have rejected the file because of the syntax error. We were able to identify the bug and reported it to ISC. ISC acknowledged it and said they would fix it in the next release.&quot;
      * We are waiting for more about Change Management Procedures. 


---+++ New VO Registrations
   * LBNE - Long-Baseline Neutrino Experiment
      * Previously a Fermigrid Sub-VO moving to full fledged VO. 


---++ Engage (Mats, John)


---++ Integration (Suchandra)


---++ Site Coordination (Marco)
Note that this report lists the currently active resources in OSG.
If a site is down or not reporting it will not be counted.
Therefore there may be fluctuations.
Each line has the current number and variation from last week in parenthesis.
You can find a table with current OSG and VDT versions at http://www.mwt2.org/~marco/myosgldr.php
   * Site update status (from !MyOSG as of today):
      * Most recent production version is OSG 1.2.21
      *       96 (1) OSG 1.2.X resources (       9 are 1.2.21)
      *        2 (0) OSG 1.0.X resources (       0 are 1.0.6)
      *        2 (0) OSG 1.0.0 resources


---++ VO and User Support (Chander)

Recently, the OSG display and Gratia graphs have been showing an overstated value for CPU hours because of a misconfiguration of the gratia probe at the Purdue Steele site (and I have opened a ticket to get this particular issue fixed).  The graph has included local users at Steele running with a !TeraGrid (dates: 8/24 to 8/26; userid TG-PHY100030; total error of 154K hours).  In this case the error induced was about 5-10% of the total. So the general question is how to keep the Gratia data reasonably accurate?  We need somebody who periodically looks at the gratia reports for “unexpected results” every so often and takes needed action to get the issue fixed.  I believe this belongs in Production.  


---++ Security (Mine)

   * Vulnerabilities/Incidents: 
      * Apache httpd vulnerability. Announcement is sent. Waiting for the official patch. Biggest risk is a DoS attack against a site&#39;s GUMS server. We classified it as moderate-to-low level risk. Apache is running late on the patch. We will immediately announce when the release is ready. VDT team is ready to upgrade and release the patch when it is available. 
      * Will follow up on bitcoin incidents. Contacted three sites so far. We will send more &quot;best practices&quot; and follow up with more sites. 
      * Teragrid had a compromise. Do not know yet if it is bitcoin related or a brand new case. The compromised site also runs osg resources. We will find out if osg is affected. 
   * CA layout migration. Atlas-BNL migrated CEs, GUMS and storage elements. No big problems so far except for a RSV probe issue. We have a solution in place. We will update the contents of the new CA-cache layout next Tuesday.  
   * A few tickets open regarding ca-cert scripts. Please open a ticket if you have a problem with existing cert scripts. 

---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings
