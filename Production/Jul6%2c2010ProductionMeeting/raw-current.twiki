-- Main.DanFraser - 07 Jun 2010
---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings

---++ Action/Significant Items:
   * All FNAL-based Gratia services will be down for up to 4 hours on Wed July 14 for OS and service upgrades. In addition, the previously announced decommissioning of the legacy redirector service will also take place at this time. (Chris)
   * The ITB BDII update will go into place later today to allow testing of SE-only systems. Testing &amp; documentation for adding the GIP to an SE-only install is currently in progress by the VDT &amp; Storage teams. (Rob, Dan)
   * Pending verification with the DZero team, it looks like the Monte carlo production has achieved a new record rate:
      * 16.4 M Evts/week. 112,000 wall hours/day at 91% efficiency. (Abhishek)

---++ Attendees:
   * Britta, Rob E., Chris, Brian, Suchandra, Tony, Marco, Mine, Dan (Lots of folks on vacation this week.)
 
---++ CMS (Burt)
   *  Job statistics for last week
      * ~53 khours/day
      * 36408 jobs/day
      * 92% success 
   * Transfer statisics for last week
      * ~430TB/day 

---++ Atlas (Armen &amp; Xin)

   * General production status
      * ATLAS data taking is continuing the same rate after the commissioning stop. Production level is still low, and still waiting for new production to be finalized and submitted. 
   * Job statistics for last week. 
      * Gratia report: USATLAS ran 2.7M jobs, with CPU/Walltime ratio of 66%. 
      * Panda world-wide production report (real jobs): 
         * completed successfully 173k managed MC production, validation and reprocessing jobs 
         * average 25K jobs per day
         * failed 15K jobs
         * average efficiency:  jobs  - 92%,  walltime - 88%
   * Data Transfer statistics for last week
      * BNL T1 data transfer rate last week was 200~400TB/day.
   * Issues
      * SAM test issue --- sam bdii under investigation
      * Publish SE only info to BDII --- GOC will enable the BDII change to allow test of the new CEMon/GIP package. 

---++ LIGO (Britta, Robert E.)
---+++ Gratia Reports
   * This week&#39;s total usage: 5 users utilized 44 sites
      * 271527 jobs total (122024 / 149503 = 44.9% success)
      * 2442581.3 wall clock hours total (1699311.8 / 743269.6 = 69.6% success)
   * Last week&#39;s total usage: 7 users utilized 43 sites
      * 283008 jobs total (110204 / 172804 = 38.9% success)
      * 2399701.5 wall clock hours total (1873355.8 / 526345.7 = 78.1% success)
---+++ LIGO / E@OSG
   * Recent Average Credit (RAC):  978,311.34280, Last week: 1,224,179.24924
   * E@H rank based on RAC: 2 (+-0)
   * E@H rank based on accumulated Credits: 4 (+-0)

---+++LIGO/INSPIRAL
   * Bug fix tested, waiting for approval to push
   * Trouble shooting USCMS-FNAL-WC1-CE3 fail

---++ Grid Operations Center (Rob Q.)

   * Rob is at the WLCG Collaboration meeting and will not be available. 
   * [[http://osggoc.blogspot.com/2010/07/goc-service-update-tuesday-july-13th-at.html][ITB Release]] done today. Will move to production next Tuesday. 
   * BDII SE Change will be in ITB today, but is not in above release note, as we are not sure of how long this will be in the ITB for testing. 

---++ Engage (Mats, John)


---++ Integration (Suchandra)
   * Waiting for xrootd changes in VDT
       * Should come in this week
   * [[https://twiki.grid.iu.edu/bin/view/SoftwareTeam/SEP13][Upcoming changes]]    

---++ Site Coordination (Marco)
Note that this report lists the currently active resources in OSG.
If a site is down or not reporting it will not be counted.
Therefore there may be fluctuations.
Each line has the current number and variation from last week in parenthesis.
You can find a table with current OSG and VDT versions at http://www.mwt2.org/~marco/myosgldr.php
   * Site update status (from !MyOSG as of today):
      * Most recent production version is OSG 1.2.11
      *       79 (1) OSG 1.2.X resources (       4 are 1.2.11)
      *        6 (0) OSG 1.0.X resources (       0 are 1.0.6)
      *        5 (-2) OSG 1.0.0 resources
      *        1 (0) OSG 0.8.0 resources
Site Coordination meeting this Thursday 7/8 at 11am central
   * Phone: 510-665-5437, #1212
   * Adobe connect: http://osg.acrobat.com/osgsc100708/
   * Special topic will be the upcoming OSG Site Administrators workshop
Site Administrators workshop - August 10-11 2010
   * http://indico.fnal.gov/conferenceDisplay.py?confId=3429
   * registration: http://indico.fnal.gov/confRegistrationFormDisplay.py?confId=3429


---++ Metrics (Brian)


---++ Virtual Organizations Group (Abhishek)

---+++ D0
   * Monte carlo production has possibly achieved a new record rate.
   * 16.4 M Evts/week. 112,000 wall hours/day at 91% efficiency.
   * Abhishek will confirm with Joel, Brad, Qizhong.

---+++ GLUE-X
   * Working to provision SRM based opportunistic storage (GLUE-X uses DCache).
   * Discussions moving forward between Richard and Jefferson lab computing division. Working on firewall matters and open port ranges. 

---+++ SBGrid
   * Malformed credential created problems at !FermiGrid resources. 
      * Fermilab VO reported possibility of banning the SBGrid credential to avoid interruption. 
      * Ticket: https://ticket.grid.iu.edu/goc/viewer?id=8831
      * Possibly rooted in use of Peter&#39;s personal proxy, glexec, and glideins.
      * Investigation ongoing.
   * !GlideinWMS progress report from previous week:
      * Ran jobs at 20 sites, reaching a peak of over 5000 jobs. 
      * Peak of 100,000 wall clock hours on June 24. 
      * SBGrid doesn&#39;t have access to information about failed pilot jobs; estimated rate of failed user jobs is less than 5%, and likely less than 1%. 
      * Several days of sustained 3000-4000 running jobs ( &gt;40K hours/day).
      * To get over 2000 jobs, heavily dependent on getting large batches of job slots at Firefly, FNAL, and UNESP.  If those sites are busy, there is much lower utilization. Expansion plan ongoing with Derek.

---+++ !GridUNESP
   * Ramping up, being used by other VOs in OSG, esp. LIGO and SBGrid.
   * Looking into MPI; discussion ongoing.

---++ Security (Mine)
