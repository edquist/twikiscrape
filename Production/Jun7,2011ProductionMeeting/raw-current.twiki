-- Main.DanFraser - 09 May 2011
---++ Action/Significant Items:
   * 

---++ Attendees:
   * (to be updated after the meeting) Mats, Xin, Armen, Britta, Robert E., Brian, Suchandra, Burt, Marco, Rob Q., Scott T., Mine, Chander, Dan
 
---++ CMS (Burt)
   * Machine: Progress, but with some issues.  &gt;1000 bunches reached, but many beam losses
   * 440 khr/day, 82% success rate.  A bit of a drop there -- don&#39;t understand it yet.
   * Firefox 4.0.1 SSL renegotiation feature starting to affect our users
   * Incompatibility between EGI gLexec and glideins -- not understood yet, but glideins failing at RAL (UK Tier 1)

---++ Atlas (Armen &amp; Xin)

   * General production status
      * Stable operation from LHC, and good accumulated luminosity during the past week. Continue operating with 1092 bunches for now. Additional 200pb-1 luminosity accumulated this week, bringing total collected luminosity for ATLAS to about 720pb-1.
      * US ATLAS production was quite stable at the average level of about 10-12k running jobs, mostly simulation.

   * Job statistics for last week. 
      * Gratia report: USATLAS ran 1.9M jobs, with CPU/Walltime ratio of 92%. 
      * Panda world-wide production report (real jobs): 
         * completed 1.1M managed group, MC production, validation and reprocessing jobs 
         * average 163K jobs per day
         * failed 93K jobs 
         * average efficiency:  jobs - 93%, walltime - 96%
      * Real Jobs processed by US sites for last week, reported from PanDA monitor 
         * 734K 
   * Data Transfer statistics for last week
      * BNL T1 data transfer rate was around 200~300TB/day in last week. 
   * Issues
      * OSG opportunistic access to USATLAS sites: 
         * HCC: working in progress on 4 T2 sites (BU, HU, WT2).
         * Engage is the next VO that we will help run on USATLAS resources. Conf. call is set up to discuss support issues and requirements. 
      * update of LFC in VDT/OSG client packages : preliminary version under testing

---++ LIGO (Britta, Robert E.)

   * Britta on vacation next week!

---+++ Gratia Reports
   * Previous week&#39;s total usage: 4 users utilized 32 sites
      * 51258 jobs total (36150 / 15108 = 70.5% success)
      * 230962.0 wall clock hours total (188672.5 / 42289.5 = 81.7% success)
   * Current week&#39;s total usage: 3 users utilized 32 sites
      * 95913 jobs total (54846 / 41067 = 57.2% success) 
      * 428659.8 wall clock hours total (366812.5 / 61847.3 = 85.6% success)

---+++ LIGO / E@OSG
   * Recent Average Credit (RAC):  893,204.35576
   * E@H rank based on RAC: 2 (+1)
   * E@H rank based on accumulated credits: 3 (+-0)


---+++ LIGO / INSPIRAL
   * Monitoring work-flow at LIGO_CIT, NotreDame, CIT_CMS_T2
   * Observing memory allocation error at FF
   * Resolved python library issue that occurred after cluster upgrades

---+++ LIGO/PULSAR
   * Ramping up!
      * Now running individual Powerflux dags (50,000 jobs) at USCMS-FNAL-WC1-CE3, GridUNESP_CENTRAL, LIGO_UWM_NEMO, Purdue-RCAC, Firefly
      * Expecting to expand to more sites
      * trouble shooting gsiftp server issues at AGLT2
   * Monitoring  large (100,000 job) dag that is running at 4 &quot;Powerflux sites&quot; UFlorida-PG, UCSDT2, Nebraska, LIGO_CIT

---++ Grid Operations Center (Rob Q.)
---+++ Operations Last Week 
   * [[http://tinyurl.com/27fknc6][GOC Services Availability/Reliability]]
   * [[http://myosg.grid.iu.edu/miscstatus/index?datasource=status&amp;count_sg_1=on&amp;count_active=on&amp;count_enabled=on][Current Status]]
   * Short week (Memorial Day), 5th Tureday of May, no changes
   * New !GlideIn Factory Hardware Ordered
      * And Reordered this week
   * Security Review, 1-2/Jun. Few action items, requested documentation.
   * New VO Package Sent to ITB for testing 
      * Removal of JDEM
      * Addition of NEES
   * GGUS ALARM test went well for BNL/FNAL
   * CERN BDII Upgrade seems stable. 
      *    &lt;img src=&quot;https://twiki.grid.iu.edu/twiki/pub/Operations/Minutes2011June06/Picture_9.png&quot; alt=&quot;Picture_9.png&quot; width=&#39;511&#39; height=&#39;363&#39; /&gt;    
   * Fermigrid Operations
      * Sat. May 28, ReSS lost all classad information due to temporary OIM database outage, filed GOC ticket, put workaround to bring ReSS back within 1 hour. OIM db was restored a few hours later. 
      * ReSS developers have been requested to transition to MyOSG URL instead of deprecated OIM public view URL.
   * WMS Glide In Factory
      * Tuesday May 31 upgraded glideins to run Condor 7.6.0 on the worker nodes.

---+++ Operations This Week
   * New VO Package Release Tomorrow
      * Removal of JDEM
      * Addition of NEES
   * ITB release
      * RSV: Relocation of tables and modification of queries
      * OIM: Minor change to make ticket templates configurable
      * MyOSG, Ticket: Cosmetic changes.
      * BDII: Change to XML for status report. (No change to BDII Service itself)
   * Discuss elimination the &quot;Troubleshooting&quot; web from TWiki
   * New [[http://insideosgops.blogspot.com/][Inside OSG Ops]] Blog
      * [[http://soichi.grid.iu.edu/planet/][Consolidated OSG Blog]] 
      * This Service Operated with no SLA 

---++++ Gratia and !ReSS (Represented by !FermiGrid Ops)
   * Half of our machines moving between buildings tomorrow 6/7/11, HA should keep all OSG services up.
---++++ WMS Glide In Factory

---++ Engage (Mats, John)


---++ Integration (Suchandra)
   * Tested VO package release last week
   * Continuing ITB testing
      * [[http://vdt.cs.wisc.edu/releases/2.0.0/release-p27.html][VDT update information]]
      * Primarily changes to fulfill CMS requests:
         * Renicing gatekeeper
         * Random sleep for gatekeeper
         * Condor jobmanager support for accounting groups
         * Cleanup script for user accounts
      * Other changes include:
         * Bestman/Bestman2 updates
         * SGE related improvements
      * Investigating load issues on gatekeepers

---++ Site Coordination (Marco)
Note that this report lists the currently active resources in OSG.
If a site is down or not reporting it will not be counted.
Therefore there may be fluctuations.
Each line has the current number and variation from last week in parenthesis.
You can find a table with current OSG and VDT versions at http://www.mwt2.org/~marco/myosgldr.php
   * Site update status (from !MyOSG as of today):
      * Most recent production version is OSG 1.2.19
      *       95 (3) OSG 1.2.X resources (      29 are 1.2.19)
      *        2 (0) OSG 1.0.X resources (       0 are 1.0.6)
      *        1 (0) OSG 1.0.0 resources
      *        0 (0) OSG 0.8.0 resources
Doodle poll to about possible dates for the site admin workshop and user forum:
   * http://www.doodle.com/etarxmfpcua7eg7e
Site coordination meeting this week, 6/9
&lt;!--   * Special topic: Campus grids --&gt;
   * SiteCoordination.SitesCoord110609
   * Phone: # 866-740-1260, code 8349885#
   * Adobe connect: http://osg.acrobat.com/osgsc110609/ 


---++ VO &amp; User Group (Chander)

SURAGrid reports that users are having good success getting their sites online using OSG  documentation.  SURAGrid has 17 resource contributors; 3 sites are already OSG sites; 3 sites actively working on converting to OSG.


---++ Security (Mine)
   * The security controls with GOC completed. Went very well. A few recommendations. Will prepare a report on the results for all OSG service before the July retreat.
      * Other production service owners on this call please take a look at the questionnaire I sent to you. I need answers by the end of June. 
   * WLCG Incident drill is completed. WE did not have any major issues during the drill. Leif from EGI is leading the grading of sites. Barlow will meet with him after June 20th to review the grading of OSG site. They need time until June 20th. 
   * Anand is back and we re-started the certificate migration work. GOC will set up a new CA cache with new hashes. They will maintain both caches. First it will get into IB test cycle and then be released. (2-3 weeks) Once new cache is active, we gradually move sites and VOs. 
      * VDT CA cache (only serving plain IGTF CAs) will also be moved to GOC. VDT will put a redirect. VDT customers will still get the plain-IGTF CAs. But VDT folks would not have run a operational service
   * New tickets and problems with VOMS/VOMRS. If you hear user complaints on voms-proxy-init, open a ticket with goc. I am aware of ongoing problems. These are different than problems we had 2-3 weeks ago. 
   * Old VOMS-admin upgrade issue. What does dites think about migrating to new version of VOMS-Admin? Alain thinks a patch can be made by teh end of August.
    


---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings
