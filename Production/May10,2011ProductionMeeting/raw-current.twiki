-- Main.BrittaDaudert - 09 May 2011

---++ Action/Significant Items:
   * CMS recorded 500 khour/day last week.   That might be a record. (Burt)
   * BNL found a problem with propagating site downtime info to GOCDB from OSG OIM, reported to OSG GOC. A ticket has been filed and Rob&#39;s team is investigating. (Xin)
   * LIGO E@H still ramping up. Robert is moving cautiously to ensure there are no new issues arising.
   * Past issues with slowdowns in the BDIIs have been concretely correlated to network problems. Network problems have been solved by moving the BDIIs out from behind the IU firewall. Now we are exploring the possibility of re-purposing the IS4 hardware for the third BDII. Data and past history indicate that we can consistently meet the SLA with two BDIIs.

---++ Attendees:
   * Xin, Armen, Britta, Robert E., Suchandra, Burt, Marco, Rob Q., Mine, Dan
 
---++ CMS (Burt)
   * 500 khour/day, 94% success.   That might be a record.
   * 25 nodes made available to preemptable HTPC computing (as opposed to HTPC jobs only getting scheduled if a machine is free already)
   * Running into new challenges with pile-up (coming close to memory limits)
   * glideinWMS deployment at CERN is nearly ready

---++ Atlas (Armen &amp; Xin)

   * General production status
      * LHC since last Tue was doing beam studies and is in technical stop now.Will be back in operation Thu. Integrated luminosity is ~270pb-1 (same as last week).
      * US ATLAS production was quite stable at the average level of about 10-12k running jobs, mostly simulation. Waiting for new Geant4 re-simulation campaign of all existing MC samples with new software release. Probably will be ready to start next week. Reconstruction step to be done during summer. 
   * Job statistics for last week. 
      * Gratia report: USATLAS ran 2.1M jobs, with CPU/Walltime ratio of 91%. 
      * Panda world-wide production report (real jobs): 
         * completed 1.1M managed group, MC production, validation and reprocessing jobs 
         * average 165K jobs per day
         * failed 98K jobs 
         * average efficiency:  jobs - 92%, walltime - 95%
      * Panda jobs processed, as reported by Panda monitor, on USATLAS sites:
         * 950K panda jobs processed for last week. 
   * Data Transfer statistics for last week
      * BNL T1 data transfer rate was around 300~350TB/day in last week. 
   * Issues
      * OSG opportunistic access to USATLAS sites: 
         * HCC: running at MWT2_IU an d OSCER, working in progress on other sites.
      * Problem with propagating site downtime info to GOCDB from OSG OIM, reported to OSG GOC. 

---++ LIGO (Britta, Robert E.)
---+++ Gratia Reports
   * Previous week&#39;s total usage: 5 users utilized 34 sites
      * 39556 jobs total (14412 / 25144 = 36.4% success)
      * 254621.3 wall clock hours total (128106.9 / 126514.4 = 50.3% success)
   * Current week&#39;s total usage: 5 users utilized 37sites
      * 26522 jobs total (23278 / 3244 = 87.8% success) 
      * 116448.8 wall clock hours total (106535.3 / 9913.5 = 91.5% success)

---+++ LIGO / E@OSG
   * Recent Average Credit (RAC): 217,482.27536,  Last Week: 271,134.36499
   * E@H rank based on RAC: 6 (-2)
   * E@H rank based on accumulated credits: 3 (+-0)


---+++ LIGO / INSPIRAL
   *  trouble shooting failed 1 week work-flows at FF, OUHEP_OSG

---+++ LIGO/PULSAR
   * trouble shooting held jobs 

---++ Grid Operations Center (Rob Q.)

---+++ Operations Last Week 
   * [[http://tinyurl.com/27fknc6][GOC Services Availability/Reliability]]
   * [[http://myosg.grid.iu.edu/miscstatus/index?datasource=status&amp;count_sg_1=on&amp;count_active=on&amp;count_enabled=on][Current Status]]
   * New VO Pacakge
      * [[https://twiki.grid.iu.edu/bin/view/Operations/PackageV36 ][Change Log]]
      * [[http://osggoc.blogspot.com/2011/05/new-vo-package.html][Notification]]
   * ITB Service Update
      * [[http://osggoc.blogspot.com/2011/05/goc-service-update-tuesday-may-10th-at.html][Notification]]
      * !GatheredAt RSV info now published in !MyOSG
   * SURAGrid AHM Support went well. 
   * Operations Presentation to Columbia Grid School
   * Approved funding for hardware for Glide-In Factory at IU 
   * Fermi Network Outage 
       * [[http://osggoc.blogspot.com/2011/05/gratia-outage-resolved.html][Notification]]

---+++ Operations This Week

   * IS4
      * Now that the network issues are resolved (by moving out from behind the IU firewall) we&#39;d like to return IS4 to it&#39;s original purpose. &lt;br&gt;&lt;br&gt;
     &lt;img src=&quot;https://twiki.grid.iu.edu/twiki/pub/Operations/ChangeMinutesApr19/after2.png&quot; alt=&quot;after2.png&quot; width=&#39;570&#39; height=&#39;645&#39; /&gt;  
   * Production Release on Tuesday 
      * [[http://osggoc.blogspot.com/2011/05/goc-service-update-tuesday-may-10th-at.html][Notification]
   * osg_ops_status email list used anymore?
   * WMS Glide In Factory
      * Upgrade Condor on Factory to 7.6.0 tomorrow, May 10
      * osg-gfactory-announce@physics.ucsd.edu should be subscribed to for Notification about UCSD Glide-In factory

---++ Engage (Mats, John)


---++ Integration (Suchandra)
   * OSG Testing
      * Waiting for VDT development to finish and release of new test candidate
      * [[http://vdt.cs.wisc.edu/releases/2.0.0/release-p27.html][Tentative changes]]
   * HTPC
      * Waiting for further testing work

---++ Site Coordination (Marco)
Note that this report lists the currently active resources in OSG.
If a site is down or not reporting it will not be counted.
Therefore there may be fluctuations.
Each line has the current number and variation from last week in parenthesis.
You can find a table with current OSG and VDT versions at http://www.mwt2.org/~marco/myosgldr.php
   * Site update status (from !MyOSG as of today):
      * Most recent production version is OSG 1.2.19
      *       93 (-2) OSG 1.2.X resources (      23 are 1.2.19)
      *        1 (-2) OSG 1.0.X resources (       0 are 1.0.6)
      *        1 (1) OSG 1.0.0 resources
      *        0 (0) OSG 0.8.0 resources
Site coordination meeting this week, 5/12
   * Special topic: What is new in Condor 7.6 and feature highlights
   * SiteCoordination.SitesCoord110512
   * Phone: # 866-740-1260, code 8349885#
   * Adobe connect: http://osg.acrobat.com/osgsc110512/ 




---++ Virtual Organizations Group (Chander)


---++ Security (Mine)
   * No incidents/serious vulnerabilities. Oak Ridge Incident has been found to have no effect on teraGrid resource at Oak ridge. 
   * WLCG Mgmt board wants to perform a security drill against panda submission mechanism. The target date is start of the drill May 23 -- end of the drill: May 28th. 
      * We notified us-atlas mgmt whether they want to participate. We have a list of us-atlas sites WLCG security team has proposed to include in the drill. We will also check with the proposed site manager&#39;s on their availability. 
      * Within the security team, we are evaluating whether we can get ready given we have a month. We are creating a list of items that will not get done if we decide to participate in the drill. I will send the list to ET. We will also ask WLCG whether we can perform the drill at a later time if we decide we cannot get ready.
   * I reported before on migrating our certificate cache to new layout and informed production sites that we will ask them to test. Unfortunately this work is delayed. Anand is in India due to death in the family. 
   * I received trouble tickets on contacting DOEGrids web site. The issue is the re-negotiation failure. It only affects firefox version 4 clients. the browser has tighter security configurations. There is a workaround posted. Please open tickets if you have issues. We are working with DOEgrids to find out if they can solve the problem from the server end.   
---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings
