-- Main.DanFraser - 10 Mar 2011
---++ Action/Significant Items:
   * There was a 4-hour outage at the DOE Grids CA on Friday. Mine is working on a follow up plan.
      * Services were restored late Friday evening (about 22:30 EST). OSG was not notified until Monday that this service was stable. [[http://osggoc.blogspot.com/2011/04/doegrids-services-outage-update-goc_04.html][Notification]]
      * Users need to resubmit any cert requests made during this period.
   * GOC is planning to move services outside the IU firewall since the internal network performance is significantly degraded.
   * BDII #3 was rebuilt using a 32bit OS and the seg faults have gone away. Plan to put this in Round Robin at the next change cycle (Rob)
   * Burt noted (again) several important LHC fixes needed in the VDT. Dan to make sure this is on Alain&#39;s short term radar after the WN_Client.
   * HTPC still waiting for a test job to integrate. Dan to follow up.

---++ Attendees:
   * Xin, Britta, Suchandra, Burt, Marco, Rob Q., Mine, Chander, Dan
 
---++ CMS (Burt)
   * Machine: in scrubbing mode -- roughly 5 more days to go before focus on collisions
   * 350 khour/day, 91% success

---++ Atlas (Armen &amp; Xin)

   * General production status
      * LHC is recovering from the technical stop, and preparing for the collisions (no collisions since last Monday). 
      * US ATLAS production level still not very high. Waiting for new MC tasks to be defined, as well as reprocessing of cosmic ray data, which may start today. 
   * Job statistics for last week. 
      * Gratia report: USATLAS ran 3.2M jobs, with CPU/Walltime ratio of 74%. 
      * Panda world-wide production report (real jobs): 
         * completed 619K managed group, MC production, validation and reprocessing jobs 
         * average 88K jobs per day
         * failed 72K jobs 
         * average efficiency:  jobs - 90%, walltime - 95%
   * Data Transfer statistics for last week
      * BNL T1 data transfer rate was around 200~400TB/day in last week. 
   * Issues

---++ LIGO (Britta, Robert E.)

---+++ Gratia Reports
   * Last week&#39;s total usage: 3 users utilized 26 sites
      * 34232 jobs total (32649 / 1583 = 95.4% success)
      * 421768.8 wall clock hours total (415895.9 / 5872.9 = 98.6% success)
   * This week&#39;s total usage: 3 users utilized 32 sites
      * 26466 jobs total (20288 / 6178 = 76.7% success)
      * 284804.2 wall clock hours total (244272.9 / 40531.2 = 85.8% success)


---+++ LIGO / E@OSG
   * Recent Average Credit (RAC): 461,452.67363, Last Week: 653,802.55289 
   * E@H rank based on RAC: 3 (+-0)
   * E@H rank based on accumulated credits: 3 (+-0)


---+++ LIGO / INSPIRAL
   * transferred 1 week of data (0.14) TB to Nebraska
   * work-flow submitted

---+++ LIGO/PULSAR
   * running two large work-flows (&gt;10000 jobs) via GlideinWMS on OSG (4 sites, pre staged data)

---++ Grid Operations Center (Rob Q.)

---+++ Operations Last Week 
   * [[http://tinyurl.com/27fknc6][GOC Services Availability/Reliability]]
   * [[http://myosg.grid.iu.edu/miscstatus/index?datasource=status&amp;count_sg_1=on&amp;count_active=on&amp;count_enabled=on][Current Status]]
   *  Fifth Tuesday, no release.
   * New VO Package to production
      * CSIU Addition, CMS Requested Change, and Engage Group Add
   * Rebooted ReSS servers, everything went well
   * WMS Glide In Factory
      * New Frontend Status
         * NWICG (Stephen Harrel - Purdue) - Is now set up to submit glideins to 20 entries. These have not yet been used.
      * Derek the HCC frontend admin at UNL reported that numbers are not correctly adding up in the daily analyze_entries reports e-mail we send to our frontends.  Igor found wrote a patch and submitted it to glideinWMS.  It was due to inadequate exception handling when parsing the condor logs
      * Discovered an edge case when glideins are preempted on sites they may incorrectly be reported as failing to start even though they have run jobs.  GlideinWMS development team was notified and Burt and Parag are troubleshooting it.

---+++ Operations This Week
   * DOEGrids CA Services Down Friday - [[http://osggoc.blogspot.com/2011/04/doegrids-services-outage-update-goc.html][Notification]]
      * Services were restored late Friday evening (about 22:30 EST). OSG was not notified until Monday that this service was stable. [[http://osggoc.blogspot.com/2011/04/doegrids-services-outage-update-goc_04.html][Notification]]
      * Please resubmit any cert requests made during this period.
      * Mike Helm wants to perform a maintenance this week and perhaps a subsequent regular scheduled maintenance window.
   * ITB Services release Tuesday
      * State Optional in OIM
      * MyOSG / Gip Validator Consolidator
      * Made changes to the top level wlcg bdii monitor script so that BDII entries are loaded one at a time instead of all at once in order to prevent timeout issue caused during low throughput events of IU network.
   * BDII at is4.grid.iu.edu was reinstalled with a 32-bit OS. 
      * Our testing shows the seg faults have gone away, however we will watch closely when this is returned to RR next Tuesday. 
   * All services to be moved outside IU institutional firewall.
      * Testing has proven that the institutional firewall substantially slows service.
   * Gratia and !ReSS (Represented by !FermiGrid Ops)
      * Short network maintenance today, HA services will mean no effect.

---++ Engage (Mats, John)


---++ Integration (Suchandra)
   * Testing
      * Working on new VDT updates
      * Updating documentation
   * HTPC updates:
      * Waiting for test jobs

---++ Site Coordination (Marco)
Note that this report lists the currently active resources in OSG.
If a site is down or not reporting it will not be counted.
Therefore there may be fluctuations.
Each line has the current number and variation from last week in parenthesis.
You can find a table with current OSG and VDT versions at http://www.mwt2.org/~marco/myosgldr.php
   * Site update status (from !MyOSG as of today):
      * Most recent production version is OSG 1.2.19
      *       86 (-2) OSG 1.2.X resources (       5 are 1.2.19)
      *        3 (0) OSG 1.0.X resources (       0 are 1.0.6)
      *        2 (0) OSG 1.0.0 resources
      *        0 (-1) OSG 0.8.0 resources
Site coordination meeting next week, 4/14 


---++ Virtual Organizations Group (Chander)

We are working with SURAGrid to make available DOE Grids certificates. 
We are now organizing a Registration Authority within the CA. Identified 
1st-level sponsor. SURAGrid is now working on identifying site-level 
sponsors.

Also expecting to roll-out a requirements gathering poll to VOs in May; as input for OSG year6 (starting Oct 2011)

---++ Security (Mine)
   * Important Operational Item: DOEGrids CA plans a scheduled outage on Wed 13 Apr 2011 The time period is 1201 pm - 4 pm PT. Mike Helms states that &quot;All services on pki1.doegrids.org will be affected. CRLs are not affected. There are no externally visible changes planned -- internal status monitoring and service management changes.&quot; If we do not object, then GOC should send an announcement today or tomorrow at the latest.
   * DOEgrids service outage was the most alarming operational item last week.  Services are back to normal. There will be more work and analysis on this. 
   * Production testing of the new certificates. Security team has finished their portion. We are waiting for other teams to review and approve our work. If you are helping with this work, please come to the TH meeting at 4 pm.
   * Jim Barlow is out on TeraGrid work (April 4-7). Anand will be out next week Th-Fri.  
   * Incidents/Vulnerabilities
      * No incidents or vulnerabilities reported. 
      * Sent a follow up notice to all dcache sites. No one asked for additional help. 
   * Bugs/Problems: 
      * Host certificate profile ticket has been resolved completely. There were two remaining ticket holder other than Suchandra. Their problems are also fixed. 
   * Routine issues:
      * We are getting RA Agents together for reviewing the processes. Routine bi-annual meetings.   
      * A policy on service certificate usage in OSG has been completed. We have been getting a lot of inquiries on this. We had discussed and determined our policy a while ago. We decided to turn them into a proper policy statement for general use. We will send this to Executive Board for approval.       




---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings
