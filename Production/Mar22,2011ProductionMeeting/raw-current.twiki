-- Main.DanFraser - 10 Mar 2011
---++ Action/Significant Items:
   * 

---++ Attendees:
   * Xin, Armen, Britta, Robert E., Suchandra, Burt, Marco, Rob Q., Mine, Chander, Dan
 
---++ CMS (Burt)
   * Machine: LHC back up with proton-proton running
   * 341 khour/day, 91% success
   * Tier 1 priorities reconfigured (CMS production &gt;&gt; CMS analysis &gt;&gt; opportunistic); this is working
   * Change to gums.template to support /cms/Role=cmsphedex (global file transfer roles)
   * gLexec deployment in OSG does not copy/set X509_USER_PROXY to gLexec&#39;ed user.  &lt;nop&gt;GlideinWMS handles this, but other gLexec users may be surprised

---++ Atlas (Armen &amp; Xin)

   * General production status
      * LHC progress continues - increase of the number of bunches and intensity. At the moment luminosity back to the level of last year. 12pb-1 collected so far. ATLAS production was quite stable during the week at the average level of 12k running jobs. It was mixture of Heavy Ion data reprocessing at T1 and simulation jobs at T2s. HI reprocessing is progressing quite well.
   * Job statistics for last week. 
      * Gratia report: USATLAS ran 2.1M jobs, with CPU/Walltime ratio of 92%. 
      * Panda world-wide production report (real jobs): 
         * completed 1.2M managed group, MC production, validation and reprocessing jobs 
         * average 167K jobs per day
         * failed 85K jobs 
         * average efficiency:  jobs - 93%, walltime - 96%
   * Data Transfer statistics for last week
      * BNL T1 data transfer rate was around 200TB/day in last week. 
   * Issues
      * Recalculation of BNL site availability and reliability, with GOC and WLCG  -- GGUS ticket opened to trace its progress :
         https://gus.fzk.de/ws/ticket_info.php?ticket=68768

---++ LIGO (Britta, Robert E.)
---+++ Gratia Reports
   * Previous week&#39;s total usage: 4 users utilized 21 sites
      * 74775 jobs total (60156 / 14619 = 80.4% success)
      * 781844.0 wall clock hours total (727948.8 / 53895.2 = 93.1% success)

   * Current week&#39;s total usage:  users utilized  sites
      * 
      * 

---+++ LIGO / E@OSG
   * Recent Average Credit (RAC): 
   * E@H rank based on RAC: 
   * E@H rank based on accumulated credits: 

---+++ LIGO / INSPIRAL

   * I (Britta) am on vacation this week

---++ Grid Operations Center (Rob Q.)
---+++ Operations Last Week 
   * [[http://tinyurl.com/27fknc6][GOC Services Availability/Reliability]]
   * Change in use of puppet on ITB machines to clear memory issues related to puppetd
   * ITB release, [[http://osggoc.blogspot.com/2011/03/goc-service-update-tuesday-march-22-at.html][Release notes]]
      *changes in MyOSG and GOC ticket to allow ticket searches from MyOSG
      * TWiki configuration change to allow large file upload, will only go to production if cleared by security team before Prod Release date 
   * GOC TX to address &quot;binary character issue&quot; 

---+++ Operations This Week
   * Production release [[http://osggoc.blogspot.com/2011/03/goc-service-update-tuesday-march-22-at.html][Release notes]]
      * IS4 Now in RR with IS1 and IS2
   * Ticket Exchange Call with BNL
      * Should TX support attachments?
      * Extra alerting on failure cases.
   * New VO Package to ITB Today
      * CSIU Addition, CMS Requested Change, and Engage Group Add
      * Release targeted for next Tuesday
   * No release next week, 5th Tuesday.

---++ Engage (Mats, John)


---++ Integration (Suchandra)
   * ITB testing ongoing
      * [[http://vdt.cs.wisc.edu/releases/2.0.0/release-p26.html][Changes for OSG 1.2.19]]
      * In ITB testing,  tentatively scheduling for next tuesday (March 29)
      * Troubleshooting RSV probe issues and timing
   * HTPC
      * Waiting for payload or test job to run against ITB sites

---++ Site Coordination (Marco)
Note that this report lists the currently active resources in OSG.
If a site is down or not reporting it will not be counted.
Therefore there may be fluctuations.
Each line has the current number and variation from last week in parenthesis.
You can find a table with current OSG and VDT versions at http://www.mwt2.org/~marco/myosgldr.php
   * Site update status (from !MyOSG as of today):
      * Most recent production version is OSG 1.2.18
      *       94 (3) OSG 1.2.X resources (      13 are 1.2.18)
      *        2 (-1) OSG 1.0.X resources (       0 are 1.0.6)
      *        2 (0) OSG 1.0.0 resources
      *        1 (0) OSG 0.8.0 resources


---++ User Support (Chander)
SURAGrid plans to join as a VO (sites and users); more details will be forthcoming and reviewed at the VO Forum call.


---++ Security (Mine)
   * Production testing of the new certificates are under planning. We wrote full directives on how a site admin should conduct the tests. 
   * Important operational test: We made a test of incident response process over the weekend. We discovered several issues. We will follow up with GOC on this important issue. 
   * DOEgrids CA is getting ready to change their CA software. This is an important change item that will affect OSG RA infrastructure. We took a look at the new test service and identified several differences from the older version. DOEgrids had trouble keeping the test service instances-- they crashed. They are re-building the test service. We will inform you as we learn more from them.    
   * Attacks/Incidents/Vulnerabilities:
      * A lot of ssh attacks and Trojan activity. Nothing targeted towards the grid. Nevertheless, CERN security team and REN-ISAC decided to encourage sites to report the incidents to the law enforcement. We are working on what type of an announcement should OSG send out the our sites. We will focus on technical information.
      * No severe vulnerabilities. A few kernel level exploits were reported last week but none has escalated to the root. 
      * No sites reporting to Pakiti seems to have a high level exploit.  
   * Bugs/errors/support tickets: 
      * GOC ssl re-negotiation ticket is closed. Security team evaluated the proposed solution and approved it.
      * DOEgrids host certificate problems: WE found the problem for one type of certificate type. Suchandra will get a new personal certificate. For other people, we understand the problem is different. WE are creating separate tickets and continue to debug.
   * RA ticket metrics. We are analyzing the ticket lifetimes on a per ticket basis weekly. We are setting up meetings with RA Agents to go over the process.  
   * Training: Igor sent out the security survey to site security contacts as we reported at last week. We received 6 responses so far. We are discussing what best ways to follow up on this work item. 
   * Items in waiting: SBgrid requested an evaluation of their authentication portal. Xrootd requested an evaluation of their authentication mechanism. 
   

---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings
