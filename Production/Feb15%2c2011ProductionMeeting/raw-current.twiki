-- Main.DanFraser - 08 Feb 2011

---++ Action/Significant Items:
   * Sites that upgraded quickly to the latest 1.2.17 were incorrectly reporting status (as &quot;unknown) to the WLCG. An announcement was sent out encouraging sites to wait until ..18 where a fix is in progress.
   * Upgrading to the latest kernel patches requires a reboot. GOC services will upgrade during the Production maintenance time next Tuesday. An 8-hour maintenance window has been approved to make sure there is time to get all the machines upgraded.

---++ Attendees:
   * Xin, Armen, Britta, Robert E., Brian, Suchandra, Marco, Rob Q., Scott T., Chander, Dan
 
---++ CMS (Burt)


---++ Atlas (Armen &amp; Xin)

   * General production status
      * LHC hardware commissioning will finish by the end of the week, first beam expected Saturday, starting beam commissioning period.
      * ATLAS production was relatively stable during the week at the average level of 10-12k running jobs, mainly simulation jobs. 
   * Job statistics for last week. 
      * Gratia report: USATLAS ran 2.2M jobs, with CPU/Walltime ratio of 85%. 
      * Panda world-wide production report (real jobs): 
         * completed 1.5M managed group, MC production, validation and reprocessing jobs 
         * average 215K jobs per day
         * failed 88K jobs 
         * average efficiency:  jobs - 95%, walltime - 96%
   * Data Transfer statistics for last week
      * BNL T1 data transfer rate was around 200~400TB/day in last week. 
   * Issues
      * RSV issues in the new OSG release caused lower WLCG availability and reliability for BNL T1. Rolled back to previous OSG release. Needs help from GOC to correct the RSV numbers for the last several days, before WLCG report is out for the month. 
      * Downtime info was resent by GOC to WLCG, to correct the WLCG site availability report for last month. 
      * Open more job slots for OSG jobs at BNL T1 : in progress. 

---++ LIGO (Britta, Robert E.)

---+++ Gratia Reports
   * Current week&#39;s total usage: 5 users utilized 30 sites
      * 77816 jobs total (56476 / 21340 = 72.6% success)
      * 1253664.7 wall clock hours total (1167349.7 / 86315.0 = 93.1% success)
   * Previous week&#39;s total usage: 4 users utilized 27 sites
      * 79252 jobs total (56278 / 22974 = 71.0% success)
      * 1388021.0 wall clock hours total (1288530.4 / 99490.5 = 92.8% success)


---+++ LIGO / E@OSG
   * Recent Average Credit (RAC): 2,256,946.65001, Last Week: 2,110,858.18624
   * E@H rank based on RAC: 1 
   * E@H rank based on accumulated credits: 3 (+-0)

---+++ LIGO / INSPIRAL

   * closed gratia ticket concerning OSG metrics report
   * generated plots for ihope runs at LIGO_CIT, NotreDame: 
   * trouble shooting 7 day data set plotting dag fails
  
---++ Grid Operations Center (Rob Q.)

---+++ Operations Last Week 
   * [[http://tinyurl.com/27fknc6][GOC Services Availability/Reliability]]
   * [[http://tinyurl.com/35zl55c][Security Services Availability/Reliability]]
   * [[http://osggoc.blogspot.com/2011/02/goc-service-update-tuesday-february-8th.html][Service Updates]] Tuesday February 8th.
   * [[http://osggoc.blogspot.com/2011/02/osg-1217-release-notification.html][OSG 1.2.17 Release]]
   * WMS Glide In Factory
      * enabled support for new frontend:
      * glowVO - requested for use with HTPC support

---+++ Operations This Week
   * ITB Operations Services release this week
   * GOC Ticket 1.33
   * Will install overhauled authentication module in TWiki to implement FNAL certs fix.
   * OS patches on ITB instances, a reboot is requied.
   * Problems with RSV in 1.2.17, some sites incorrectly reported as unknown.
      * Working to correct the RSV reports
   * working on setting up two new frontends:
      * OSG_UChicago, for VO OSG
      * nanoHUB for HUBzero 


---++ Engage (Mats, John)


---++ Integration (Suchandra)
   * OSG 1.2.17 issues discovered on Monday
      * RSV WLCG metrics not being uploaded correctly
      * Working on a corrected release (OSG 1.2.18)
      * Targeting a Wednesday release

---++ Site Coordination (Marco)
Note that this report lists the currently active resources in OSG.
If a site is down or not reporting it will not be counted.
Therefore there may be fluctuations.
Each line has the current number and variation from last week in parenthesis.
You can find a table with current OSG and VDT versions at http://www.mwt2.org/~marco/myosgldr.php
   * Site update status (from !MyOSG as of today):
      * Most recent production version is OSG 1.2.17
      *       94 (2) OSG 1.2.X resources (       8 are 1.2.17)
      *        3 (0) OSG 1.0.X resources (       0 are 1.0.6)
      *        2 (0) OSG 1.0.0 resources
      *        1 (0) OSG 0.8.0 resources
There is a form to propose questions for the panels and the talk with the experts session at the OSG all hands meting:
   * The best set of questions submitted by Feb 20 will win an iPod nano! 
   * Form to propose questions: https://spreadsheets.google.com/viewform?formkey=dC1kc0U4MmRrSkJUbnVXcl9YLTRELXc6MQ
   * OSGAH Agenda: http://indico.fnal.gov/conferenceDisplay.py?confId=3627
   * OSGAH Website: http://ahm.sbgrid.org/


---++ Metrics (Brian)


---++ Virtual Organizations Group (Marcia)
At the VO Forum call last week, we had a discussion on VO&#39;s experiences running long jobs. Marko Slyz &amp; Gabriele Garzoglio have a user with earthquake simulation jobs running ~46 hours+ (typically, many jobs don&#39;t run at the same time). Tests have generated job disconnects, blocks, or evictions, so they are trying to figure out ways to optimize. Do VOs have any recommendation of either how to find clusters or knowledge of clusters that permit long job runs that do not have a fixed time limit? 

---++ Security (Mine)

---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings
