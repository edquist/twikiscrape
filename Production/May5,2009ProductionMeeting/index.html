<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en_US" lang="en_US">
<head>
<link rel="stylesheet" href="https://twiki.opensciencegrid.org/twiki/pub/TWiki/HeadlinesPlugin/style.css" type="text/css" media="all" />
<title> May5,2009ProductionMeeting &lt; Production &lt; TWiki    </title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
<link rel="icon" href="/twiki/pub/Production/WebPreferences/favicon.ico    " type="image/x-icon" />
<link rel="shortcut icon" href="/twiki/pub/Production/WebPreferences/favicon.ico    " type="image/x-icon" />
<link rel="alternate" href="https://twiki.opensciencegrid.org/bin/edit/Production/May5,2009ProductionMeeting?_T=16 Feb 2017" type="application/x-wiki" title="edit May5,2009ProductionMeeting" />
<meta name="SCRIPTURLPATH" content="/bin" />
<meta name="SCRIPTSUFFIX" content="" />
<meta name="TEXT_JUMP" content="Jump" />
<meta name="TEXT_SEARCH" content="Search" />
<meta name="TEXT_NUM_TOPICS" content="Number of topics:" />
<meta name="TEXT_MODIFY_SEARCH" content="Modify search" />
<meta name="robots" content="noindex" /><link rel="alternate" type="application/rss+xml" title="RSS Feed" href="/bin/view/Production/WebRss" />    
<base href="https://twiki.opensciencegrid.org/bin/view/Production/May5,2009ProductionMeeting"></base>
<!--BEHAVIOURCONTRIB--><script type="text/javascript" src="/twiki/pub/TWiki/BehaviourContrib/behaviour.compressed.js"></script>
<script type="text/javascript" src="/twiki/pub/TWiki/TWikiJavascripts/twikilib.js"></script>
<script type="text/javascript" src="/twiki/pub/TWiki/TWikiJavascripts/twikiWindow.js"></script>
<script type="text/javascript" src="/twiki/pub/TWiki/TWikiJavascripts/twikiEvent.js"></script>
<script type="text/javascript" src="/twiki/pub/TWiki/TWikiJavascripts/twikiHTML.js"></script>
<script type="text/javascript" src="/twiki/pub/TWiki/TWikiJavascripts/twikiCSS.js"></script>
<script type="text/javascript" src="/twiki/pub/TWiki/TWikiJavascripts/twikiForm.js"></script>
<script type="text/javascript" src="/twiki/pub/TWiki/PatternSkin/pattern.js"></script><style type="text/css" media="all">
@import url('/twiki/pub/TWiki/TWikiTemplates/base.css');
</style><script type="text/javascript" src="/twiki/pub/TWiki/TWikiJavascripts/twikiStyles.js"></script><style type="text/css" media="all">


</style>
<style type="text/css" media="all">
@import url("/twiki/pub/TWiki/TWikiNetSkin/layout.css");
@import url("/twiki/pub/TWiki/TWikiNetSkin/style.css");
@import url("/twiki/pub/TWiki/TWikiNetSkin/colors.css");
@import url("/twiki/pub/TWiki/TWikiNetSkin/rounded_corners.css");
</style>
<style type="text/css" media="all">
	/* Styles that are set using variables */
	#patternLeftBar .patternWebIndicator,
	.patternBookView .twikiTopRow {
		background-color:#DDDDDD;
	}
	.patternBookView {
		border-color:#DDDDDD;
	}
	.patternPreviewPage #patternMain {
		/* uncomment to set the preview image */
		/*background-image:url("/twiki/pub/TWiki/PreviewBackground/preview2bg.gif    ");*/
	}
	
</style><style type="text/css" media="all">



</style>
<style type="text/css" media="all">
	@import url("/twiki/pub/TWiki/TWikiNetSkin/print.css");
</style><!--GOOGLEANALYTICSPLUGIN--><!-- Google Analytics script -->
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-69012-21']);
  _gaq.push(['_setDomainName', 'none']);
  _gaq.push(['_setAllowLinker', true]);
  _gaq.push(['_trackPageview']);
  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
</head>
<body class="patternViewPage patternPrintPage">
<a name="PageTop"></a>
<div id="patternScreen">
<div id="patternPageShadow">
<div id="patternPage">
<div id="patternOuter">
<div id="patternFloatWrap">
<div id="patternMain">
<div id="patternMainContents">
<div class="patternContent"><div class="patternTopic"> -- <a href="/bin/view/Main/DanFraser" class="twikiLink">DanFraser</a> - 01 May 2009
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Action_Items_results_of_discussi"></a> Action Items (<font color="#0000ff"> results of discussion </font>) </span></h2> <ul>
<li> D0, Nanohub, Engage submitting jobs to CMS sites that are terminating and/or suspending jobs. Need to understand the circumstances for these and find out what is happening. Abhishek to contact GLOW &amp; San Diego and report back with more detail.
</li></ul> 
<font color="#0000ff">  <ul>
<li> Opportunistic applications need to be prepared for job eviction -- this is an OSG principle.
</li> <li> Nanohub's Steve Clark coming to Fermi to discuss more on Thursday.
</li></ul> 
</font> <ul>
<li> Atlas -- Throughput good but hitting Condor bug involving <span class="twikiNewLink">GridMon<a href="/bin/edit/Production/GridMon?topicparent=Production.May5,2009ProductionMeeting" rel="nofollow" title="GridMon (this topic does not yet exist; you can create it)">?</a></span> and logfiles that are too old. (Xin working with Jamie, needs to report back with update)
</li></ul> 
<font color="#0000ff"> <ul>
<li> There is a long term plan in place to improve Condor-G performance, Xin to make sure he gets what he needs from Jamie.
</li> <li> <a href="http://condor-wiki.cs.wisc.edu/index.cgi/tktview?tn=429" target="_top">http://condor-wiki.cs.wisc.edu/index.cgi/tktview?tn=429</a> 
</li></ul> 
</font> <ul>
<li> LIGO -- Switched <a href="mailto&#58;E&#64;H">E&#64;H</a> to GT2, but now hitting GT2 job submission limits. Need to discuss a solution approach/plan. (Britta,Kent,Dan)
</li></ul> 
<font color="#0000ff"> <ul>
 <li>
 <ul>
<li> Will be investigating further as to cause of failures.
</li></ul> 
</li></ul> 
</font> <ul>
<li> LIGO -- Problem with job status at CIT_CMS_T2. New ticket opened: 'https://oim.grid.iu.edu/gocticket/viewer?id=6763' (Britta) 
</li> <li> D0 still affected by LSF/Globus Gatekeeper bug -- Alain to keep pinging Globus Tickets: <a href="https://oim.grid.iu.edu/gocticket/viewer?id=6489" target="_top">https://oim.grid.iu.edu/gocticket/viewer?id=6489</a> and <a href="http://bugzilla.globus.org/bugzilla/show_bug.cgi?id=6688" target="_top">http://bugzilla.globus.org/bugzilla/show_bug.cgi?id=6688</a>
</li></ul> 
<font color="#0000ff"> <ul>
<li> Bug fix was submitted by Globus. Globus speculates that the problematic error code could still be seen occasionally. More testing needed to determine if the bug is completely fixed.
</li></ul> 
</font>
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Attendees"></a> Attendees: </span></h2> <ul>
<li> Xin, Britta, Mats, Suchandra, Burt, Abhishek, Rob Q., Mine, Chander, Miron, Dan
</li></ul> 
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="CMS_Burt"></a> CMS (Burt) </span></h2>
CMS ran 153 khours/day at 92% success.  CPU/wallclock was 67% -- it seems to be uniformly low as opposed to concentrated at a particular site (although GLOW is much lower as always).
<p />
A follow-up on last week's discussion of LIGO GRAM2 jobs overloading gatekeepers -- we'll speak to Nebraska to get Brian Moe the specifics, but I think the problem is understood.
<p />
Our Tier 2 admins are keeping an eye on their individual sites and are starting to implement measures to protect themselves.  Unfortunately the only tool really available is turning off submissions for a particular VO outright.
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Atlas_Armen_Xin"></a> Atlas (Armen &amp; Xin) </span></h2>
<p />
During the last week US sites were running MC simulation jobs. The 
production was quite stable at the level of 6k running jobs.
<p />
From Gratia report: USATLAS sites ran 903K jobs, with CPU/Walltime ratio of 85%. 
<p />
From World-wide Panda production report (real jobs) :  <ul>
<li> completed successfully 643,635 managed MC production, validation and reprocessing jobs
</li> <li> average ~91,947 jobs per day
</li> <li> failed   163,191  jobs
</li> <li> average efficiency: <ul>
<li> jobs     - 79.8%
</li> <li> walltime - 93.5%
</li></ul> 
</li></ul> 
<p />
The CPU efficiency is higher last week because the reprocessing exercise has stopped. 
<p />
No particular site issues to report.
<p />
Panda server setup at CERN : Beginning of the next week (May 11) Panda for US clouds will migrate to
Oracle database.
<p />
Condor team provided us with a new grid monitor binary, which is running in our production now. 
<p />
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="LIGO_Britta"></a> LIGO (Britta) </span></h2>
<p />
Recent Average Credit (RAC):79,602.20066 (+ 20,000)
<a href="mailto&#58;E&#64;H">E&#64;H</a> rank based on RAC: 7 (+3)
<a href="mailto&#58;E&#64;H">E&#64;H</a> rank based on accumulated Credits: 39 (+0)
<p />
<p />
   Current week's total usage: 3 users utilized 17 sites;
<p />
     8758 jobs total (4193 / 4565 = 47.9% success);
<p />
     37775.1 wall clock hours total (33779.2 / 3995.9 = 89.4% success);
<p />
<p />
<h4><a name="Previous_week_s_total_usage_3_us"></a> Previous week's total usage: 3 users utilized 18 sites; </h4>
<p />
     6548 jobs total (4498 / 2050 = 68.7% success);
<p />
     34851.6 wall clock hours total (30031.3 / 4820.3 = 86.2% success);
<p />
<h3><a name="Gram_was_down_on_the_submit_host"></a> Gram was down on the submit host (04/27, 04/28) </h3>
<p />
           cause unknown
<p />
           fixed through OSG stack update
<p />
<h3><a name="50_Job_success_rate"></a> 50 % Job success rate: </h3>
<p />
   - CIT_CMS_T2- 100% fail 04/30 - 05/04
<p />
            Taken off submit list 05/04
<p />
   - SPRACE 95% fail 04/30 - 05/04
<p />
            Taken off submit list 05/04
<p />
   - MIT_CMS 87% fail 04/30 - 05/04
<p />
            Taken off submit list 05/04
<p />
Eviction policies at some CMS sites :
<p />
    Active e-mail thread Robert &lt;--> Michael Thomas
<p />
    CIT_CMS_T2 GOC ticket open
<p />
<p />
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Site_Coordination_Integration_Su"></a> Site Coordination, Integration (Suchandra) </span></h2> <ul>
<li> Currently in planning stages of OSG 1.2 release <ul>
<li> <a href="https://twiki.grid.iu.edu/bin/view/Trash/Trash/Trash/Trash/SoftwareTools/OSG12Plan" target="_top">Current plan</a>
</li> <li> Initial VTB testing will start next week
</li> <li> Biggest changes process improvements and changes to packages to help with future updates
</li> <li>  Also adds support of Debian Lenny for LIGO and testing dcache 1.92.5 release
</li></ul> 
</li> <li> The latest vo package update was tested before the goc release
</li> <li> Planning for the site admins meeting is currently ongoing
</li> <li> The campfire site is being used to help admins with upgrade issues and will be used for vtb testing coordination as well
</li></ul> 
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Engagement_Mats"></a> Engagement (Mats) </span></h2>
<p />
<p />
<hr />
     | VO             | # of Jobs | Wall Dur. | Cpu / Wall |      Delta
<hr />
  9  | engage         |     2,266 |     9,326 |       59.6 |         16
<p />
<p />
Another slow week for Engagement. We have figured out that the low efficiency
is due to Blast jobs against large databases. These jobs are doing a lot of
I/O and lower CPU time / wall time is expected.
<p />
<p />
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Metrics_Brian"></a> Metrics (Brian) </span></h2>
<p />
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Virtual_Organizations_Group_Abhi"></a> Virtual Organizations Group (Abhishek) </span></h2>
<p /> <ul>
<li> D0  <ul>
<li> D0 MC production led to an average consumption of 120,000 wall hours per day, at 68% job, 78% wall, 65% CPU:wall efficiencies. 
</li> <li> D0 Event production reached a peak rate of 12.3 million events per week. This is a new peak for the past year.
</li> <li> High failures were noted with a new cluster at UNL site; now resolved. 
</li> <li> Related to OSG, there are two lingering problems: (a) Long-lived D0 jobs are expunged at the CMS sites, likely due to the recently enforced policy on maximum wall clock time. (b) A bug which was uncovered in Globus LSF Manager; affecting OU and TTU sites. Work is ongoing between GOC, VDT and Globus. A partial fix is now in place. URLs - <a href="https://oim.grid.iu.edu/gocticket/viewer?id=6489" target="_top">https://oim.grid.iu.edu/gocticket/viewer?id=6489</a> and <a href="http://bugzilla.globus.org/bugzilla/show_bug.cgi?id=6688" target="_top">http://bugzilla.globus.org/bugzilla/show_bug.cgi?id=6688</a>
</li></ul> 
</li></ul> 
<p /> <ul>
<li> OSG-TeraGrid Gateway <ul>
<li> D0 made a first successful small-scale submission using Condor-G through the gateway, with job execution on TeraGrid site. 
</li> <li> D0 management is considering to use the gateway at a higher scale.
</li></ul> 
</li></ul> 
<p /> <ul>
<li> ALICE   <ul>
<li> Scalability and stress-testing exercise of VO-Box is ongoing on OSG site at NERSC/LBL. Using EU team's recommendation, target is 200 jobs with local data access sustained over a week. During last 2 weeks, peak rates of nearly 100 jobs per day (ALICE view) with an equivalent of 1200 wall hours per day (OSG view) were achieved.
</li></ul> 
</li></ul> 
<p /> <ul>
<li> CompBioGrid <ul>
<li> Site deployment ongoing; recent problems are related to submit side packages, PBS jobs, GIP reporting. Most problems are due to the mixed topology of the site: Windows filesystems exported and in use on Linux systems, with OSG software stack on top. 
</li> <li> We have recommended CompBioGrid to start a blog, to get a more coherent expression of issues. No recent update.
</li></ul> 
</li></ul> 
<p /> <ul>
<li> IceCube <ul>
<li> A few members have started to attend weekly VO forum. IceCube is planning to expand production to other sites besides GLOW; and have asked for more guidance on data management solutions available on OSG sites at-large. Storage need is 14 GB total persistent, and 1-2 GB per job transient, at a site. 
</li> <li> Britta/VO-Group and Mats/Trash/Engagement are helping IceCube understand GFTP use on OSG with $osg_app, $osg_data, $osg_wn_tmp. If needs exceed these legacy mechanisms, we will try to get IceCube started with SRM based persistent storage.
</li></ul> 
</li></ul> 
<p /> <ul>
<li> VORS deprecation <ul>
<li> Fermilab-VO/FermiGrid has come to heavily rely on VORS API. Fermilab-VO has conveyed hesitation toward VORS deprecation, unless all features and programmatic API of VORS are fully replaceable by the new combination of MyOSG/OIM/RSV. Meeting at FNAL to discuss this on May 6. 
</li> <li> Other known dependents on VORS are NYSGrid, SBGrid, STAR. 
</li> <li> VO Group and GOC have agreed that a short document listing the new functionality/API, is a prerequisite to collect more informed feedback from the affected VOs. 
</li> <li> nanoHUB has conveyed a need to have an XML parser to MyOSG/OIM metadata.
</li></ul> 
</li></ul> 
<p /> <ul>
<li> Matters related to Site Preemption Policy <ul>
<li> Production of at-large VOs is affected by job suspensions related to site preemption at LHC sites. 
</li> <li> At least 3 VOs - D0, Engage, nanoHUB, (also LIGO) - have pointed out that each's running jobs are sometimes suspended or evicted, during the job startup, at CMS sites. 
</li> <li> E.g., at Caltech, GLOW, UCSD. Unofficial estimates of CMS sites indicate a 36-hours wall clock limit and a 2-weeks queue time limit. However, problem may not be directly related to newly enforced policies of CMS; each sites decides its own.
</li> <li> Need to discuss more precise ways for sites to declare these policies, and/or for VOs to checkpoint the jobs. 
</li> <li> Britta has started a ticket, discussing with Caltech. URL - <a href="https://oim.grid.iu.edu/gocticket/viewer?id=6763" target="_top">https://oim.grid.iu.edu/gocticket/viewer?id=6763</a>
</li></ul> 
</li></ul> 
<p /> <ul>
<li> GPN <ul>
<li> David has expressed interest in attending the weekly VO forums.
</li></ul> 
</li></ul> 
<p /> <ul>
<li> GROW <ul>
<li> Bringing up a local site. Currently deploying a small local SE, worth 3TB.
</li> <li> Will convey if help from Trash/Trash/CampusGrids is needed.
</li></ul> 
</li></ul> 
<p /> <ul>
<li> nanoHUB <ul>
<li> A F2F technical meeting on May 7, at FNAL.
</li> <li> An item out-of-scope of TaskForce but can be important is Multi-gatekeeper handling: Difficulty to evaluate status of a site with multiple gatekeepers. There is a need to advertise {gk1 OR gk1} model so that remote VO does not erroneously evaluate site as {gk1 AND gk2}. 
</li></ul> 
</li></ul> 
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Grid_Operations_Center_Rob_Q"></a> Grid Operations Center (Rob Q.) </span></h2> <ul>
<li> New VO Package Released
</li> <li> At this point no site have upgraded to OSG 1.0.1 <ul>
<li> Caltech is bringing on some new resources soon that will be 1.0.1
</li></ul> 
</li> <li> New NEBioMed VO Registered <ul>
<li> Working toward ET Approval
</li></ul> 
</li> <li> Ticket Exchange was broken this morning due to GRNOC maintenance that caused an address change
</li> <li> Installed Capacity will be available very soon for Tier 2 Coordinators to test
</li></ul> 
<p />
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Security_Mine"></a> Security (Mine) </span></h2></div><!-- /patternTopic-->
<p />
<p />
</div><!-- /patternContent-->
<hr />
This topic: Production<span class='twikiSeparator'>&nbsp;&gt;&nbsp;</span><a href="/bin/view/Production/WebHome" class="twikiCurrentWebHomeLink twikiLink">WebHome</a> &gt; <a href="/bin/view/Production/WeeklyProductionMeetings" class="twikiLink">WeeklyProductionMeetings</a><span class='twikiSeparator'>&nbsp;&gt;&nbsp;</span>May5,2009ProductionMeeting</span> <br />    
Topic revision: r12 - 12 Oct 2016 - 15:23:10 - <a href="/bin/view/Main/KyleGross" class="twikiLink">KyleGross</a>
</div><!-- /patternMainContents-->
</div><!-- /patternMain-->
</div><!-- /patternFloatWrap-->
<div class="clear">&nbsp;</div>
</div><!-- /patternOuter--><div id="patternBottomBar"><div id="patternBottomBarContents"><div id="twikinetBadge"><a href="http://www.twiki.net/"><img src="https://twiki.opensciencegrid.org/twiki/pub/TWiki/TWikiNetSkin/twiki-badge-88x31.gif" alt="TWIKI.NET" width="88" height="31" border="0" /></a></div><!--/twikinetBadge--><div id="patternWebBottomBar"><p>
<font size="-1">
TWiki |
<a href="https://ticket.grid.iu.edu/goc/twiki">Report Bugs</a> |
<a href="https://twiki.grid.iu.edu/bin/view/Operations/IUPrivacyPolicy">Privacy Policy</a>
</p>
<p>
<font size="-2">
<span class="twikiRight"> <a href="http://twiki.org/"><img src="/twiki/pub/TWiki/TWikiLogos/T-logo-80x15.gif" alt="This site is powered by the TWiki collaboration platform" width="80" height="15" title="This site is powered by the TWiki collaboration platform" border="0" /></a></span>Copyright by the contributing authors. All material on this collaboration platform is the property of the contributing authors..
</font>
</p></div><!--/patternWebBottomBar--></div><!-- /patternBottomBarContents--></div><!-- /patternBottomBar-->
</div><!-- /patternPage-->
</div><!-- /patternPageShadow-->
</div><!-- /patternScreen-->
</body></html>
<p />