-- Main.DanFraser - 19 Jan 2010
---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings

---++ Action/Significant Items:
   * A bug was finally found and fixed in the BDII at CERN that resulted in stale entries. This was first noted by Xin over 2 months ago. 
   * GOC&#39;s monitoring of the BDIIs has demonstrated that everything is working appropriately. Problems were correlated to site outages or downtimes. Plan to close ticket 7772. The current script is too complicated to use on an ongoing basis for monitoring, but it was agreed that some type of ongoing monitoring should be implemented and run at the GOC. (Rob)
   * A problem with GGUS-GOC ticket exchange system has been fixed as the transition was made to implement a web services based system that interfaces directly between the two systems. (Rob)
   * LIGO hit a new record of 160K hours/day thanks in part to Burt&#39;s increasing the disk quota on the FNAL T1, and also due to some storage optimizations made by Robert. (Robert)
   * The number of simultaneous jobs that can be run at FNAL is limited by a Condor 7.3 limitation to ~3000. Upgrading to 7.4 should improve this. (Burt)
   * SBGRID is trying multiple solutions (now looking at PANDA). It would be better if we can try and focus them to complete one strategy before diversifying. (Abhishek, Dan)

---++ Attendees:
   * Xin, Armen, Britta, Robert E., Brian, Suchandra, Burt, Marco, Abhishek, Rob Q., Mine, Chander, Dan
 
---++ CMS (Burt)
   * Computing: 100 khour/day, 90% success. CPU/wallclock at 59% (excluding T1: 68%).
   * Storage: 1.8 PB xfer (T1), 75 TB (others)
   * Continued to run intense skim runs at the Tier 1 to test dCache/network congestion issues.
   * LIGO seems to be running full-out at the CMS T1 (slots are limited by Condor 7.3 bug; we hope to upgrade to 7.4 soon).

---++ Atlas (Armen &amp; Xin)
   * Atlas reported verbally but did not complete a written report due to handling some on-site emergencies. (Dan)

---++ LIGO (Britta, Rob E.)

 * Gratia reports:
   * Last week&#39;s total usage: 5 users utilized 34 sites
     * 91942 jobs total (63184 / 28758 = 68.7% success)
     * 854231.0 wall clock hours total (700689.1 / 153541.8 = 82.0% success)
   * Last week&#39;s total usage: 5 users utilized 38 sites;
     * 74974 jobs total (51987 / 22987 = 69.3% success);
     * 640336.3 wall clock hours total (593458.9 / 46877.4 = 92.7% success);
 
   * E@H reports
      * Recent Average Credit (RAC): 1,670,211.09593
      * E@H rank based on RAC: 3 (+0)
      * E@H rank based on accumulated Credits: 10 (+0)
 
   * Robert is working on code changes required to expand to Fermilab sites and Sprace

 
---+++ Binary Inspiral
   * Work-flow comparison:
      * 1) Firefly
      * 2) LIGO_CIT  (local ITB cluster)
      * 3) ldas-grid (local LIGO cluster)
   * Compared queue times and execution  times of different job types in the work-flow
   * Summary and plots can be found here:  http://www.ligo.caltech.edu/~bdaudert/INSPIRAL

   * Testing clustering capabilities of Pegasus

---++ Engage (Mats, John, Chris)

10 users utilized 37 sites;

35227 jobs total (29198 / 6029 = 82.9% success);

148639.9 wall clock hours total (133903.4 / 14736.6 = 90.1% success);

No production issues this week. We will not be able to make the call this week.


---++ Integration (Suchandra)
   * OSG 1.2.6 released last friday
   * OSG 1.2.7 will be go into testing this week
      * Primarily security fixes 
   * Testing dcache 2.4.6

---++ Site Coordination (Marco)
Note that this report lists the currently active resources in OSG.
If a site is down or not reporting it will not be counted.
Therefore there may be fluctuations.
   * Site update status (from !MyOSG as of today):
      * Most recent production version is OSG 1.2.6
      *       66 OSG 1.2.X resources (       3 are 1.2.6)
      *       10 OSG 1.0.X resources (       2 are 1.0.5)
      *       15 OSG 1.0.0 resources
      *        2 OSG 0.8.0 resources
         * OU_OCHEP_SWT2, tier2-01.ochep.ou.edu , Contact: Horst Severini
         * UIC_PHYSICS mstr1.cluster.phy.uic.edu , Contact: John Wolosuk

Current versions of OSG and VDT on all OSG production sites. The page pulls updated information from MyOSG:
   * http://www.mwt2.org/~marco/myosgldr.php

---++ Metrics (Brian)
   * Gratia - should we take any actions on sites with no OSG jobs?  Accrding to Dan&#39;s latest email, maybe no?
   * New xrootd-transfer, xrootd-storage, and dCache-storage probes coming into testing from OSG-Storage team.

---++ Grid Operations Center (Rob Q.)

---+++ Operations Last Week 
   * Last week&#39;s availability metrics
      * [[http://tinyurl.com/yl6pb7a][GOC Services: BDII, MyOSG, RSV Collector, OSG Display]] 
      * [[http://tinyurl.com/yjkchjp][GOC hosted Security services managed by OSG security team]]
   * *[[http://osggoc.blogspot.com/2010/01/goc-service-update-tuesday-january-26th.html][Production release completed on Tuesday - Jan 26th 14:00 UTC]]* -- there was no known outage.
   * [[http://osggoc.blogspot.com/2010/01/new-vo-package-available.html][VO package v30 released]] -- change in ordering requested by cdf and addition of grid unesp
   * [[http://osggoc.blogspot.com/2010/01/myosg-url-registration.html][MyOSG URL usage registration]] -- GOC requested MyOSG XML users to register URLs they are using so those users could be contacted to ensure continued success in use following update releases.
   * [[http://osggoc.blogspot.com/2010/01/osg-126-release-announcement.html][OSG 1.2.6]] released last week
   * GOC-GGUS ticket exchange was successfully moved to using a web-service based ticket exchange system.
      * GOC also attempting to setup prototype exchange with RT ticketing system (ATLAS ticket system)

---+++ Operations This Week
   * *GOC Service ITB release Tuesday - Feb 2nd 14:00 UTC* 
   * Continue new web service based GOC-FNAL ticket exchange work
      * Continue discussion re: web service based ATLAS RT ticket exchange as well
   * Continue final testing of Debian repository deployment for CA distribution (requested by LIGO VO), then announce release.
   * GOC working on collating VOMS monitoring metric results into a table, possibly with limited history ([[https://ticket.grid.iu.edu/goc/viewer?id=7983][related ticket]])
   * Minor update to GIP validator tool - necessitates changes to way results are parsed by MyOSG&#39;s GIP Validation results view
   * SAMS broker outages - I&#39;ve gotten word directly from WLCG that all availability and reliability will be recalculated due to these outages.

---+++ Future Events
   * RSV Collector upgrade to be done on Feb 9th (production release Tuesday); ITB collector already successfully upgraded to 1.06.14 two weeks ago.
   * New member of the Support Group starting Feb 15th. 


---++ Virtual Organizations Group (Abhishek)

   * D0 MC production picking up; remains low. Last week&#39;s average 3 M Evts/week.

   * CDF production running smoothly; opportunistic expansion plan awaited.
   
   * SBGrid 
      * Provided with detailed Gratia logs of sites that give high failures. Investigation goal is to improve overall job success rate at sustained moderate scale (1000-1500 jobs); results awaited. 
      * Last week&#39;s average: Successfully used 70,000 wall hours. 35,000 hours/day at 28% wall efficiency; 40,000 jobs in week at 34% efficiency.    
      * SBGrid trying to find a good storage solution.
         * Requirements
            * Workflow takes 10-30,000 hours to complete.
            * Nearly 5-15,000 jobs, arranged as DAG.
            * One 1-5 MB file shared between every job.
            * Each job fecthes a file 5-20 times. 
         * Suggestion from ATLAS MWT2 is PCache, an unsupported client-side tool; OSG Storage is open to add it as a partly supported tool in operations-toolkit if needed.
         * Squid and RFT also under discussion.
         * Looking to arrange for a phone meeting with SBGrid and Tanya, Ted, Brian to converge.
      * SBGrid investigating PANDA WMS. 

   * ALICE to make NERSC site production-ready on small scale. Work in progress. 

   * !GlueX&#39;s site UCONN_OSG is not visible in !ReSS. Available in RSV. To remedy, Richard/GlueX working to resolve system-level !CentOS 5 issues. Aim is to make CE more stable before fixing CEMon/ReSS.
 
   * !CompBioGrid&#39;s site issue with firewall on site upgrade from OSG 1.2.3 to 1.2.4; investigation currently on hold; trying to re-install and evaluate if issue is resolved with the newer release. VDT team in loop. Ticket -- https://ticket.grid.iu.edu/goc/viewer?id=7870      
   
   * !IceCube evaluating HTTP cache/Squid for data staging; had phone meeting last week to expedite work.


---++ Security (Mine)
 We are testing the apt
repository and the package. However, we are finding errors, one of which
related to signing Debian packages. We normally sign the tarball and
rpms. When we sign debian packages, during installation Debian complains
the signatures cannot be verified. In addition, when Tim tested apt
repository, he get a different error. In short, we are not sure what is
wrong, but we have ideas about testing to find the root cause.

Security team has no experts on Debian, and Tim has helped us immensely,
and he is still helping with debugging. Tim and Anand have been testing
for the past three days. We will continue testing today and tomorrow. if
we cannot progress, we will ask for outside Debian help.
