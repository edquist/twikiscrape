-- Main.DanFraser - 15 Sep 2009
---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings

---++ Action/Significant Items:
   * Status of the Gratia Probe? (needed for CMS)
      * This effort was stalled but this should be back in the ITB soon. (Suchandra, Arvind to keep it moving)
   * BNL data not appearing in RSV probe (GOC ticket 7489)
      * Should be fixed next Monday
   * LIGO/Pegasus agreed to modify code to start getting sites catalog data directly from ReSS instead of myOSG (Britta)
   * LIGO will be ramping up production over the next few weeks as Condor-G seems to be working well (Britta)
   * Site Admin support call (to become a place for T3 support) will be available every second Thursday of the month starting Oct. (Marco)
   * nanoHub started making OSG resources available to users -- now running 300-500 hours/day.
   * Not all site admins getting security announcements; need to understand what is happening (Mine, Rob)
   * Engage discovered a problem where some sites are not returning job completed notifications (Mats is investigating)
   * Security drill for T2 sites starting next week (Mine)

---++ Attendees:
   * Xin, Armen, Britta, Mats, Brian, Suchandra, Burt, Marco, Abhishek, Mine, Dan 
---++ CMS (Burt)
   * Computing: 192 khour/day, 90% success. CPU/wallclock at 83%.
   * Storage: Tier 1 transferred 1.6 PB last week (peak of 372 TB/day). Tier 2s transferred 386 TB (peak: 102 TB/day). Probes not functional at UERJ, MIT, Florida, Purdue.
   * OSG: No change again: we have 3 CEs at OSG 1.2 (both Nebraska and cit-gatekeeper2). Tier 3s at 1.2: UCDavis, FIT, UMD, Vanderbilt, UCR, Notre Dame.
   * RSV: Status of gratia probe in ITB?
   * Physics challenge: focused on analysis.  Hope to have T1 skims finished around October 2.  T2-T2 transfers, &quot;group skims&quot;, and debut of Store/Results Service.

---++ Atlas (Armen &amp; Xin)

   * On average USATLAS sites keep 6~7k running jobs, most of them are regional production jobs. New major simulation software release is still in validation. Reprocessing test jobs are run on T1 now, will be sent to T2s soon. 
   * job statistics for last week. 
      * Gratia report: USATLAS ran 734K jobs, with CPU/Walltime ratio of 92.6%. 
      * PanDA world-wide production report (real jobs): 
         * completed successfully 244,758 managed MC production, validation and reprocessing jobs (185,583 of them in US cloud)
         * average ~34,965 jobs per day
         * failed 41,892 jobs
         * average efficiency is very good:  jobs  - 94.1%,  walltime - 81.5%
   * Site issues
      * All USATLAS T2s are preparing to go to SL(C)5 platform, in test now. T1 is already migrated to SL5. 
      * Brian fixed the problem of missing BNL availability numbers in the WLCG daily availability report. It is still missing from the VO specific RSV daily report, ticket open at GOC to trace it. 

---++ LIGO (Britta)
  * Gratia reports:
      * 3 users utilized 10 sites
      * 15922 jobs total (15045 / 877 = 94.5% success);
      * 111618.1 wall clock hours total (108592.4 / 3025.6 = 97.3% success);
   
      * Last Week&#39;s report: 4 users utilized 17 sites   
      * 16807 jobs total (15159 / 1648 = 90.2% success);
      * 126326.5 wall clock hours total (116850.4 / 9476.1 = 92.5% success);

  * E@OSG reports
      * Recent Average Credit (RAC):297,240.63604, Last week: 271,826.44862
      * E@H rank based on RAC: 5 (+2)
      * E@H rank based on accumulated Credits: 17 (+1)

   * Details:
      * Robert is returning from vacation today
      * Will increase # of sites and # jobs over next 2 weeks
      * Pegasus and MyOSG: talk with Tanya, Ted, Marco and Karan --&gt; ReSS
  

---++ Integration (Suchandra)
   * Released OSG 1.2.3 today
   * Working on documentation improvements
      * Standalone GridFTP documentation
   * Held initial discussions with panda group in regards to using it for itb testing
   * Tested lcg utils with atlas workflows

---++ Site Coordination (Marco)
Note that this report lists the currently active resources in OSG.
If a site is down or not reporting it will not be counted.
Therefore there may be fluctuations.
   * Site update status (from !MyOSG as of today):
      * Most recent production version is OSG 1.2.3
      * 24 OSG 1.2.X resources (1 are 1.2.3)
      * 28 OSG 1.0.X resources (18 are 1.0.4)                                                                                                                                                                  
      * 32 OSG 1.0.0
      * 2 OSG 0.8.0 (OU_OCHEP_SWT2, UIC_PHYSICS)
   * Site administrators meeting in the ITB slot Thursday 10/1, 2:30pm:
      * define regular calendar (once a month, every second week)
      * in depth topic: RSV and probes (suggestions for the following)
      * become a place where sites (specially less experienced Trash/Tier3 can come for support)
      * Adobe Connect


---++ Engagement (Mats)

9 users utilized 36 sites;

11810 jobs total (8345 / 3465 = 70.7% success);

33369.0 wall clock hours total (24356.2 / 9012.8 = 73.0% success);

Only production issue is that we do not seem to get reliable job completed notifications from some sites, which results in &quot;stuck jobs&quot;
We are trying to determine the cause, but no luck so far.


---++ Metrics (Brian)
   * GOC should be starting with transition of Bestman/Xrootd endpoints.  I got a few questions from ATLAS sites, but no issues were raised.
   * Starting the process of filtering out VO reports.  If your endpoint is not registered or your VO is not registered, your CPU hours will be categorized as &quot;other&quot; and not shown with the registered VOs.  Gratia folks are working with Fermilab to make sure all the Fermi VOs are indeed registered.
      * All changes are reversible.
      * In other words, OSG reports will only show OSG VOs and OSG resources.
      * If you want reports showing non-OSG VOs, Gratia team can help you set up your own collector.

---++ Virtual Organizations Group (Abhishek)

---+++ VOs with High Activity

   * D0 -- (i) MC Production average at 40,000 hours/day. Equivalent 7 Million Events/week. Job efficiency 70%, Wall efficiency 85%,  CPU/wall 74%. D0 internal workload is low; expected to increase with new MC software release after a few weeks. (ii) Preemption is present; rate changed at UFL, MIT, CIT, GLOW; it prevents persistent pauses/restarts of jobs. Improvement being noted.
   
   * Fermi-VO -- (i) Fermilab VO has 12+ sub-VOs (or subgroups). Need to keep the parentVO/subVO classification uniform across OIM, Gratia, VOMS, GUMS. (ii) Fermi KCA changes are upcoming; packages are being tested, not fully ready yet. In the interim, a few users of Fermi-VO, CDF, D0, ILC, CMS, DES are likely to be affected. OSG Security has advised to delay the change. (iii) Fermilab VO has agreed to implement GIP configuration changes to advertise subcluster parameters; a related paper is also being written by Fermilab VO and will be shared with OSG.
   
   * CDF -- CDF is affected by Enterprise Linux 4 to 5 migration. Ongoing effort is to find all packages, and ship dependencies with application to sites. 
   
---+++ VOs with Limited Activity

   * nanoHUB -- Average 300-500 hours/day. Influx of &#39;User jobs&#39; also started; in addition to &#39;Application jobs&#39;. nanoHUB is preparing an accounting web to display job-statistics. Details awaited.
   
   * NYSGrid -- Planning a state-wide portal using HUBzero (http://www.hubzero.org). HUBzero is a product spinoff from nanoHUB. If assistance is needed from nanoHUB, NYSGrid has agreed to convey.
   
   * !IceCube -- Work in progress with !IceCube simulation team (P. Desiati, J. Velez, S. Barnet), GLOW and UCSD site teams. GLOW has setup a glidein schedd, to port !IceCube jobs for glideinWMS. Short-term plan is to use Squid (not SRM) to minimize failure modes. Currently, !IceCube team is porting the jobs. Part of !IceCube team is on travel; so effort is being delayed. 
   
---+++ General

   * Accuracy of new accounting alert report (OIM/Gratia comparison) -- Most entries are due to site mappings of local subgroups/users, being interpreted as unregistered VOs. E.g., two-thirds (12 of 19) of entries are actually from local subgroups at UNL site. Need to find a fix with Metrics and Gratia.
   
   * Version 5 of Enterprise Linux on sites -- Encouraging VOs to prepare for the transition.
   
   * OIM categorization of old and new VOs -- Old unregistered VOs, and new applicants, are currently marked as inactive VOs in OIM. Need to find a fix with GOC.

---++ Grid Operations Center (Rob Q. will not attend this week)
---+++ Operations Last Week 
   * ITB-BDII RCA Completed -- see [[https://twiki.grid.iu.edu/bin/view/Operations/BDIIRootCauseAnalysis#Testing_on_Sept_11_2009_and_Sep][RCA]]
   * Some parts of the RSV Daily reports were erroring out even after last week&#39;s update. Those have been fixed as of Monday -- see [[https://ticket.grid.iu.edu/goc/viewer?id=7463][related ticket]]
   * BDII basic functionality now being monitored by RSV. I will test bring details to next weeks meeting.
&lt;img src=&quot;%ATTACHURLPATH%/Picture_3.png&quot; alt=&quot;Picture_3.png&quot; width=&#39;762&#39; height=&#39;361&#39; /&gt;    


---+++ Operations This Week
   * I&#39;m at EGEE 09 if you need me find me early in the morning US time.
   * No operations events planned.

---+++ Future Events
   * Machine Room Move in Bloomington October 17 2009 - All GOC Services in Bloomington are expected to be down. IUPUI will still be handling BDII and !MyOSG traffic. GOC will attempt to install as many other services on an Indianapolis-based server/VM as possible, especially critical ones like !MyOSG. 


---++ Security (Mine)
   * Kernel problems. New exploits are discovered. There are no workarounds for these exploits. 
      * We ran a test job on all OSG sites last week. A significant number is NOT updated. We called/emailed 10-12 sites. Many claims they never got any emails from OSG. We found out OIM emailing query only emailed half of the securit contacts. But I talked with contacts they were supposed to be emailed and they still claim they did not get it. I think we should test our announcement method once more. Problem may be with client side, such as spam filters. 
      * We will send a new update. There are 5 new kernel vulnerabilities found in Red Hat 4. There are no known exploits. 
      * Current attacks detected against EGEE, TeraGrid, NCSA and Berkeley lab. Attack vector uses ssh. We will urge our sites not to use ssh open to external world. 
      * called T3 first. some, such as UMD-cms uses Rocks management tool and admin thought they applied the patch. Our test revealed that Rocks somehow changed the booting kernel and booted from an unpacthed version. emailed T3 site admins. 
 
   * About communication problem: 
      * I requested a log of site admins who have viewed the GOC announcement. To see how many at least received an email on announcement. GOC does not keep logs at granularity of each announcement, but for the whole ticket.grid.iu.edu site. Even then IPs of site admins are not meaningful for me. I need to see their DNs. This is not captured in the logs but can be done since admins use their certs to access announcements. 
      * We need confirmation from site admin to see they indeed read the announcement. We do not have it right now.
   * Security drill is starting this week. We attended tier 2 site meetings, contacted Rob G and Ken Bloom. 
      * Sites have entered their preferred dates. This week UFlorida-HPC and UFlorida PG on Thursday
      * Next week 15 sites will be drilled.
      * We are running our test job on each site before the drill to ensue it actually runs. 
   * Jim Basney has left this week and Jim Barlow has joined the security team effective yesterday. He is from NCSA and will do operational security. I will arange him to meet GOC personnel. 
   * Workshops are being almost finished. OGF workshop is being advertised. Security workshops are being finalized. Doug attempted to contact Miron several times on the workshop issues with no avail. I told him not to lose time and go ahead with current agenda and invitee list.  
   * Finished testing Bestman-Gateway installation. There are a few small security issues. I will talk with Doug Benjamin and Tanya. I read Doug&#39;s website for Atlas tier3. I want to test a few things he said there. I think there might be a small problem. 



  

