-- Main.DanFraser - 02 Mar 2010
---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings

---++ Action/Significant Items:
   * Machine: 7 &lt;nop&gt;TeV collisions achieved!
   * No data transfers were reported on Atlas over the weekend. Xin to work with the Gratia team to identify where the problem is. 
   * GGUS tickets now being routed through GOC-TX (web services), running smoothly so far
   * GOC Ticket emails will begin to appear from osg [at] tick.globalnoc.iu.edu instead of of osg [at] tick-indy.globalnoc.iu.edu -- starting mid April.
      * GOC will work with collaborating SCs that do ticket exchange to try to ensure nothing breaks
   * The BDII monitors reported stale data in the BDII for a short period of time although the BDII logs did not indicate any problems. The Production Coordinator has requested that the GOC continue looking into this (Rob). 
   * Throughput limitations being explored by the Engage team appear to be due to specific user requested resources (e.g. memory requests) that limit the number of suitable sites on the OSG. (John)
   * DZero production seems to be limited for the first time by the number of slots available on the OSG. Possible strategies for improving this being discussed. (Abhishek, Dan)

---++ Attendees:
   * John, Xin, Armen, Britta, Suchandra, Burt, Marco, Abhishek, Dan
 
---++ CMS (Burt)
   * Computing: 199 khour/day, 82% success.  Attributed to bad workflow submitted last week.
   * Machine: 7 &lt;nop&gt;TeV collisions achieved!
http://home.fnal.gov/~burt/CMS1stEvent_resized.png
http://cms.web.cern.ch/cms/News/e-commentary/images/images2010/run_132440_pi0.gif

---++ Atlas (Armen &amp; Xin)

   * General production status
      * ATLAS production has been stable, all simulation, 7~8K running jobs all the time. Collisions happened at 7Tev today. 
   * Job statistics for last week. 
      * Gratia report: USATLAS ran 1.5M jobs, with CPU/Walltime ratio of 89%. 
      * Panda world-wide production report (real jobs): 
         * completed successfully 1.2M managed MC production, validation and reprocessing jobs 
         * average 175K jobs per day
         * failed 126K jobs
         * average efficiency:  jobs  - 91%,  walltime - 97%
   * Data Transfer statistics for last week
      * BNL T1 data transfer is &lt;100 TB/day on average, lower than usual.  
   * Issues
      * USATLAS T3 sites ticket, we would like them to stay with GOC, not automatically forwarding to BNL RT queue. 
      * Opportunistic SE usage on USATLAS resources for D0: test is going on.
      * GGUS - GOC - BNL ticket exchange: test is going on. 

---++ LIGO (Britta, Rob E.)
   * Robert out sick until Thursday
   * Britta on vacation: April 1 - April 12
---+++ Gratia Reports
   *  Current week&#39;s total usage: 5 users utilized 41 sites
      * 106063 jobs total (38737 / 67326 = 36.5% success)
      * 784526.7 wall clock hours total (640658.4 / 143868.3 = 81.7% success)
   * Previous week&#39;s total usage: 3 users utilized 40 sites;
      * 92029 jobs total (48934 / 43095 = 53.2% success);
      * 898077.5 wall clock hours total (800659.6 / 97417.9 = 89.2% success);

---+++ LIGO / E@H
   * Recent Average Credit (RAC): 1,998,041.82747, Last Week: 2,427,724.97007
   * E@H rank based on RAC: 1 (+0)
   * E@H rank based on accumulated Credits: 4 (+0) 

---+++ LIGO / INSPIRAL
   * Tested file transfer dag at Firefly
      * third party guc executed on submit host
      * md5sum check executed remotely
      * 500 files with md5sum check: ~11 hours run time

---++ Grid Operations Center (Rob Q.)

---+++ Operations Last Week 
   * [[https://twiki.grid.iu.edu/bin/view/Operations/Minutes2010March22][Previous Meeting Agenda]]
   * Availability metrics for the last week 
      * [[http://tinyurl.com/yhkl4jl][GOC Services: BDII, MyOSG, RSV Collector, OSG Display]]
      * [[http://tinyurl.com/yecs5jo][GOC hosted Security services managed by OSG security team]]
   * *ITB GOC services release*: Complete -- see [[http://osggoc.blogspot.com/2010/03/goc-service-update-tuesday-march-30th.html][blog]] for more details 
   * [[http://osggoc.blogspot.com/2010/03/new-vo-package-available.html][VO Package 32 released]] -- HCC VO added; DOSAR entry changed
   * [[http://osggoc.blogspot.com/2010/03/goc-footprints-mail-anomaly.html][Footprints Accidental Email Flush Issue from last Friday afternoon]]

---+++ Operations This Week
   * *Production release*: See [[http://osggoc.blogspot.com/2010/03/goc-service-update-tuesday-march-30th.html][blog]] for more details
      * This went without incident today between 9:00 and 9:45 EDT
   * GOC Ticket emails will begin to appear from osg [at] tick.globalnoc.iu.edu instead of of osg [at] tick-indy.globalnoc.iu.edu -- starting mid April.
      * GOC will work with collaborating SCs that do ticket exchange to try to ensure nothing breaks 
   * *Ticket Exchange (TX)*: 
      * GGUS
         * Running Smoothly
         * USCMS had question about origin of alarm tickets from training/ITB systems; We have contacted GGUS admins about this.
         * Discovered a 4000 Character Limit in GGUS Description field. 
      * BNL RT
         * Updates to GOC-TX, etc. will be deployed tomorrow; GOC will do testing after that before recommending production transition to new setup
         * [[http://docs.google.com/Doc?docid=0AQGl_1gJKDWDZGY5ZnR6anZfMjFmMmpzZmc1cA&amp;hl=en#Transition_from_email_based_ex_7272405605382354][GOC-TX  section with detailed transition proposal]]
      * FNAL Remedy
         * Initial Connections Issues Resolved, Moving Forward this week after production release on March 30th
      * We urge everyone to move to using using GOC-TX -- contact GOC if you do ticket exchange with us! (In the near future, we will also start initiating contacts to our ticket exchange collaborators]
   * *Operations on Holiday Schedule Friday, April 2nd*

---++ Engage (Mats, John, Chris)

7 users utilized 38 sites;

29956 jobs total (21633 / 8323 = 72.2% success);

136878.0 wall clock hours total (119666.5 / 17211.5 = 87.4% success);


Production Issue: we are struggling to find slots for current workload  requirements:

   - 2GB RAM / 48 hour wallclock

   - 1.5 GB RAM / 72 hour wallclock

The issue is being discussed within Trash/Engagement and with Dan/Chander/Brain/Jim.


---++ Integration (Suchandra)
   * Finishing up OSG 1.0.6 release
   * Starting work on OSG 1.2.9 release testing
      * Will be using automated testing on sites
      * Changes outlined in [[https://twiki.grid.iu.edu/bin/view/SoftwareTeam/SEP5][SEP 5]]
      * Anticipate about 3-4 weeks before release
   * ITB Robot
      * Continuing efforts to automate testing and reporting
      * Should have reporting and initial automation done for this release
   * Documentation 
      * Iwona completing updates to pages
      * Will contact owners and review pages during osg 1.2.9 cycle to make sure pages are up to date
       

---++ Site Coordination (Marco)
Note that this report lists the currently active resources in OSG.
If a site is down or not reporting it will not be counted.
Therefore there may be fluctuations.
   * Site update status (from !MyOSG as of today):
      * Most recent production version is OSG 1.2.8
      *       71 OSG 1.2.X resources (      16 are 1.2.8)
      *        8 OSG 1.0.X resources (       2 are 1.0.5)
      *        9 OSG 1.0.0 resources
      *        2 OSG 0.8.0 resources
Survey results about CRL update process:
   * https://twiki.grid.iu.edu/bin/view/Trash/Trash/Trash/Trash/SiteCoordination/SitesCoord100304#Follow_up_CRL_update_survey_resu


---++ Metrics (Brian)


---++ Virtual Organizations Group (Abhishek)

---+++ VOs with significant activity last week

   * *D0* 
      * MC Production affected by reduced availability of batch slots at CMS T1 cmsosgce3.fnal.gov. Average dropped to 6.7 M Events/week from previous week&#39;s 9.8 M Events/week. 101,000 wall-hours/day at 86% efficiency. 
      * ATLAS/UTA SE access still pending. Joel waiting to hear back from Mark.
      
   * *GLUE-X*
      * Site-side: Abhishek facilitating other VOs to use GLUE-X site in production. GLUE-X site now in use by Engage, GEANT4, GPN, LIGO, SBGrid, GLOW. Some problems with glide-ins; resolved by resubmissions.
      * VO-side: Next step for GLUE-X workflow management - need to decide on a scheme for job dispatch. Abhishek &amp; Dan discussing options with Richard Jones.
      * Policy related feedback: Lack of OSG policy on POSIX account requirements; a site&#39;s support for multiple VOs; multiple sites&#39; support for a specific VO.

   * *IceCube*
      * External review in two weeks.
         * One of the topics of discussion for review panel will include !IceCube plans for future grid usage. !IceCube team will be talking about !IceCube&#39;s infrastructure plans (and adequacy of plans) for the upcoming year.
         * In addition, !IceCube expects to produce requirements for simulation production (!IceCube&#39;s first OSG workload). Will be able to get these numbers to OSG for planning purposes.

   * *SBGrid*
      * VO-side: 
         * BNL team has set up Panda submission infrastructure for SBGrid operations. Targeting 8 sites.
         * Joey Kong, performing cancer research, is an active user. Encouraging results/publication after 4-6 weeks.
   
   * *DOSAR*
      * Preparing for upcoming workshop; April 6-8. URL: http://physics.uj.ac.za/conferences/2010/DOSAR

   * *nanoHUB*
      * Upgraded submit/workflow infrastructre to Condor 7.4.1; problems being noticed in DAG; jobs being resubmitted; resulting in apparent peak in consumption.
      * Investigation ongoing between Steve C, Alain, Abhishek. Waiting for Jaime F&#39;s return from vacation.
     &lt;img src=&quot;%ATTACHURLPATH%/nanoHUB_facility_hours_bar_smry.png&quot; alt=&quot;nanoHUB_facility_hours_bar_smry.png&quot; width=&#39;800&#39; height=&#39;500&#39; /&gt;    
   
---+++ Miscellaneous

   * Working with VOs to collect direct input for:
      * Production resource planning (with Dan). Input received from LIGO, D0, GLUE-X, DOSAR, JDEM.
      * Software Enhancement Proposals (with Alain). Input received from GLUE-X.

---++ Security (Mine)

