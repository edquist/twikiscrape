---+!! *&lt;noop&gt;%SPACEOUT{ &quot;RSV Storage Probes&quot; }%*
%DOC_STATUS_TABLE%
%TOC{depth=&quot;3&quot;}%

---++ About this Document

This document explains how to configure and use RSV Storage Probes.  Two types of probes are listed under this document: client probes and tester probes.
This document is intended for site administrators who want to use these probes to monitor their storage elements.  They are intended to test and monitor SRM endpoints.
This document also gives some information on the default storage probes.

%INCLUDE{&quot;Trash/DocumentationTeam/DocConventions&quot; section=&quot;Header&quot;}%
%INCLUDE{&quot;Trash/DocumentationTeam/DocConventions&quot; section=&quot;CommandLine&quot;}%


---++ Requirements

You will need to [[Documentation/Release3.RsvOverview][install RSV]] first.  Refer to the main page on how to do this.  
These instructions only cover how to configure SRM probes once RSV is installed.

---++ Storage Probes

Included with RSV are several types of storage probes. 

   * *Basic Client Probes*: The first will begin with &quot;org.osg.srm.srmclient-&quot;. These will use SRM client commands to connect to your storage facility and run commands to check basic functionality connected to the SRM storage protocol.  If applications accessing this storage element are using SRM client commands, these probes are ideal, as they will access the endpoint in a similar way to the client applications.
   * *Tester Probes*: The second will begin with &quot;org.osg.srm.srmtester-&quot;. These will use the LBNL [[ReleaseDocumentation/Bestman][BeStMan]] [[Storage/SRMTester][srm-tester]] command to connect to your storage facility and run commands to check basic functionality connected to the SRM storage protocol.  The SRM tester uses the base SRM to test individual calls of the protocol and can provide detailed reports.  This application is tied to the [[ReleaseDocumentation/Bestman][BeStMan]] application and is ideal for testing it, though it can be used to test any SRM endpoint.
   * *Default probes*:  Also included in this document is a description of default storage probes.  The first will test stand-alone gridFTP servers and classic storage elements by using a globus-url-copy to a gridFTP server.  There are also description of the SRM ping probe and copy probe, which test rudimentary functions of a storage element.

Each of these types of probes is described in the section below.

%RED%NOTE:%ENDCOLOR% For the current version of RSV, any non-enabled probes need to be configured with the srm directory and web service path.  Make sure to follow the configuration file step below to ensure that each non-default probe has a configuration file with the correct settings.

---+++ Basic Client Probes

The basic client probes ( &quot;org.osg.srm.srmclient-*&quot;) will use SRM client commands to connect to your storage facility and run SRM client commands to check basic 
functionality connected to the SRM storage protocol.  The exact commands used are detailed under each probe&#39;s description below.  Each probe will return a status:

   * *OK (Green)*: This means the test was successful.
   * *Warning (Yellow)*: This means that the server returned &quot;Not supported&quot;.  This operation does not work, but only because it is not supported by your storage element.  For instance, release space and reserve space are not supported under !BeStMan gateway unless static tokens are configured.
   * *Critical (Red)*:  The test has failed.  Click on the link on the probe results web page for more details.

These probes have to use either the [[ReleaseDocumentation/FermiSrmClientCommands][Fermi SRM client]] (srmping, srmcp, etc) or the [[ReleaseDocumentation/LBNLSrmClient][LBNL client]] (srm-ping, srm-copy, etc).  These are included by default in the RSV installation.  The client type (Fermi or LBNL) can be changed by adding the &quot;srm-client-type&quot; in the configuration files manually (below).  By default, these probes use the LBNL client.  If you would like to use the Fermi client, please install it using the OSG repo by using =yum install dcache-srmclient=.

Description of the functionality for each probe is below:

   * *org.osg.srm.srmclient-copy:* Tests a SRM copy operation on the remote server.  First, uploads a file using srmcp/srm-copy from a local file to a file named like 1274991241-srmclient-probe-test-file-remote.14288 in the remote directory (numbers differ based on time and process id).  It then copies it to a new file called 1274991241-srmclient-probe-test-file-remote.142881274991241-srmclient-probe-test-file-remote.14288.copy (using srmcp/srm-copy).  It uses a srmls/srm-ls to verify that the copy has occurred.  Lastly, it performs a srmrm/srm-rm to clean up both copies.
   * *org.osg.srm.srmclient-get:* Tests SRM copy to get a file from the server.  Use srmcp/srm-copy to copy a file to the remote server.  Use srmcp/srm-copy to retrieve the file from the server.  Compares the two copies using the unix diff command.
   * *org.osg.srm.srmclient-mkdir:*  This command uses srmmkdir/srm-mkdir to create a directory on the storage element.  It uses srmls/srm-ls to verify that the directory exist.  The cleanup uses srm-rmdir/srm-rmdir to remove the temporary directory.
   * *org.osg.srm.srmclient-rmdir:* This command uses srmmkdir/srm-mkdir to create a directory, then uses srmrmdir/srm-rmdir to delete it.  It uses srmls/srm-ls to verify both that the directory was created and then that it also was later removed.
   * *org.osg.srm.srmclient-mv:* Tests the srmmv or srm-mv command.  This first copies a file to the storage element using srmcp/srm-copy.  It then moves it to a new name using srmmv/srm-mv.  It then uses srmrm/srm-rm to clean both the old name and new name off the server (in case the mv failed).
   * *org.osg.srm.srmclient-ping:* Pings a server using srmping/srm-ping.  Uses the exit status to verify whether the command was successful.
   * *org.osg.srm.srmclient-put:* Tests srmcp/srm-copy.  Put a file onto the server using srmcp/srm-copy, then use srmls/srm-ls to verify that the file was copied successfully.  Lastly, srmrm/srm-rm is used to clean this file off the storage element.
   * *org.osg.srm.srmclient-reservespace:* Test srm-reserve-space command to reserve a space.  This will only work if space reservation is enabled on the SRM endpoint.
   * *org.osg.srm.srmclient-releasespace:* Test srm-reserve-space then srm-release-space it. This will only work if space reservation is enabled on the SRM endpoint.
   * *org.osg.srm.srmclient-rm:* Use srmcp/srm-copy to copy a file to the server then remove it using srmrm/srm-rm.  Use srmls/srm-ls to verify the file has been removed.


---+++ Tester Probes

Note that these probes require the =srm-tester= application.  If you do not have it installed, you may need to install it.  With the OSG repositories installed, you can run =yum install srm-tester= to get this application.

Included in the optional SRM probes are two types of probes.  The second will begin with &quot;org.osg.srm.srmtester-&quot;.
These will use the LBNL [[ReleaseDocumentation/Bestman][BeStMan]] [[Storage/SRMTester][srm-tester]] command to connect to your storage facility and run commands to check basic 
functionality connected to the SRM storage protocol.  This application is provided with [[ReleaseDocumentation/Bestman][BeStMan]] and is ideally suited for testing the completeness and correctness of
[[ReleaseDocumentation/Bestman][BeStMan]] installations.  However, it can also be used to test other SRM endpoints as well.  Each probe will return a status:

   * *OK (Green)*: This means the test was successful.   
   * *Warning (Yellow)*: This means that the server returned &quot;Not supported&quot;.  This operation does not work, but only because it is not supported by your storage element.
   * *Critical (Red)*:  Either the test failed, or it was not tested, due to a dependent operation failing (i.e. if a put fails, then there is no file to get).  Click on the link on the probe results web page for more details.

Each probe runs one &quot;operation&quot;, which corresponds to a common task, such as getting a file.  Each test calls srm-tester with a different value in the &quot;-op&quot; parameter.  Some of these operations actually comprise multiple SRM commands or tests, so it is possible that one test fails, causing the subsequent tests to be not completed.  This would register as a failure.  In the case of a &quot;critical&quot; result, you can view the details, which will include a summary of all commands performed, and which have failed.  It will also show the detailed output of the srm-tester, which may give some clues as to why the operation failed.

Description of the functionality for each probe is below:

   * *org.osg.srm.srmtester-bringonline:* Test bringonline functionality.  This test will put a file, try to bring it to ONLINE latency, then will remove it.  This operation uses the following SRM operations:srmPrepareToPut, srmStatusOfPutRequest, gsiftp-put, srmPutDone, srmBringOnline, srmStatusOfBringOnlineRequest, srmLs, srmRm.  This test will only succeed if the srmBringOnline operation succeeds.
   * *org.osg.srm.srmtester-get:*  Test getting a file from the server.  This will put a file on the server, then get it using gsiftp.  It uses the SRM operations: srmPrepareToPut, srmStatusOfPutRequest, gsiftp-put, srmPutDone, srmPrepareToGet, srmStatusOfGetRequest, gsiftp-get, srmReleaseFiles, srmLs, srmRm.
   * *org.osg.srm.srmtester-getspacemeta:* This operation tests getting the meta-data attributes of a reserved space.  It reserves a space, then gets the meta-data, then releases the space.  It uses srmReserveSpace, srmGetSpaceMetadata, srmReleaseSpace.
   * *org.osg.srm.srmtester-getspacetokens:* This operation tests retrieving space tokens.  It uses the following SRM functionality: srmReserveSpace, srmGetSpaceTokens, srmReleaseSpace
   * *org.osg.srm.srmtester-gettransferprotocols:*  This tests the srmGetTransferProtocols operation.  It should return all valid protocols for returning data.
   * *org.osg.srm.srmtester-gsiftp:*  This tests getting a file via the gsiftp protocol.  It uses srmPrepareToPut, srmStatusOfPutRequest, gsiftp-put, srmPutDone, srmLs, srmRm, srmCopy-pull-gsiftp, srmStatusOfCopyRequest-pull-gsiftp.
   * *org.osg.srm.srmtester-ls:*  This tests browsing a directory.  It uses the srmLs functionality.
   * *org.osg.srm.srmtester-mkdir:*  This tests making a directory on the remote storage element.  This uses the operations srmMkdir and srmRmdir.
   * *org.osg.srm.srmtester-mv:* This tests moving a file from one location to a different location while on the remote storage element.  This operation actually calls srm-tester twice.  The first it calls with the operation put, in order to first prepare a file on the remote storage,  It then calls with the operation mv, which uses the srmMv, then srmRm to clean-up.
   * *org.osg.srm.srmtester-ping:*  This operation pings a server to see if it responds.  It only uses the srmPing operation.
   * *org.osg.srm.srmtester-pull:* This tests getting a file in &quot;pull&quot; mode.  This uses srmCopy-pull and srmStatusOfCopyRequest-pull.
   * *org.osg.srm.srmtester-push:* This tests putting a file onto the remote storage in &quot;push&quot; mode.  This uses srmCopy-push and srmStatusOfCopyRequest-push.
   * *org.osg.srm.srmtester-put:*  This tests copying a file onto the remote storage.  It uses a srmls in order to verify it.  The operations used are srmPrepareToPut, srmStatusOfPutRequest, gsiftp-put., srmPutDone, srmLs, srmRm.
   * *org.osg.srm.srmtester-release:*  This tests releasing a reserved space.  First, it must reserve a space where the release operation can be tested.  It uses srmReserveSpace, srmReleaseSpace.
   * *org.osg.srm.srmtester-reserve:*  This tests reserving a space on the storage element with which to put files.  This tests the srmReserveSpace operation.
   * *org.osg.srm.srmtester-rmdir:*  This tests removing a directory from the storage element.  It will need to create a directory first..  This uses the operations srmMkdir and srmRmdir.
   * *org.osg.srm.srmtester-srmrm:*  This tests removing a file from the storage element.  It will first copy a file to the server for testing.

For more information, see the [[SrmTester][srm-tester]] documentation.


---+++ Default storage probes

Several other simple storage probes are also shipped with RSV.  They are listed here with a short description.

   * *srm-ping-probe*: This probe will use the srm-ping command to test a server using the SRM protocol.  It is similar to the srmclient-ping probe.
   * *srmcp-srm-probe*: This probe will copy a file to and from an SRM endpoint using the SRM protocol.  It is similar to the srmclient-get probe.
   * *gridftp-simple-probe*:  This probe tests a gridFTP server.  This is useful if you do not have a full SRM-endpoint and use a classic storage element (gridFTP on the head node) or just have a standalone gridFTP server.  This probe will attempt to put a file a file on a gridFTP server using gsiftp (globus-url-copy).  It will then retrieve the file using gsiftp and verify that it was transferred correctly.  It then uses [[Storage/StorageUberFTP][UberFTP]] to clean up the file.


---++ Configuring RSV for storage

As part of the RSV installation, you will find a file =/etc/osg/config.d/30-rsv.ini= that configure-osg uses to configure RSV.
In order to use storage probes, you will need to specify three attributes in this file.

&lt;pre class=&quot;file&quot;&gt;
srm_hosts = host1:port1,host2:port2
srm_dir = /mount/point/for/host1,/mount/point/for/host2
srm_webservice_path = srm/v2/server,srm/managerv2
&lt;/pre&gt;

| *srm_hosts* | gw014k1.fnal.gov:8443,gw014k2.fnal.gov:10443 | A comma-separated list of host:port combination that specify the servers that will be tested.. |
| *srm_dir* | /mnt/hadoop,/osg/vo/engage | This is the common path that will be accessed. This mount point is the path on the storage element that the testing probes will attempt to access.  |
| *srm_webservice_path* | srm/v2/server,srm/managerv2 | This is the webservice path.  For dCache, it is &quot;srm/managerv2&quot;.  For [[ReleaseDocumentation/Bestman][BeStMan]], it is &quot;srm/v2/server&quot;. |

*Note: if you are using a stand-alone SE (and therefore do not want to test CE probes), also set ==enable_ce_probes = False==.*


After setting these appropriately, run the following (as root):
&lt;pre class=&quot;rootscreen&quot;&gt;
service rsv stop
configure-osg -v
configure-osg -c
service rsv start
&lt;/pre&gt;

---++ Enabling storage probes

RSV Probes can be enabled to run on a timed basis (usually hourly) or run once immediately.  Client probes and tester probes are not enabled by default.  This section briefly describes how to enable/run probes in general.  The following sub-sections go into more detail for each type probe.

To enable an optional RSV probe that is not on by default, you can run:
&lt;pre class=&quot;rootscreen&quot;&gt;
rsv-control --enable --host %RED%host probe-name%ENDCOLOR%
&lt;/pre&gt;

Most probes will run on a pre-specified schedule (usually hourly). To run a probe immediately, you can use the following command:
&lt;pre class=&quot;rootscreen&quot;&gt;
rsv-control --run --host %RED%host probe-name%ENDCOLOR%
&lt;/pre&gt;

More information on enabling specific storage probes is below.

---+++ Enabling basic client probes

SRM Client probes are optional RSV probes.  They are not enabled by default in a RSV installation.
You can enable the probes using [[RsvControl][rsv-control]] below, with COMMAND being one of the probes listed above.  
HOST is the hostname that you wish to test, including the port.  This will match what you have put in ==/etc/osg/config.d/30-rsv.ini==.

&lt;pre class=&quot;rootscreen&quot;&gt;
rsv-control --enable --host %RED%host%ENDCOLOR% org.osg.srm.srmclient-%RED%COMMAND%ENDCOLOR%
&lt;/pre&gt;
For example,
&lt;pre class=&quot;rootscreen&quot;&gt;
rsv-control --enable --host gw014k1.fnal.gov:8443 org.osg.srm.srmclient-ping
&lt;/pre&gt;

The host should be specified in the ==/etc/osg/config.d/30-rsv.ini== file with the correct webservice path and mount point.  If this host is not in the ==/etc/osg/config.d/30-rsv.ini==, you will need to either re-run ==configure-osg== script after adding it, or [[#Storage_Probe_Configuration_File][add probe configuration files manually]] with the webservice and mount point information.

---+++ Enabling tester probes

SRM Client probes are optional RSV probes.  They are not enabled by default in a RSV installation.
You can enable the probes using [[RsvControl][rsv-control]] below, with COMMAND being one of the probes listed above.
HOST is the hostname that you wish to test, including the port.  This will match what you have put in ==config.ini==.

&lt;pre class=&quot;rootscreen&quot;&gt;
rsv-control --enable --host %RED%host%ENDCOLOR% org.osg.srm.srmtester-%RED%COMMAND%ENDCOLOR%
&lt;/pre&gt;

For example,
&lt;pre class=&quot;rootscreen&quot;&gt;
rsv-control --enable --host gw014k1.fnal.gov:8443 org.osg.srm.srmtester-ping
&lt;/pre&gt;

The host should be specified in the ==/etc/osg/config.d/30-rsv.ini== file with the correct webservice path and mount point.  If this host is not in the ==/etc/osg/config.d/30-rsv.ini==, you will need to either re-run ==configure-osg== script after adding it, or [[#Storage_Probe_Configuration_File][add probe configuration files manually]] with the webservice and mount point information.

*NOTE: If you are enabling the gsiftp, push, or pull metrics, you will need to perform an extra step.*

The probes org.osg.srm.srmtester-gsiftp, org.osg.srm.srmtester-pull, and org.osg.srm.srmtester-push test 3rd party copies by using another server to copy a test file from.  Note that not all SRM servers (e.g. [[ReleaseDocumentation/Bestman][BeStMan]] gateway) support this kind of copy, so you may not want to enable these probes for those sites.  To test this, you will need another server to copy a file from.  You will need to add this location in the copysource parameter in the file ==$VDT_LOCATION/osg-rsv/etc/HOST:PORT/org.osg.srm.srmtester-CMD.conf== (where CMD is either pull, push, or gsiftp):

&lt;pre class=&quot;file&quot;&gt;
[org.osg.srm.srmtester-put args]
srm-destination-dir=/example/mount/point/dir
srm-webservice-path=srm/managerv2
copysource=gsiftp://someserver:port/withapath/of/a/test-file
&lt;/pre&gt;

For more on these configuration, see the below section on [[#Storage_Probe_Configuration_File][adding probe configuration files manually]].


---++ Storage Probe Configuration Files (optional)

The above procedure explains how to use ==configure-osg== to configure RSV storage probes.  That script will create configuration files that determines how the probes will access the storage element.  

This section will describe those configuration files in more detail and where they are located.  For most cases, using the above method will be sufficient to configure the storage probes.  Modifying the configuration files manually is only needed if the above procedure can not be used.  For instance, if you want to pass additional arguments to the probes (ie for third party copy testing) or if you want to access multiple mount points with different probes on the same host, additional configuration is necessary for these custom installations.  If you already have an OSG installation (for a CE for instance) and do not want to reconfigure the whole installation with ==configure-osg==, you can also add these files manually. 

For each host, there will be one file per storage probe with the name ==/etc/rsv/metrics/HOST:PORT/probename.conf==.  This file contains the arguments passed to the probe on execution.  By default, it is populated with the attributes in the config.ini file.  However, you can add or change arguments in this file if needed.  By default, each file will have the mount point in the srm-destination-dir argument as well as the webservice (usually &quot;srm/v2/server&quot; for [[ReleaseDocumentation/Bestman][BeStMan]] or &quot;srm/managerv2&quot; for dcache) in the srm-webservice-path arguments.  Certain srmtester probes that test 3rd party copies will also need the &quot;copysource&quot; argument specified for the 3rd party address (see previous section).

Note that non-default probes will need this file in order to configure the probes.  If this file does not exist, non-default probes may not function correctly.

&lt;pre class=&quot;file&quot;&gt;
[org.osg.srm.srmtester-put args]
srm-destination-dir=/mount/point/for/host
srm-webservice-path=srm/managerv2
&lt;/pre&gt;

Entries in this file will be passed to the probe. 


---++ Troubleshooting

These can be found in ==/var/logs/rsv/probes==.  
There will be a output and error file for each host/probe combination, for instance: ==gw014k1.fnal.gov:8443__org.osg.srm.srmping.log==.
For failed probes, more detailed information can be found by clicking the probe on the results web page.


---++ Comments
%COMMENT{type=&quot;tableappend&quot;}%

&lt;!-- CONTENT MANAGEMENT PROJECT
############################################################################################################
   DEAR DOCUMENT OWNER
   ===================

   Thank you for claiming ownership for this document! Please fill in your FirstLast name here:
   * Local OWNER          = DouglasStrain

   Please define the document area, choose one of the defined areas from the next line
   DOC_AREA = (ComputeElement|Storage|VO|Security|User|Monitoring|General|Trash/Trash/Integration|Operations|Tier3)
   * Local DOC_AREA       =  Storage

   define the primary role the document serves, choose one of the defined roles from the next line
   DOC_ROLE = (EndUser|Student|Developer|SysAdmin|VOManager|Documenter)
   * Local DOC_ROLE       = SysAdmin

   Please define the document type, choose one of the defined types from the next line
   DOC_TYPE = (Troubleshooting|Training|Installation|HowTo|Planning|Navigation|Knowledge)
   * Local DOC_TYPE       = Installation
   
   Please define if this document in general needs to be reviewed before release ( %YES% | %NO% )
   * Local INCLUDE_REVIEW = %YES%

   Please define if this document in general needs to be tested before release ( %YES% | %NO% )
   * Local INCLUDE_TEST   = %YES%

   change to %YES% once the document is ready to be reviewed and back to %NO% if that is not the case
   * Local REVIEW_READY   = %YES%

   change to %YES% once the document is ready to be tested and back to %NO% if that is not the case
   * Local TEST_READY     = %YES%

   change to %YES% only if the document has passed the review and the test (if applicable) and is ready for release
   * Local RELEASE_READY  = %YES%


   DEAR DOCUMENT REVIEWER
   ======================

   Thank for reviewing this document! Please fill in your FirstLast name here:
   * Local REVIEWER       = NehaSharma
  
   Please define the review status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local REVIEW_PASSED  = %YES%


   DEAR DOCUMENT TESTER
   ====================

   Thank for testing this document! Please fill in your FirstLast name here:
   * Local TESTER         =  NehaSharma
  
   Please define the test status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local TEST_PASSED    = %YES%
############################################################################################################
--&gt;




-- Main.DouglasStrain - 31 Oct 2011
