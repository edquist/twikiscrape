---+!! XrootD plug-ins testing

%TOC{depth=&quot;2&quot;}%

---# About This Document

%ICON{hand}% This document is intended for OSG Software/Release teams to gather information on testing XrootD plug-ins

---# About XrootD

---# Requirements

   * There nodes with  root access

---# Hadoop name node installation:

Use the following script with option 1:

&lt;pre class=&quot;file&quot;&gt;
#!/bin/bash
set -e

select NODETYPE in namenode datanode gridftp; do
  [[ $NODETYPE ]] &amp;&amp; break
done
case $NODETYPE in
  namenode ) NAMENODE=$HOSTNAME ;;
         * ) read -p &#39;hostname for NAMENODE? &#39; NAMENODE ;;
esac
echo NODETYPE=$NODETYPE
echo NAMENODE=$NAMENODE
read -p &#39;ok? [y/N] &#39; ok
case $ok in
  y*|Y*) ;;  # ok
      *) exit ;;
esac
#yum install --enablerepo=osg-minefield osg-se-hadoop-$NODETYPE
yum install osg-se-hadoop-$NODETYPE
case $NODETYPE in
  namenode|datanode )
    mkdir -p /data/{hadoop,scratch,checkpoint}
    chown -R hdfs:hdfs /data
    sed -i s/NAMENODE/$NAMENODE/ /etc/hadoop/conf.osg/{core,hdfs}-site.xml
    cp /etc/hadoop/conf.osg/{core,hdfs}-site.xml /etc/hadoop/conf/
    touch /etc/hosts_exclude
    ;;
  gridftp )
    ln -snf conf.osg /etc/hadoop/conf
    sed -i s/NAMENODE/$NAMENODE/ /etc/hadoop/conf.osg/{core,hdfs}-site.xml
    echo &quot;hadoop-fuse-dfs# /mnt/hadoop fuse server=$NAMENODE,port=9000,rdbuffer=131072,allow_other 0 0&quot; &gt;&gt; /etc/fstab
    mkdir /mnt/hadoop
    mount /mnt/hadoop
    cp -v /etc/redhat-release /mnt/hadoop/test-file
    sed -i &#39;/globus_mapping/s/^# *//&#39; /etc/grid-security/gsi-authz.conf
    sed -i s/yourgums.yourdomain/gums.fnal.gov/ /etc/lcmaps.db
    mkdir /mnt/hadoop/fnalgrid
    useradd fnalgrid -g fnalgrid
    chown fnalgrid:fnalgrid /mnt/hadoop/fnalgrid
    service globus-gridftp-server start
    if type -t globus-url-copy &gt;/dev/null; then
      globus-url-copy file:////bin/bash  gsiftp://$HOSTNAME/mnt/hadoop/fnalgrid/first_test
    else
      echo globus-url-copy not installed
    fi
    ;;
esac
case $NODETYPE in
  namenode ) su - hdfs -c &quot;hadoop namenode -format&quot; ;;
esac
service hadoop-hdfs-$NODETYPE start

&lt;/pre&gt;

---# Hadoop data node installation

   * Run same script as before but with option number 2.
   * Install xrootd-server: &lt;pre class=&quot;rootscreen&quot;&gt; yum install xrootd-server &lt;/pre&gt;
   * Install xrootd-plugins &lt;pre class=&quot;rootscreen&quot;&gt; yum install xrootd-cmstfc xrootd-hdfs&lt;/pre&gt;

---# Gridftp installation

Run same as script but with option number.

---# Testing instructions

---# On the name node:

&lt;pre class=&quot;rootscreen&quot;&gt;
[root@fermicloud092 ~]# hdfs dfs -ls /test-file
Found 1 items
-rw-r--r--   2 root root          0 2014-07-21 15:57 /test-file
&lt;/pre&gt;

This means your hadoop is working.

Modify the file =/etc/xrootd/xrootd-clustered.cfg=
to look like this:
&lt;pre class=&quot;file&quot;&gt;
xrd.port 1094

# The roles this server will play.                                                                                            
all.role server
all.role manager if xrootd.unl.edu
# The known managers                                                                                                          
all.manager srm.unl.edu:1213
#all.manager xrootd.ultralight.org:1213                                                                                       

# Allow any path to be exported; this is further refined in the authfile.                                                     
all.export / nostage

# Hosts allowed to use this xrootd cluster                                                                                    
cms.allow host *

### Standard directives                                                                                                       
# Simple sites probably don&#39;t need to touch these.                                                                            
# Logging verbosity                                                                                                           
xrootd.trace all -debug
ofs.trace all -debug
xrd.trace all -debug
cms.trace all -debug

# Integrate with CMS TFC, placed in /etc/storage.xml                                                                          
oss.namelib /usr/lib64/libXrdCmsTfc.so file:/etc/xrootd/storage.xml?protocol=hadoop

xrootd.seclib /usr/lib64/libXrdSec.so
xrootd.fslib /usr/lib64/libXrdOfs.so
ofs.osslib /usr/lib64/libXrdHdfs.so
all.adminpath /var/run/xrootd
all.pidpath /var/run/xrootd

cms.delay startup 10
cms.fxhold 60s
cms.perf int 30s pgm /usr/bin/XrdOlbMonPerf 30

oss.space default_stage /opt/xrootd_cache
&lt;/pre&gt;

Create file =/etc/xrootd/storage.xml= and place this:

&lt;verbatim&gt;
&lt;storage-mapping&gt;
&lt;lfn-to-pfn protocol=&quot;hadoop&quot; destination-match=&quot;.*&quot; path-match=&quot;.*/+tmp2/test-file&quot; result=&quot;/test-file&quot;/&gt;
&lt;/storage-mapping&gt;
&lt;/verbatim&gt;

For el7 the instrucctions are a little bit different. See:

https://jira.opensciencegrid.org/browse/SOFTWARE-2198?focusedCommentId=334667&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-334667

Now from a node do:

&lt;pre class =&quot;rootscreen&quot;&gt;
xrdcp --debug 3 root://yourdatanode.yourdomain:1094//tmp2/test-file .
&lt;/pre&gt;



If it is sucessful it would have tested both cmstfc and hdfs plugins
-- Main.EdgarFajardo - 25 Jul 2014

