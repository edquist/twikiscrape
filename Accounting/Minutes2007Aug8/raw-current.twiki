---+!!&lt;nop&gt;%TOPIC%
%TOC%

---++Introduction

Minutes of Gratia meeting
   * Last meeting: [[Minutes2007Aug1][August 1st]]
   * Previous meetings: MeetingMinutes
   * Coordinates: Wednesday at 1:30pm CST/CDT, 1-510-665-5437 and use the meeting ID: 2966. 

---++Attending
   * TBA.
   * Apologies: TBA

---++Action items from previous meeting:

---++Gratia sysadmin and operations tasks

It&#39;s time to have another meeting between Grid Dept. staff and
the rest of the Gratia project on the long term plans for the Gratia cluster.
There are two major categories: Known sysadmin tasks for which we
have to plan downtimes, and discussion of how to administer and operate
the services long term.

   1. Known sysadmin tasks on Steve Timm&#39;s plate:
      A. Finish load of lvm and Xen instances on gratia01,02,03,05.
 	    Fill in test twiki to document same.
      A. Set downtimes to upgrade memory (and disk) on some gratia
 	machines using the parts left over from the main Fermigrid machines.
 	Order will be:
         1. gratia08  2-&gt;6 GB RAM
         1. gratia09  2-&gt;6 GB RAM
         1. gratia03  2-&gt;6 GB RAM, plus 2x73GB disks
         1. gratia05  2-&gt;6 GB RAM
         1. gratia01  2-&gt;6 GB RAM, plus 2x73GB disks
 		Suggest Tuesdays in sequence, August 14, 21 and maybe 28
 		During this downtime verify that KVM cables work
 		on gratia08,09.
             See https://twiki.grid.iu.edu/twiki/bin/view/Accounting/GratiaDevAndTestEnviron
      A. Test TiBS restore on gratia06, gratia07;  The 2 largest tables have been excluded.
      A. Make further tests with RAID10 arrays, compare speed to RAID 5.
  	    Decide whether or not to convert gratia07,08,09 to RAID10
 	    based on these results.
          At the time of the downtime of gratia08, Steve will test the speed of RAID10 on gratia06.
      A. Label console cables and power cords, dress cables.
      A. Are any other system rpms necessary in the development
 		machines or xen instances of same, if so, add them.
      A. Learn how to use LVM to enlarge the appropriate partitions
 	    when it comes time to do so.

   1. Planning decisions that need to be made.
      A. Set a plan for how to run all the services (mysql, tomcat) as
 		non-root.
          Steve will update mysql on gratia06 and gratia07
          Chris will update Tomcat sometimes in September.
      A. Determine optimum disk configuration on collectors
 		gratia08,gratia09
          /data partition will need to be backed-up.
          For the database machine, we need a meeting in October to discuss data amount trends and how to address.
      A. Who authorizes giving someone an account to log in
 		as gratia admins?
          Project lead.
      A. Mysql administration (dsg-dbas, D. Bonham et al to lead effort).
         1. how best to back up the database
            A. investigate mysql 5.2 and its table file
 			     vertical partitioning.
            A. any better way than mysqlhotcopy to dump the
 			     database to the folders where it can
 			     be backed up from?
            A. Any way to have a live clustered database
 			     for live failover?
            A. Any place other than TiBS to back it up,
 			     enstore/dCache maybe?
         1. how to plan for unbounded growth of database
          For the database machine, we need a meeting in October to discuss data amount trends and how to address.
      A. Operating the services:
         1. FermiGrid staff learn how to do the complex interventions
 			that have recently been necessary, or
         1. the software is made to work such that those complex
 			interventions are not necessary or
         1. Gratia staff stay on to operate the service indefinitely.
         1. Upgrades are made infrequently enough so that
 			the process, which is already documented, can
 			actually be simplified for routine operations
 			by FermiGrid staff.
         1. Service level agreement agreed to and implemented
 			between FermiGrid, OSG Operations, and Gratia project
      A. Plans for new hardware in FY08 and what it is for.
      A. Do we want dedicated ITB machines, either real or Xen instances?
 		(we think we do).
      A. Make plans for converting over all Fermilab probes to
 		point to gratia-fermi server.

---++DB and Schema issues

Philippe: We upgrade to the last hibernate version which solved a race condition.

Chris: We also corrected the VONameCorrection tables updates.

Philippe: This morning I clean-up the DupRecord table (by removing the actual
duplicate older than 1 months).

Diana: I will copy the backup of the production down to a node where I will
make some test.
Diana: I will ask around to figure out when mysql 5.1 will be becoming production

---++Collector/Report development

John: We send an update of the Collector and probes to VDT (1.8.0a).

John: I am nearing finding the problem with Margherita&#39;s collector.  It seems
to be a jar files conflict (axis.jar).

Penelope: I am working on cleaning up the list of jar files we are using.

Jeff: I have an initial version of the report library for birt 2.2.  I will need to
redo the rptdesign files, however most of the tedious part is already been 
factored in the library.

Jeff: I am looking into cumulative area charts.

Jeff: I am writing down the list of priorities for the report developement.

---++Probes

---++Storage Probe

---++Test Bed

John: I will try to reproduce the case where the default condor probe is
sending duplicates.

---++Metrics

---++Any Other Business

John: I re-updated the LCG data with a few more sites.
