---+!! Main gratia DB - Upgrade to v0.34.9%BR%
%TOC%

%STARTINCLUDE% &lt;!--
   * Set EDITTHISTEXT = &lt;div class=&quot;twikiSmall&quot;&gt;&lt;a href=&quot;%TOPIC%&quot;&gt;edit this section&lt;/a&gt;&lt;/div&gt;
--&gt;

---+ Main gratia DB - Upgrade to v0.34.9
%EDITTHISTEXT%

The main Gratia database ( *gratia* ) served by the *gratia09:/data/tomcat-gratia* instance will require a very long conversion time. So to maximize availability we will:
   1 create a current copy of the *gratia06/gratia* database on *gratia07* 
   1 using a temporary Gratia collector on *gratia08:/data/tomcat-conversion* 
      * this collector will be upgraded to v0.34.9 allowing the new summary table and md5v2 checksums to be calculated. 
      * we will then replicate from *gratia06* to *gratia07* to &quot;catch up&quot; the database before we switch the production *gratia09:/data/tomcat-gratia* over to using it. 
   1 switch the current *gratia09:/data/tomcat-gratia* to use the *gratia07/gratia* database 
   1 perform the upgrade of the *gratia06/gratia* database to v0.34.9 using the Gratia collector on *gratia08:/data/tomcat-conversion* . 
   1 While the checksum upgrades are occurring, we will replicate from *gratia07* to *gratia06* so the &quot;catch up&quot; time to make it current is reduced. 
   1 when the upgrade is complete (inclusive of the conversion to the new md5 key), we will switch the *gratia09:/data/tomcat-gratia* instance back to using the *gratia06/gratia* database 

During the upgrade period, this will be the tomcat/database environement for the *gratia* database: 
%TABLE%
| *Tomcat instance* | *Database instance* |
| gratia09:/data/tomcat-gratia port 8880 | gratia07:/data/mysqldb/gratia port 3320 |
| gratia08:/data/tomcat-conversion port 8884 | gratia06:/data/mysqldb/gratia port 3320 |

The above is a high level summary of the process. The details are contained in subsequent sections.

---++ Create a copy of the current database on *gratia07*
 On 5/28, the *gratia07:/data/mysqldb* was re-partitioned into a single 200Gb area to provide the required space for the *gratia* database.

---+++ Create the *gratia07:gratia* database using the ZRM backup
 This is in process now (5/30) and a finalized procedure will be included when it completes.

%GREEN%Done - 6/3/08 08:00 CDT%ENDCOLOR% %BR%

---+++ Configure *gratia08:/data/tomcat-conversion* to use the *gratia07:gratia* database
 On *gratia08*, edit the */data/tomcat-conversion/gratia/service-configuration.properties* file for this resulting attribute: 
   * service.mysql.url=jdbc:mysql://gratia07.fnal.gov:3320/gratia 

%GREEN%Done - 6/3/08 12:37 CDT (John Weigand)%ENDCOLOR% %BR% %GREEN%Re-confirmed - 6/11/08 10:30 CDT (John Weigand)%ENDCOLOR%

---+++ Upgrade *gratia08:/data/tomcat-conversion* to *v0-34-9*
 On *gratia08* : 
   1 Stop the tomcat service 
      * service tomcat-conversion stop 
      * %GREEN%Done - 6/11/08 14:48 CDT%ENDCOLOR% 

On *gratia07* :
   1 Disable the checksum upgrade on *gratia07/gratia* database. In a !MySql client: 
      * update !SystemProplist set cdr=1 where car=&#39;gratia.database.disableChecksumUpgrade&#39;; 
      * %GREEN%Done - 6/11/08 14:51 CDT%ENDCOLOR% 

Back on *gratia08* :
   1 Perform the upgrade to v0.34.9 
      * pswd=xxx 
      * source=/home/gratia/gratia-releases/gratia-v0.34.9 
      * pgm=/home/gratia/gratia-releases/gratia-v0.34.9/common/configuration/update-gratia-local 
      * $pgm -d $pswd -S $source -s conversion 
   1 Effective with this release, there is an administrative login process that, by default, does not allow access to the admin functions. You will need to update the __TOMCAT_LOCATION/gratia/service-configuration.properties__ file with the following attributes. You will also need to change 2 connection attributes, as well. (Note that if you forget to do this, the administrator can be added at anytime without restarting the tomcat service): 
      * service.admin.DN.0=/DC=gov/DC=fnal/O=Fermilab/OU=People/CN=Philippe G. Canal/CN=UID:pcanal 
      * service.admin.DN.1=/DC=org/DC=doegrids/OU=People/CN=Christopher H. Green 851859 
      * service.admin.DN.2=/DC=org/DC=doegrids/OU=People/CN=John Weigand 458491 
      * service.admin.DN.3=/DC=org/DC=doegrids/OU=People/CN=Steven Timm 74183 
      * service.admin.DN.4=/DC=gov/DC=fnal/O=Fermilab/OU=People/CN=Steven C. Timm/CN=UID:timm 
      * service.admin.DN.5=/DC=org/DC=doegrids/OU=People/CN=Dan Yocum 346615 
      * service.admin.DN.6=/DC=gov/DC=fnal/O=Fermilab/OU=People/CN=Dan Yocum/CN=UID:yocum 
      * 
      * service.open.connection=http://gratia-fermi.fnal.gov:8884 
      * service.secure.connection=https://gratia-fermi.fnal.gov:8860 
   1 *IMPORTANT IMPORTANT... THESE MUST BE CHANGED* 
      * %RED%service.mysql.url=jdbc:mysql:// *gratia07*.fnal.gov:3320/gratia%ENDCOLOR% in the *service-configuration.properties* file 
      * in *post-install.sh*, change the mysql client execution *from* %RED%gratia-db01%ENDCOLOR% *to* %RED%gratia07%ENDCOLOR%. 
   1 Start the tomcat service 
      * service tomcat-conversion start 

%GREEN%Done - 6/11/08 14:55 CDT%ENDCOLOR% %BR% %RED%First shot was against the production database. I did not realize the _collector-pro.dat_ file set the mysql to gratia_db01:3320/gratia. Chris bailed me out and confirmed that no damage had occured. Chris changed the _collector-pro.dat_ for the _conversion_ instance to garbage data to avoid this on future releases forcing manually changing the file. I will add this to the upgrade instructions for the *gratia09:tomcat-gratia* . %ENDCOLOR% %BR% %GREEN%Re-Done - 6/11/08 15:21 CDT%ENDCOLOR%

%BLUE%First thing it does is add the _GridDescription_ to the _JobUsageRecord_Meta_ table.%BR% In !MySql client ( _show processlist;_ ):
| Id  | User  | Host  | db  | Command | Time  | State  | Info  |
| 2786 | gratia | gratia08.fnal.gov:11262 | gratia | Query  | 57891 | copy to tmp table | alter table !JobUsageRecord _Meta add column !GridDescription varchar(255) |
 Started: 6/11 15:20 CDT%BR% Status as of 6/12 07:27 CDT 
   * -rw-rw---- 1 gratia gratia 23G Jun 5 09:08 !JobUsageRecord_Meta.ibd 
   * -rw-rw---- 1 gratia gratia 14K Jun 11 15:20 #sql-3275_ae2.frm 
   * -rw-rw---- 1 gratia gratia 16G Jun 12 07:27 #sql-3275_ae2.ibd 
%ENDCOLOR%

%GREEN% !GridDescription add to !JobUsageRecord _Meta table
   * Started - 6/11 15:21 CDT Ended - 6/12 22:30 CDT Elapsed - 31:09 md5v2 and index add to !JobUsageRecord _Meta 
   * Started - 6/12 23:26 CDT Ended - 6/14 10:07 CDT Elapsed -34:41 !MasterSummary table creation (started tomcat-conversion service) 
   * Started - 6/14 10:45 CDT Ended - 6/12 CDT Elapsed &lt;verbatim&gt;
Jun 14, 2008 10:55:21 AM net.sf.gratia.util.Logging log
FINE: Executing: /data/tomcat-conversion/gratia/post-install.sh summary
ABOVE ONE WAS AGAINST THE gratia06 database as the post-install.sh script needed to be changed too

Jun 14, 2008 11:21:24 AM net.sf.gratia.util.Logging log
FINE: Executing: /data/tomcat-conversion/gratia/post-install.sh summary

&lt;b&gt;Jun 15, 2008 3:01:31 AM net.sf.gratia.util.Logging log
FINE: ERROR - ERROR 1206 (HY000) at line 45: The total number of locks exceeds the lock table size&lt;/b&gt;

In the grati07.fnal.gov.err file....
080615  2:47:28  InnoDB: WARNING: over 67 percent of the buffer pool is occupied by
InnoDB: lock heaps or the adaptive hash index! Check that your
InnoDB: transactions do not set too many row locks.
InnoDB: Your buffer pool size is 512 MB. Maybe you should make
InnoDB: the buffer pool bigger?
InnoDB: Starting the InnoDB Monitor to print diagnostics, including
InnoDB: lock heap and hash index sizes.


Jun 15, 2008 13:30
Set increased my.cnf variable:
innodb_buffer_pool_size = 512M
to
innodb_buffer_pool_size = 768M

also stopped mysql_test instance... restarted mysql ... restarted tomcat-conversion

Jun 15, 2008 1:34:57 PM net.sf.gratia.util.Logging log
FINE: Executing: /data/tomcat-conversion/gratia/post-install.sh summary
Jun 16, 2008 9:27:50 AM net.sf.gratia.util.Logging log
FINE: OUTPUT&gt;post-install.sh: loading /data/tomcat-conversion/gratia/build-summary-tables.sql ... OK 
Jun 16, 2008 9:27:51 AM net.sf.gratia.util.Logging log
FINE: OUTPUT&gt;post-install.sh: loading /data/tomcat-conversion/gratia/build-summary-view.sql ... OK
Jun 16, 2008 9:27:51 AM net.sf.gratia.util.Logging log
FINE: exitValue: 0
Jun 16, 2008 9:27:51 AM net.sf.gratia.util.Logging log
FINE: Executing: select count(*) from SystemProplist where car = &quot;gratia.database.summaryTableVersion&quot;
Jun 16, 2008 9:27:51 AM net.sf.gratia.util.Logging log
FINE: Command: Error: select count(*) from SystemProplist where car = &quot;gratia.database.summaryTableVersion&quot; : com.mysql.jdbc.CommunicationsException: Communications link failure due to underlying exception:
** BEGIN NESTED EXCEPTION **
java.io.EOFException
   &lt;/verbatim&gt; 

Apparently connection timed-out around 6/16 09:27. The summary table and views were updated successfully. Just failed in the update of the !SystemProplist table entries. Chris updated them manually. Then we recycled the *tomcat-conversion* service on gratia08.
&lt;verbatim&gt;
Jun 16, 2008 9:27:51 AM net.sf.gratia.util.Logging warning
WARNING: Command: Error: insert into SystemProplist(car,cdr) values(&quot;gratia.database.summaryTableVersion&quot;, &quot;38&quot;)

root      7218     1 20 10:05 ?        00:32:35 /data/jre/bin/java 
   &lt;/verbatim&gt; 
%ENDCOLOR%

*WAIT* until the summary tables have been created. Then you can proceed to the next step of &quot;catching up&quot; the *gratia07* database.

---+++ Bring the *gratia07* database up to current
 Since the *gratia07* database is based on a nightly backup and production has been collecting data from the CE nodes, it needs to be brought up to current by replicating from *gratia06* to *gratia07* using the administrative services *Replication* menu. 
   * on http://gratia.opensciencegrid.org:8880/gratia-administration 
   * both *Job Usage* and *Metric* replication services should be activated to replicate to:%BR% - &lt;nop&gt;http://gratia-fermi.fnal.gov:8884 
   * The starting *dbid* should be determined ( *once only* after the backup is restored) using the mysql client on *gratia07* %BR% - select max(dbid) from &lt;nop&gt;JobUsageRecord_Meta; %BR% - select max(dbid) from &lt;nop&gt;MetricRecord_Meta; %BR% 

%GREEN% *Partially done* - 6/3/08 13:45 CDT (John Weigand)
&lt;pre&gt;select max(dbid) from JobUsageRecord_Meta;  +-----------+ | max(dbid) | +-----------+ |  75242300 |  +-----------+  select max(dbid) from MetricRecord_Meta;  +-----------+ | max(dbid) | +-----------+ |      1506 |  +-----------+  *On gratia06:* update Replication set dbid=75242300  where openconnection=&#39;http://gratia-fermi.fnal.gov:8884&#39; and replicationid=52;  update Replication set dbid=1506  where openconnection=&#39;http://gratia-fermi.fnal.gov:8884&#39; and replicationid=54;  &lt;/pre&gt;

Starting point (approx 6/3/08 14:00 CDT)
| gratia06 max(dbid) | 75,851,594 |
| gratia07 max(dbid) | 75,242,300 |
| catch up | 609,294 |

Catch up complete around 6/3/08 23:00 CDT
| hour UTC | updates |
| 080604 12 |  7715 |
| 080604 11 |  8224 |
| 080604 10 |  8435 |
| 080604 09 |  6962 |
| 080604 08 |  7869 |
| 080604 07 |  8005 |
| 080604 06 |  7753 |
| 080604 05 |  6874 |
| 080604 04 |  7944 |
| 080604 03 |  9629 |
| 080604 02 |  14588 |
| 080604 01 |  92283 |
| 080604 00 |  89794 |
| 080603 23 |  87849 |
| 080603 22 |  70699 |
| 080603 21 |  89476 |
| 080603 20 |  89201 |
| 080603 19 |  32873 |

%ENDCOLOR%

%GREEN% *2nd round of &quot;catchup&quot; statistics*
   * started at 6/16 10:10 
   * 2M records to process 
   * at 6/16 12:46 these are the counts. 
| Period | !JobUsage | Metric |
| 1 hours ago  | 43173 | 0 |
| 2 hour ago | 35046 | 0 |
| 3 hours ago  | 7590 | 25 |

%ENDCOLOR%

*Wait* until the *gratia07* is caught up to the *gratia06* database. You can monitor this by:
   * on *gratia06* %BR% - select max(dbid) from &lt;nop&gt;JobUsageRecord_Meta; %BR% - select max(dbid) from &lt;nop&gt;MetricRecord_Meta; %BR% 
   * on *gratia07* %BR% - select max(dbid) from &lt;nop&gt;JobUsageRecord_Meta; %BR% - select max(dbid) from &lt;nop&gt;MetricRecord_Meta; %BR% 

When they are close, stop the *administrative update service* on
   * http://gratia.opensciencegrid.org:8880/gratia-administration 

The replication services should still be running to ensure we &quot;catch up&quot; the last of the updates on *gratia06* to *gratia07*. The replication activity shall be complete when both replication data pumps (as shown by =gratia-0.log= on gratia08) have been through at least one check-duplicate cycle without uploading records.

Then, turn off both the *Job Usage* and *Metric* replication services on:
   * http://gratia.opensciencegrid.org:8880/gratia-administration for &lt;nop&gt;http://gratia-fermi.fnal.gov:8884. 
   * Do *not* delete the entries at this time.%BR% 

Take note of max(dbid) in =JobUsageRecord_Meta= and =MetricRecord_Meta= on *gratia07*, as these numbers will be used to set up replication from *gratia07* back to *gratia06* while checksums are being upgraded on *gratia06*.

---+++ Update the Replication services on *gratia06* to *gratia07*
 On *gratia06*, if there are *Job Usage* and *Metric* replication services active, we will need to create entries in the *gratia07* instance as this will shortly become our production database.

When creating these entries, we will need to insure that we start with the last record replicated from *gratia06*, which may not have the same dbid on gratia06 as it did on gratia07.

Instructions for doing this will be provided later if this needs to be performed for this release.

This should be done *before* we switch the *gratia09:/data/tomcat-gratia* to use the *gratia07/gratia* database.

The entries should be added and *only* a test that the entry is correct made at this time. We will set the *starting dbid* later and activate the entry after we switch the tomcat collectors.

---++ Stop *gratia09:/data/tomcat-gratia* and *gratia08:/data/tomcat-conversion*
 Stop each collector: 
   1 on *gratia08* 
      * service tomcat-conversion stop 
   1 on *gratia09* 
      * service tomcat-gratia stop 

---++ Upgrade the current *gratia09:/data/tomcat-gratia* to *v0.34.9*
 &lt;strong&gt;REMEMBER: 
   1 on gratia07 my.cnf, we need to eliminate the binary log files.... NO BACKUPS WILL NOT WORK W/O BINARY LOGS... AT LEAST SO FAR. 
   1 on gratia06 my.cnf, we need to change the buffer size as we did on gratia07. Also need to eliminate the binary log files. This will mean stopping all collectors and bouncing the mysql. BE CAREFUL THAT BACKUPS HAVE COMPLETED. 
   1 backups on gratia07 
&lt;/strong&gt;

On gratia09:
   1 Perform the upgrade to v0.34.9 
      * pswd=xxx 
      * source=/home/gratia/gratia-releases/gratia-v0.34.9 
      * pgm=/home/gratia/gratia-releases/gratia-v0.34.9/common/configuration/update-gratia-local 
      * $pgm -d $pswd -S $source -s gratia 
   1 Effective with this release, there is an administrative login process that, by default, does not allow access to the admin functions. You will need to update the __/data/tomcat-gratia/gratia/service-configuration.properties__ file with the following attributes. You will also need to change 2 connection attributes, as well. (Note that if you forget to do this, the administrator can be added at anytime without restarting the tomcat service): 
      * service.admin.DN.0=/DC=gov/DC=fnal/O=Fermilab/OU=People/CN=Philippe G. Canal/CN=UID:pcanal 
      * service.admin.DN.1=/DC=org/DC=doegrids/OU=People/CN=Christopher H. Green 851859 
      * service.admin.DN.2=/DC=org/DC=doegrids/OU=People/CN=John Weigand 458491 
      * service.admin.DN.3=/DC=org/DC=doegrids/OU=People/CN=Steven Timm 74183 
      * service.admin.DN.4=/DC=gov/DC=fnal/O=Fermilab/OU=People/CN=Steven C. Timm/CN=UID:timm 
      * service.admin.DN.5=/DC=org/DC=doegrids/OU=People/CN=Dan Yocum 346615 
      * service.admin.DN.6=/DC=gov/DC=fnal/O=Fermilab/OU=People/CN=Dan Yocum/CN=UID:yocum 
      * 
      * service.open.connection=http://gratia.opensciencegrid.org:8880 
      * service.secure.connection=https://gratia.opensciencegrid.org:8845 
   1 Change the *post_install.sh* script to point to *gratia07.fnal.gov* 

%GREEN%Started 6/24 08:17 Done 6/24 08:24%ENDCOLOR%

---++ Switch *gratia09:/data/tomcat-gratia* to use the *gratia07/gratia* database
 Update the *service-configuration.properties* file to change the database that the production instance points to: *IMPORTANT IMPORTANT... THIS MUST BE CHANGED* 
   1 In *gratia09:/data/tomcat-gratia/gratia/service-configuration.properties* 
      * service.mysql.url=jdbc:mysql://%RED%gratia07%ENDCOLOR%.fnal.gov:3320/gratia %GREEN%Done 6/24 08:24%ENDCOLOR% 
   1 In *gratia09:/data/tomcat-gratia/gratia/post-install.sh*, change the mysql client execution *from* %RED%gratia-db01%ENDCOLOR% *to* %RED%gratia07%ENDCOLOR%. 
   1 Start the *gratia09* production collector *only* (it will be using the *gratia07* database 
      * service tomcat-gratia start 

At this point we have production gratia reporting and services back on-line and available. Verify there are no problems by tailing the log files in *gratia09:/data/tomcat-gratia/logs* .

%GREEN%Done 6/24 08:30%ENDCOLOR%

%RED%Problems:
   1 *catalina.out* exceptions &lt;pre&gt;command: select T.SiteName, P.currenttime, P.probename from Probe P, Site T where P.active = 1 and T.siteid = P.siteid order by T.SiteName,P.currenttime desc java.lang.ArrayIndexOutOfBoundsException &lt;/pre&gt; 
   1 *gratia-rmi-servlet0.log* - coming every 10 minutes. Chris thinks from a probe. &lt;pre&gt;INFO: RMIHandlerServlet: Error: Problematic req: org.apache.catalina.connector.RequestFacade@564a38 Jun 24, 2008 2:29:25 PM net.sf.gratia.util.Logging info &lt;/pre&gt; 
      * A v0.34.9a was installed (not put in CVS) as 11:35am to trouble-shoot the problem. 
      * A new v0.34.a installed (11:47 - 11:51) with problem fixed hopefully 
   1 Static reports appear to be truncating... should be landscape to fit in or scaled differently. 
%ENDCOLOR%

If all is well, we can proceed to the v0.34.9 upgrade of the *gratia06:gratia* database.

---++ Backups
 We will need to take backups on the *gratia07* database for the *gratia* database.

And also *stop* the backups on *gratia06* for the *gratia* database.

---++ Crons
 This section can be delayed depending on the time of day.

---+++ Cron processes during upgrade
 There are several processes (cron) that will need to be copied/modified on _gratia06_ and _gratia09_ for reports and interfaces. 
   1 gratia06 - user gratia 
      * APEL-WLCG interface &lt;pre&gt; dir=/home/gratia/interfaces/apel-lcg; cd $dir; ./lcg.sh --config=lcg.conf --date=current --update &lt;/pre&gt; This cron process can remain on *gratia06*. The only modification required is to the */home/gratia/interfaces/apel-lcg/lcg-db.conf* file for the following parameter: 
         * GratiaHost *gratia07*.fnal.gov &lt;p&gt; %GREEN%Done - 6/24 13:19%ENDCOLOR% &lt;/p&gt; &lt;p&gt; &lt;/p&gt; 
      * OSG daily reports &lt;verbatim&gt;
/home/gratia/gratia-summary/gratiaSum.cron.sh
/home/gratia/gratia-summary/daily_mail_cron.sh
/home/gratia/gratia-summary/range_mail_cron.sh --weekly
/home/gratia/gratia-summary/range_mail_cron.sh --monthly
/home/gratia/gratia-summary/rungratia.sh --production 
&lt;/verbatim&gt; 
      * CMS weekly reports &lt;verbatim&gt;/home/gratia/gratia-summary/cms_mail_cron.sh --weekly&lt;/verbatim&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt; Change in /home/gratia/gratia-summary/PSACCTReport.py the &lt;/p&gt;&lt;verbatim&gt;gMySQLConnectString = &quot; -h gratia-db01.fnal.gov -u reader --port=3320 --password=reader &quot;&lt;/verbatim&gt; %GREEN%Done - 6/24 13:20%ENDCOLOR% &lt;p&gt; &lt;/p&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt; &lt;/p&gt; 
   1 gratia06 - user root&lt;br /&gt; Database backups on *gratia06* will need to be changed to exclude the *gratia* database. This includes the purging of log files by the zrm process. &lt;pre&gt;/usr/local/bin/gratia_backup_cron.sh /usr/bin/mysql-zrm --action purge &lt;/pre&gt; 
%GREEN%Done 06/24 12:43 - commented the *gratia* database backup.

However, could not really stop the purging. So copied them to */backup/mysqldb/gratia/zrm.20080624.backup* to preserve them.%BR% Done 6/24 13:05 
%ENDCOLOR%

   1 gratia09 - user root&lt;br /&gt; The static reports cron on gratia09 *does not* require changing as it references the gratia09 gratia collector which will be pointing to the gratia07 database. 
   1 gratia07 - user root&lt;br /&gt; A database backup cron entry needs to be *added* to this cron. The appropriate zrm configuration files have already been added. &lt;pre&gt;/usr/local/bin/gratia_backup_cron.sh /usr/bin/mysql-zrm --action purge &lt;/pre&gt; The */usr/local/bin/gratia_backup_cron.sh* script needs to be copied over from *gratia06* to *gratia07* and modified to only backup the *gratia* database. There should be no copies made to other machines. &lt;p&gt; &lt;/p&gt; &lt;p&gt; &lt;/p&gt; 
%GREEN%Done 6/24/08 12:40

The backups are being performed in /test/backup and then copied to /backup/zrm.gratia07 after they are compressed. This is being done as the /test file system is the only one with sufficient space for the uncompressed dump. 
%ENDCOLOR%

---+++ Nebraska (Brian Bockelman) interfaces
 Notify Brian to effect the changes necessary for his processes to use the *gratia07:3320* database

%GREEN%Done on 6/20. Had Brian do this early. Re-verified on 6/24%ENDCOLOR%

---++ Upgrade the gratia06 database
---+++ Manual mysql client updates
 The first thing that has to be done is to bounce the gratia06 database to allow the new my.cnf entries to take affect. &lt;pre&gt;innodb_buffer_pool_size = 768M &lt;/pre&gt; This parameter was expended from 512 to 768 to hopefully avoid the table lock problem experienced on gratia07 last week.

The use of binary log files has been left in effect as they are needed for backups.

%GREEN%Started: 6/24 14:03 Ended: 6/14 14:06%ENDCOLOR%

Perform a manual mysql client execution of the following so we reduce the time for the tables to be changed. The hibernate instance single threads these.
&lt;pre&gt;alter table JobUsageRecord_Meta add column GridDescription varchar(255),  add column md5v2 varchar(255), add index index17(md5v2);    &lt;/pre&gt;

*MUST WAIT FOR THIS TO FINISH*

%GREEN%Started: 6/24 14:20 Completed: 6/26 12:59 Elapsed: 46:39 %ENDCOLOR%

---++ Switch the current *gratia08:/data/tomcat-conversion* to use the *gratia06/gratia* database
 Update *gratia08:/data/tomcat-conversion/gratia/service-configuration.properties* to point to the *gratia06/gratia* database: 
   * service.mysql.url=jdbc:mysql:// *gratia06*.fnal.gov:3320/gratia 

In *post-install.sh*, change the mysql client execution *from* %RED%gratia-db01%ENDCOLOR% *to* %RED%gratia06%ENDCOLOR%.

On *gratia08* ,start the newly-upgraded tomcat-conversion collector
   * service tomcat-conversion start 

*MUST WAIT FOR THE SUMMARY TABLE TO BE BUILT AND THE NEW CHECKSUM CALCULATIONS TO START.*

%GREEN%Started: 6/26 14:05 Ended: 6/27 15:00 Elapsed: 24:55
| Table | Started | Completed | Elapsed |
| !ProbeStatus  | 6/26 14:05 | 6/26 16:31 | 02:26 |
| !MasterSummaryData  | 6/26 16:31 | 6/27 15:00  | 22:29 |
%ENDCOLOR%

%GREEN% *Checksum calculation progress (number of records: 76,015,870 ):* 
%TABLE{ tableborder=&quot;1&quot; cellpadding=&quot;0&quot; cellspacing=&quot;1&quot; headerbg=&quot;#99CCCC&quot; databg=&quot;#FFFFCC, #FFFFFF&quot;}% 
%EDITTABLE{  header=&quot;|*Schema*|*URL*|*Description*|&quot; format=&quot;| text, 15 | text, 15 | text, 6 |&quot;  changerows=&quot;on&quot; quietsave=&quot;on&quot; editbutton=&quot;Edit table&quot; }%
| *Time* | *Current record* | *% Complete* |
| Jun 27 15:00 | | |
| Jun 30 09:34:12 | 18,995,566 | 23% |
| Jul 1 16:01 | 27,331,103 | 24% |
| Jul 2 08:39 | 29,731,103 | 39% |
| Jul 2 04:13 | 30,831,203 | 40% |
| Jul 2 08:16 | 31,841,303 | 42% |
| Jul 3 08:35 | 38,686,103 | 50% |
| Jul 7 13:20 | 66,110,503 | 86% |
| Jul 8 09:23 | 71,132,503 | 93% |
| Jul 9 01:24 | 75,226,303 | 99% |
| Jul 9 03:30 | approximately | 100% |

%ENDCOLOR%

%RED%June 30 10:15 - Logging was turned down from FINEST to FINE on the tomcat-collector so progress can no longer be measured using the log file. This was done in attempt to improve performance. The alternative is to perform a query on the database &quot;Select cnt(*) from !JobUsageRecord _Meta where md5v2 is NULL;%ENDCOLOR%

%RED%July 9 08:30 - Logging turned back up from FINE to FINEST to be able to view progress in duplicate resolution phase of the checksum upgrade. &lt;br /&gt;%ENDCOLOR%

%GREEN% *Checksum resolution progress :* &lt;br /&gt;%TABLE{ tableborder=&quot;1&quot; cellpadding=&quot;0&quot; cellspacing=&quot;1&quot; headerbg=&quot;#99CCCC&quot; databg=&quot;#FFFFCC, #FFFFFF&quot;}% 
%TABLE{ tableborder=&quot;1&quot; cellpadding=&quot;0&quot; cellspacing=&quot;1&quot; headerbg=&quot;#99CCCC&quot; databg=&quot;#FFFFCC, #FFFFFF&quot;}%
| Date | Total  | Dups  | Remaining | %_Compl | Elapsed_Hrs | Processed | Rate_per_hr | ETC |
| Jul 09 03:30 | 1109089 | Started |||||||
| Jul 09 08:50 | 1109089 | 24,722 |||||||
| Jul 09 10:58 | 1109089 | 30,737 |||||||
| Jul 09 13:02 | 1109089 | 40,737 |||||||
| Jul 09 20:00 | 1109089 | 160741 |  948348 | 14.4931 |  7.6514 |  130004 |  16990.9022 | 55 |
| Jul 10 00:00 | 1109089 | 229742 |  879347 | 20.7145 |  11.6514 |  199005 |  17079.9380 | 51 |
| Jul 10 04:00 | 1109089 | 280744 |  828345 | 25.3130 |  15.6517 |  250007 |  15973.1871 | 51 |
| Jul 10 08:00 | 1109089 | 290744 |  818345 | 26.2147 |  19.6514 |  260007 |  13230.9732 | 61 |
| Jul 10 12:00 | 1109089 | 349228 |  759861 | 31.4878 |  23.6511 |  318491 |  13466.2172 | 56 |
| Jul 10 16:00 | 1109089 | 417513 |  691576 | 37.6447 |  27.6517 |  386776 |  13987.4390 | 49 |
| Jul 10 20:00 | 1109089 | 480748 |  628341 | 43.3462 |  31.6514 |  450011 |  14217.7331 | 44 |
| Jul 11 00:00 | 1109089 | 542463 |  566626 | 48.9107 |  35.6514 |  511726 |  14353.6063 | 39 |
| Jul 11 04:00 | 1109089 | 590750 |  518339 | 53.2644 |  39.6517 |  560013 |  14123.3155 | 36 |
| Jul 11 08:00 | 1109089 | 600750 |  508339 | 54.1661 |  43.6514 |  570013 |  13058.3016 | 38 |
| Jul 13 12:00 | 1109089 | 1100758 |  8331 | 99.2488 |  95.6514 |  1070021 |  11186.6750 | 0 |

Started: Jul 09 03:30 Completed: Jul 13 12:00 Elapsed: 4 days 08:00 hours

%ENDCOLOR%

*MUST WAIT FOR CHECKSUM CALCULATIONS TO COMPLETE ALL THE WAY THROUGH THE FINAL RESOLUTION PHASE.*

%GREEN% *Created unique index on md5v2:*

Started: Jul 13 12:00 Completed: Jul 21 17:20 Elapsed: 8 days 05:20 hours

Comment: This took unexpectedly long presumably because this entailed a complete reorg of the !JobUsageRecord _Meta table which had grown in size to 45Gb during the checksum resolution phase. Upon completion (with the optimization), it was reduced to 31Gb in size.

%ENDCOLOR%

%GREEN% *Drop old md5 index:*

Started: Jul 21 17:20 Completed: Jul 23 14:20 Elapsed: 1 day 21:00 hrs

%ENDCOLOR%

*MUST WAIT FOR THIS TO COMPLETE*

---++ Backup the gratia06/gratia database

At this point and considering the length of time to get here, a database backup is critical.

As the other databases on gratia06 already have cron scheduled backups occuring, we may have to improvise a little on how we do this depending on the time of day.

The cron job that is executed nightly is:
   * 43 2 !* !* !* /usr/local/bin/gratia_backup_cron.sh 

At this point, the specifics on the &quot;how&quot; will be left open as it will depend on when the step can be started. Running from cron is recommended however to avoid any problems should the machine go down during the upgrade.

*MUST WAIT FOR THE BACKUP TO COMPLETE THE MYSQLDUMP PHASE.*

%GREEN%

Started: Jul 23 14:45
mysqldump phase ended Jul 23 18:41
Elapsed: 3:56

%ENDCOLOR%

*WE CAN PROCEED ONCE IT GETS INTO THE COMPRESSION PHASE.*

---++ 2nd Upgrade of gratia08:/data/tomcat-conversion to v0.36

Due to the extraordinary duration of the v0.34.9 upgrade and due to some new features in v0.36 that will improve performance during the &quot;catch-up&quot; phase, we will upgrade the __gratia08:/data/tomcat-conversion__ services to v0.36 before activating the replication in the next step.

To install the new software on the Gratia __gratia08:tomcat-conversion__ instance, run the following script on __gratia08__ as __root__ user:
   * /home/gratia/gratia-builds/gratia-latest/build-scripts/gratia-upgrade.sh 

The responses to the questions are:
   * collector?: __tomcat-conversion__ 
   * source directory?: __releases__ 
   * release?: __v0.36__ 
   * root !MySql password: __(you better know it)__ 

*Do not start the collector until the following are verified*:
   * it is pointing to gratia06 mysql database and NOT gratia07 
   * the lifetime parameters on !JobUsageRecord retention are the desired ones 

%GREEN%

Parameter changes:
   * DB connection parameters verified to be gratia06:3320.
   * JUR lifetime set to 6 months.
   * Procedure-specific Trace lifetime setting removed to avoid triggering (minor) bug.
   * Log files set to 5 vs 3.
   * Queue size set to 100K.
   * Safe mode set to 1.
%ENDCOLOR%

With v0.36, the upgrade will require the following schema changes:
   * the addition of a new column ( __SummaryID__) to the __MasterSummaryData__ table with a new __unique index__ on this column as it will be the primary key. 
   * addition of a new table ( __NodeSummary__) 

*MUST WAIT FOR THESE SCHEMA CHANGES TO COMPLETE.*

%GREEN%
Collector started at Jul 23 20:21:43%BR%
%RED%Upgrade FAILED at Jul 23 20:28:22 due to mis-configured post-install.sh%ENDCOLOR%%BR%
Collector restarted at Jul 23 20:33:38, went into safe-start at Jul 23 20:34:41.
%ENDCOLOR%

---++ Start replication from production collector to upgrade collector.

Before we can switch production back to using *gratia06/gratia*, we need to perform a &quot;catch-up&quot; by replicating from *gratia07/gratia* to *gratia06/gratia*.

To do this we need to activate the replication of !JobUsageRecord table records using the *gratia09:/data/tomcat-gratia* service.

The dbid to start with was determined in an earlier step when we switched to using gratia07.
   * the last dbid at that time on gratia07 was *79801016*    %GREEN%  *VERIFIED*  CG 2008/07/23 %ENDCOLOR%
   * We do not have to do !MetricRecords as there should be no !MetricRecords. Those that are there are a mistake 

Using the UI on http://gratia.opensciencegrid.org:8880/gratia-administration (this is pointing to the *gratia07* database):
   * create a replication entry pointing to *http://gratia08.fnal.gov:8884* (this is pointing to the *gratia06* database). 
   * test it 
   * then using a !MySql client, update the dbid to *79801016*: 
   &lt;pre&gt;update Replication set dbid=79801016 where openconnection=&#39;http://gratia-fermi.fnal.gov:8884&#39;; &lt;/pre&gt; 
   * start the replication in the UI 

%GREEN%Replication started from http://gratia.opensciencegrid.org:8880 to http://gratia08.fnal.gov:8884 at Jul 23 21:15%BR%

| Date | count(*) |
| 2008-07-24 13:00:00 | 24658 |
| 2008-07-24 12:00:00 | 57519 |
| 2008-07-24 11:00:00 | 50869 |
| 2008-07-24 10:00:00 | 44378 |
| 2008-07-24 09:00:00 | 37886 |
| 2008-07-24 08:00:00 | 42897 |
| 2008-07-24 07:00:00 | 74025 |
| 2008-07-24 06:00:00 | 80757 |
| 2008-07-24 05:00:00 | 89247 |
| 2008-07-24 04:00:00 | 85363 |
| 2008-07-24 03:00:00 | 77831 |
| 2008-07-24 02:00:00 | 35706 |

Replication completed: Jul 30 06:00 (approx)%BR%
Elapsed: 6 days 09:15 hours   (153.5 hrs)%BR%
Records replicated: 8,522,056  as of Jul 30 08:50%BR%
Average Rate: 55,518 / hr%BR%

%ENDCOLOR%

---++ Monitor &quot;catch-up&quot; progress on gratia06/gratia and stop replication when done
Towards the end of the upgrade of *gratia06/gratia*, updates to the DB will be stopped pending a final duplicate resolution phase and conversion of the index on =md5v2= to unique.

Between this happening and the listener queue hitting its threshold, replication from *gratia09:/data/tomcat-gratia* to *gratia08:/data/tomcat-conversion/gratia* should be stopped.  %GREEN% DONE: 7/30 18:45%ENDCOLOR%

---++ Switch the current *gratia09:/data/tomcat-gratia* to use the *gratia06/gratia* database
 To switch-over the tomcat collectors: 
   1 Delete the replication data entries in both collectors so they are no longer pointing to each other
      * gratia08:/tomcat-conversion %GREEN%Has already beed removed (7/30 19:13 confirmed JGW)%ENDCOLOR%
      * gratia09:/tomcat-gratia %GREEN% Removed entry 7/30 19:14   Last dbid replicated: 89980675 %ENDCOLOR%
   1 Stop each collector 
      * on *gratia08* %BR% - service tomcat-conversion stop  %GREEN%  Jul 30 19:19   %ENDCOLOR%
      * on *gratia09* %BR% - service tomcat-gratia stop  %GREEN%  Jul 30 19:21   %ENDCOLOR%
   1 Upgrade tthe gratia09:tomcat-gratia to v0.36 (do not start)  %GREEN%  Jul 30 19:23   %ENDCOLOR%
   1 Update the *service-configuration.properties* file to change the databases they point to 
      * on *gratia08:/data/tomcat-conversion/gratia* %BR% - service.mysql.url=jdbc:mysql:// *xxxxx*.fnal.gov:3320/xxxxx  %GREEN%  Jul 30 19:19   %ENDCOLOR%
      * on *gratia09:/data/tomcat-gratia/gratia* %BR% - service.mysql.url=jdbc:mysql:// *gratia06*.fnal.gov:3320/gratia   %GREEN% Verified (JGW) Jul 30 19:27   %ENDCOLOR%
      1 Start the *gratia09* production collector *only* (it will be using the *gratia06* database 
      * on *gratia09* %BR% - service tomcat-gratia start   %GREEN%  Jul 30 19:29   %ENDCOLOR%
      * turn housekeeping off %GREEN%  Jul 30 19:33  %ENDCOLOR%
   1 Verified gratia08:tomcat-conversion is not set to restart at any run level
      &lt;pre&gt;
[root@gratia08 init.d]# chkconfig --list tomcat-conversion
tomcat-conversion       0:off   1:off   2:off   3:off   4:off   5:off   6:off
&lt;/pre&gt;



At this point production gratia reporting and services area back on-line and available and using the *gratia06* database

Verify there are no problems by tailing the log files in *gratia09:/data/tomcat-gratia/logs* .%BR% 
%GREEN%EVERYTHING LOOKS GOOD!  HOORAY!!!  07/30 07:35 %ENDCOLOR%


---++ Backups for  switchback
 We will need to *start* the backups on *gratia06* for the *gratia* database.%BR%
%GREEN%They were started back when we started the &quot;catchup&quot; phase%ENDCOLOR%

And *deactivate* the backups on the *gratia07* database for the gratia database.%BR%
%GREEN% Commented root cron for backups on gratia07   -  Jul 30 19:56%ENDCOLOR%

---++ Crons - switchback
---+++ Cron processes
 There are several processes (cron) that will need to be copied/modified on _gratia06_ and _gratia09_ for reports and interfaces. 
   1 gratia06 - user gratia 
      * APEL-WLCG interface - This cron process remained on *gratia06*. The only modification required is to the */home/gratia/interfaces/apel-lcg/lcg-db.conf* file for the following parameter to point it back to the *gratia06* database. 
         * GratiaHost *gratia-db01*.fnal.gov &lt;p&gt; &lt;/p&gt;  %COLOR%7/30 20:03%ENDCOLOR%
      * OSG daily reports  - %GREEN% in /home/gratia/gratia-summary/Gratia.C changed &#39;   static TSQLServer *db = TSQLServer::Connect(&quot;mysql://gratia06.fnal.gov:3320/gratia&quot;,&quot;reader&quot;, &quot;reader&quot;);&#39; - Jul 30 20:18 %ENDCOLOR%
&lt;verbatim&gt;
/home/gratia/gratia-summary/gratiaSum.cron.sh
/home/gratia/gratia-summary/daily_mail_cron.sh
/home/gratia/gratia-summary/range_mail_cron.sh --weekly
/home/gratia/gratia-summary/range_mail_cron.sh --monthly
/home/gratia/gratia-summary/rungratia.sh --production 
&lt;/verbatim&gt; 
      * CMS weekly reports %GREEN% 7/30 20:12 - Moved /home/gratia/gratia-summary/PSACCTReport.py.gratia06.2  PSACCTReport.py%ENDCOLOR%
      &lt;verbatim&gt;
/home/gratia/gratia-summary/cms_mail_cron.sh --weekly
&lt;/verbatim&gt; 
   1 gratia06 - user root&lt;br /&gt; Database backups on *gratia06* will need to be changed to now include the *gratia* database. This includes the purging of log files by the zrm process.  %GREEN%These were activated when the catchup phase started.%ENDCOLOR%
&lt;pre&gt;/usr/local/bin/gratia_backup_cron.sh /usr/bin/mysql-zrm --action purge &lt;/pre&gt; 
&lt;p&gt; &lt;/p&gt; &lt;p&gt; &lt;/p&gt; 
   1 gratia09 - user root&lt;br /&gt; The static reports cron on gratia09 *did not* require changing as it references the gratia09 gratia collector which will now be pointed back to the gratia06 database. &lt;p&gt; &lt;/p&gt; &lt;p&gt; &lt;/p&gt; 
   1 gratia07 - user root&lt;br /&gt; This database backup cron entry needs to be *removed* from this cron.  The */usr/local/bin/gratia_backup_cron.sh* script can be removed as well.  %GREEN% root cron commented out - 7/30 20:14 %ENDCOLOR% 
&lt;pre&gt;/usr/local/bin/gratia_backup_cron.sh /usr/bin/mysql-zrm --action purge &lt;/pre&gt;


---+++ Nebraska (Brian Bockelman) interfaces
 Notify Brian to switch back to using *gratia-db01:3320* database. %GREEN% DONE: 7/30 20:07 %ENDCOLOR%

&lt;!-- ----------------- POST MORTEM  ------------- --&gt;
---+ Post-mortem
 At this time, this will appear to be random notes. After the conversion, they may be organized.

   1 *catalina.out* exceptions &lt;pre&gt;command: select T.SiteName, P.currenttime, P.probename from Probe P, Site T where P.active = 1 and T.siteid = P.siteid order by T.SiteName,P.currenttime desc java.lang.ArrayIndexOutOfBoundsException &lt;/pre&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt; Chris is creating a patched v0.34.9a without putting things in CVS so we can troubleshoot this and not destroy our real v0.34.9 set. &lt;/p&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt; &lt;/p&gt; 
   1 *gratia-rmi-servlet0.log* - coming every 10 minutes. Chris thinks from a probe. &lt;pre&gt;INFO: RMIHandlerServlet: Error: Problematic req: org.apache.catalina.connector.RequestFacade@564a38 Jun 24, 2008 2:29:25 PM net.sf.gratia.util.Logging info &lt;/pre&gt; &lt;p&gt; &lt;/p&gt; 
      * 
         * 11:35 - 11:39: A v0.34.9a was installed (not put in CVS) to trouble-shoot the problem. 
         * 11:47 - 11:51: A new v0.34.a installed with problem fixed hopefully. Chris fix. 
         * 13:34 - 13:51: another new install 
 

   1 Static reports appear to be truncating... should be landscape to fit in or scaled differently. 

%STOPINCLUDE%

-- Main.JohnWeigand - 30 May 2008
