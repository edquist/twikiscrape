---+!! *&lt;noop&gt;%SPACEOUT{ &quot;%TOPIC%&quot; }%*


%RED%
WARNING! This page is for an older version of Hadoop.
For newer versions, please visit [[Documentation/Release3.InstallHadoopSE][Hadoop Release 3 Installation]]
%ENDCOLOR%

%TOC%

---++ Reading files from SRM

Testing a SRM endpoint is fairly straight forward. You&#39;ll need to know the SE path endpoint on the hadoop door and you&#39;ll have to have a valid gridcert that is permitted to move files in and out of your site.

First generate a proxy certificate with grid-proxy-init or voms-proxy-init.  Now attempt to pull from your srm door. The command will look something like:

&lt;verbatim&gt;
# srmcp -2 -debug srm://cit-se2.ultralight.org:8443/srm/v2/server?SFN=/mnt/hadoop/junk.txt file:////tmp/junk.txt
[some debug output omitted]
Tue Aug 18 22:42:11 PDT 2009: starting SRMGetClient
Tue Aug 18 22:42:11 PDT 2009: In SRMClient ExpectedName: host
Tue Aug 18 22:42:11 PDT 2009: SRMClient(https,srm/managerv2,true)
SRMClientV2 : user credentials are: /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dkcira/CN=655958/CN=Dorian Kcira
SRMClientV2 : WEBSERVICE_PATH srm/managerv2
SRMClientV2 : connecting to srm at httpg://cithep250.ultralight.org:8443/srm/v2/server
copy_jobs is empty
Tue Aug 18 22:42:12 PDT 2009: calling srmPrepareToGet
SRMClientV2 :  srmPrepareToGet, contacting service httpg://cithep250.ultralight.org:8443/srm/v2/server
Tue Aug 18 22:42:13 PDT 2009: received responce
Tue Aug 18 22:42:13 PDT 2009:  srm returned requestToken = get:1318
copy_jobs is not empty
copying CopyJob, source = gsiftp://cithep230.ultralight.org:2811//mnt/hadoop/junk.txt destination = file:////tmp/junk.txt
GridftpClient: memory buffer size is set to 1048576
GridftpClient: tcp buffer size is set to 1048576
GridftpClient: connecting to cithep230.ultralight.org on port 2811
Tue Aug 18 22:42:13 PDT 2009: no more pending transfers, breaking the loop
GridftpClient: gridFTPClient tcp buffer size is set to 1048576
GridftpClient: gridFTPRead started
GridftpClient: set local data channel authentication mode to None
GridftpClient: parallelism: 10
GridftpClient: starting a transfer from /mnt/hadoop/junk.txt
GridftpClient: waiting for completion of transfer
GridftpClient: DiskDataSink.close() called
GridftpClient: gridFTPWrite() wrote 234bytes
GridftpClient: closing client : org.dcache.srm.util.GridftpClient$FnalGridFTPClient@39a2f02e
GridftpClient: closed client
execution of CopyJob, source = gsiftp://cithep230.ultralight.org:2811//mnt/hadoop/junk.txt destination = file:////tmp/junk.txt completed
SRMClientV2 :  srmReleaseFiles, contacting service httpg://cithep250.ultralight.org:8443/srm/v2/server
srmReleaseFilesResponse status code=SRM_SUCCESS
copy_jobs is empty
stopping copier
&lt;/verbatim&gt;

The line =srmReleaseFilesResponse status code=SRM_SUCCESS= is your indication that the transfer was successful.  You should manually check the contents of the local file =/tmp/junk.txt= and verify that the contents are correct.

---++ Writing files to SRM

To write files to SRM, you must first generate a proxy certificate with grid-proxy-init or voms-proxy-init.  Now attempt to write to your srm door. The command will look something like:

&lt;verbatim&gt;
# srmcp -2 -debug file:////tmp/junk.txt srm://cit-se2.ultralight.org:8443/srm/v2/server?SFN=/mnt/hadoop/store/user/wart/junk.txt
[some debug output omitted]
Tue Aug 18 22:45:20 PDT 2009: starting SRMPutClient
Tue Aug 18 22:45:20 PDT 2009: In SRMClient ExpectedName: host
Tue Aug 18 22:45:20 PDT 2009: SRMClient(https,srm/managerv2,true)
SRMClientV2 : user credentials are: /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dkcira/CN=655958/CN=Dorian Kcira
SRMClientV2 : WEBSERVICE_PATH srm/managerv2
SRMClientV2 : connecting to srm at httpg://cithep250.ultralight.org:8443/srm/v2/server
copy_jobs is empty
SRMClientV2 :  srmPrepareToPut, contacting service httpg://cithep250.ultralight.org:8443/srm/v2/server
Tue Aug 18 22:45:21 PDT 2009:  srm returned requestToken = put:1351
Tue Aug 18 22:45:21 PDT 2009: no more pending transfers, breaking the loop
copy_jobs is not empty
copying CopyJob, source = file:////tmp/junk.txt destination = gsiftp://cithep230.ultralight.org:2811//mnt/hadoop/store/user/wart/junk.txt
GridftpClient: memory buffer size is set to 1048576
GridftpClient: tcp buffer size is set to 1048576
GridftpClient: connecting to cithep230.ultralight.org on port 2811
GridftpClient: gridFTPClient tcp buffer size is set to 1048576
GridftpClient: gridFTPWrite started, source file is java.io.RandomAccessFile@307b4703 destination path is /mnt/hadoop/store/user/wart/junk.txt
GridftpClient: gridFTPWrite started, destination path is /mnt/hadoop/store/user/wart/junk.txt
GridftpClient: set local data channel authentication mode to None
GridftpClient: parallelism: 10
GridftpClient: adler32 for file java.io.RandomAccessFile@307b4703 is 3cec4db3
GridftpClient: Was not able to send checksum value:org.globus.ftp.exception.ServerException: Server refused performing the request. Custom message:  (error code 1) [Nested exception message:  Custom message: Unexpected reply: 500 Invalid command.] [Nested exception is org.globus.ftp.exception.UnexpectedReplyCodeException:  Custom message: Unexpected reply: 500 Invalid command.]
GridftpClient: waiting for completion of transfer
GridftpClient: starting a transfer to /mnt/hadoop/store/user/wart/junk.txt
GridftpClient: DiskDataSink.close() called
GridftpClient: gridFTPWrite() wrote 234bytes
GridftpClient: closing client : org.dcache.srm.util.GridftpClient$FnalGridFTPClient@168e4805
GridftpClient: closed client
execution of CopyJob, source = file:////tmp/junk.txt destination = gsiftp://cithep230.ultralight.org:2811//mnt/hadoop/store/user/wart/junk.txt completed
srmPutDone status code=SRM_SUCCESS
copy_jobs is empty
stopping copier
&lt;/verbatim&gt;

The line =srmReleaseFilesResponse status code=SRM_SUCCESS= is your indication that the transfer was successful.  You should manually check the contents or checksum of the file in hdfs and verify that the contents are correct.
