---+*%SPACEOUT{ &quot;%TOPIC%&quot; }%*
%TOC%

The proposal is to allow users to access all opportunistic storage on OSG via a grid centralized storage element. The motivation is to hide from the user the current necessity of making the storage available and to provide the mechanisms of discovery, etc, as a backend service. Technical feasibility of a few software implementations are discussed.

---++IRODS

One of the main drivers of IRODS is the federation of heterogeneous data management technologies. 

It should be noted that federation in IRODS terminology is across Multiple IRODS instances, or zones. Federation allows access to other IRODS instances from an IRODS instance. The IRODS zone hosting the file is the root of the logical path of the file. Therefore federation as defined in IRODS does not in itself make the instances transparent. That may be acceptable, but it seems to defeat the purpose of having logical vs physical names. Furthermore, it would nominally require an IRODS instance at each site, though it is conceivable that a central host could run an IRODS instance for each site.

The logical name does hide the specific storage resource that the file is on. Logical names are mapped to physical names in the iCAT database. Federation of OSG resources would be the creation of an IRODS zone with distributed storage resources. That allows flexible file location, though further catalog operations will be necessary to, for example, make sure collections of files are co-located.

OSG Storage Elements do not incorporate iRODS servers, therefore direct transfer using native iRODS movers is not possible. Support exists in IRODS for the use of custom scripts to execute file operations, through the Universal Mass Storage System driver. Into these scripts might be placed code to cause the transfer to be done using current such as globus-url-copy.

Another option is to use only the iCAT portion of IRODS, to form a logical namespace and to define collections. Data could then be moved by the client, followed by file registration by the client. Such a use could potentially pose difficulties, since it is not the canonical way of using IRODS. FTS (see below) may be a better fit for this model. 

See the next section for a more complete discussion of the requirements and possible approaches.

---+++ OSG iRODS Model

Discovery, Transfer, Catalog, Management

*Within iRODS framework, or iRODS as a component in another framework?*

Minimize the disparity between this approach and what would be done for direct submission to sites.

---++++Discovery
   
Provide for automatic selection of storage element. Support data-driven computation.

   * On directory creation, assign a storage element to it
      * Store as collection metadata
      * Should include the expected size of the directory
         * May need to move the files to another storage element
      * Space reservation option
      * Storage profile option
   * Use the discovery service to populate iCAT with the SE availability for the user&#39;s VO
      * Return the corresponding TURL or SURL to the user
   * Associate a compute element with a storage element via data objects
      * Computation profile option
         * Influences where the data is placed
   * Associate with other data collections.
   * Use Pidgeon SE availability checker to identify authorized sites
   * Allow for operation with OSGMM

#OSGiRODSDataTransfer
---++++Data Transfer

Desire direct transfer between storage element and user based on non-iRODS storage services. Storage Management policies and Catalog operations should be triggered as in normal iRODS operation.

No option here is recommended, for the specified reasons.

   * Use iRODS standard transfer with gridftp extension microservices
      * Because the gridftp extension is a set of microservices (not a driver) it does not invoke policy rules.
         * Driver is in development.
      * In iRODS a gridftp server is a compound resource; data must hop through the OSG iRODS server
   * Use an SRM transfer with and SRM interface to iRODS
      * Academia Sinica developed SRM interface for SRB.
      * Said by RENCI to be &quot;interested&quot; in SRM interface for iRODS.
      * Presumably would be an adapter for native 
      * Must use gridftp or other non-iRODS storage resources; data must hop through the OSG iRODS server
   * Use microservice-wrapped web service for callbacks
      * Integrate with globus.org-type service
      * Facilitate future integration with Java-based iRODS microservices
      * May do GUMS call
      * Does not invoke policy rules
      * gsoap, complicated, must recompile for each added web service
   * Use iRODS transfer with Universal Mass Storage Driver
      * Storage resources registered as such
      * Uses regular transfer microservices, which will invoke policy rules
      * Must stage through OSG irods server
      * Might have to use grid credential proxy
         * No support for this in iRODS*
   * Use iRODS as a shadow storage service
      * Actual transfers in external framework
         * Using same clients as for non-opportunistic storage.        
      * Get TURL or SURL and make the transfer in the next step
         * Override microservice to provide info rather than transfer data
            * Essential that iRODS automatic policy functions are still invoked.
            * Policy functions are invoked before and after invocation of drivers
               * Custom driver using rcExecCmd (same as UMSD)
               * Additional cmd within workflow with msiExecCmd
         * Write UMSD functions to return information rather than do transfers
            * Must avoid false registration on failure
               * Must have a way to block until file completion
            * Current nop for file transfer (stage only). Extend?
               * univMSSFileWrite, etc
               * Could write scripts for either gridftp or srm. It may be better in the end to use separate drivers for gridftp and SRM.
      * In order for pre and post-processing to work in the normal iRODS way, the driver would to block while the client does the transfer.
         * Would need to establish a connection and have a protocol with the client to have it do the transfer, report status, etc.
         * *Evaluation of complexity/effort/risk is necessary before recommendation can be made.*
   * Use iCAT catalog commands directly, completely bypassing any iRODS data object functionality.
      * iRODS as a component within another framework.
      * Only a few client commands, such as ireg (to register a file) and imeta (to add metadata), would be usable
      * Policy rules are not invoked.
      * Can administrative commands based on catalog-only functionality meet the capability requirements for Catalog and Management, below?
         * To what degree will a new framework need to be written?
         * To what degree would use of a full iRODS server still fall short of the capability requirements?
      * *Evaluation of complexity/effort/risk is necessary before recommendation can be made.*

Might use globus-url-sync to copy whole collections and relocate data.            

---++++Catalog

Database registration should be transparent to the user.

   * Trigger job on completion of pre-defined file set.
   * Add FITS data to metadata (LSST)
      * Database searchability
   * Monitor data movement status
   * Leverage existing iRODS GUIs and web interfaces.
   * Support Storage Management functions, see below

Deploy only iCAT at sites? Or iCAT-enabled iRODS, but only as info server and policy executor?

---++++Management

Should be done through iRODS policy rules.

   * Trigger deletion of expired data collections.
   * Maintain space and availability information.
   * Replication
   * Relocation
   * Aggregation

Data-related pre- and post-processing rules in iRODS code

Available blackboard objects are listed for each rule.

&lt;pre&gt;
1) acSetRescSchemeForCreate - SdataObj1 and SuserAndConn 
2) acPreprocForDataObjOpen - SdataObj2 and SrescInfo and SuserAndConn 
3) acSetMultiReplPerResc - SuserAndConn 
4) acPostProcForPut - SdataObj2 and SrescInfo and SuserAndConn 
5) acPostProcForCopy - SdataObj2 and SrescInfo and SuserAndConn 
6) acPostProcForFilePathReg - SdataObj2 and SrescInfo and SuserAndConn 
7) acPostProcForCreate - SdataObj2 and SrescInfo and SuserAndConn 
8) acPostProcForOpen - SdataObj2 and SrescInfo and SuserAndConn 
9) acSetNumThreads - SuserAndConn 
10) acDataDeletePolicy - SdataObj2 and SrescInfo and SuserAndConn 
11) acPostProcForDelete - SdataObj2 and SrescInfo and SuserAndConn 
18) acPreprocForCollCreate - Scollection and SuserAndConn 
19) acPostProcForCollCreate - Scollection and SuserAndConn 
20) acPretProcForRmColl - Scollection and SuserAndConn 
21) acPostProcForRmColl - Scollection and SuserAndConn 
&lt;/pre&gt;

---+++ OSG iRODS Program of Work for Discovery Capability

Development needed for using a collection is less than that needed for making a collection. Some of the schema from the latter will be needed.

---++++ Using a collection

iRODS has a default storage resource which can be overridden by rules or the user&#39;s environment. 

   1. Study means of ensuring that a file written to a collection is stored on the resource associated with that collection.
      1. Possibly use acSetRescSchemeForCreate. See below.
         1. Write a rule based on database lookup associating path with resource.
         1. Understand where this is in relation to the storage driver.
            1. Invoked as part of iput and available to server side of driver as session variable?
               1. Is invoked just before data object creation. Dummy file may need to be made on iRODS server.
               1. Object is created and registered before driver fileWrite is called, so selected storage resource should be in the database (committed?).
               1. fileWrite gets only the file descriptor of the open file. It would be good if it got the whole file input structure.
                  1. Its path is unknown to the driver, so it cannot query the database for the storage resource at that point.
                  1. Make an auxiliary table and populate it in the fileCreate process. The serial ID becomes the file descriptor.
                  1. Or, ask the client through the socket what the path is (could use open files table as a check). 
            1. How to get session variables in UMSD?
         1. Default would be to write to a resource group.
   1. Refinement: write custom command to query for available space remaining in reservation, expiration, etc.
   1. Quotas are supported by the rules.
   1. Retry on another resource in a resource group is supported.

---++++ Directing a collection to a resource

One can use iclient commands to specify the resource to which a file should go. According to the default iCAT schema, a resource may be associated with a file, but not for a collection. This allows a collection to be spread over several resources. One can use rules, such as these from ARGO, to guide an iput to a resource according to the destination collection.

&lt;pre&gt;
1	#ARGO rules
2	acSetRescSchemeForCreate|&quot;$objPath&quot; like &quot;/ARCS/projects/IMOS/*/ARGO/*&quot;|msiSetDefaultResc(emii.resource.tpac.org.au,preferred)|nop
3	
4	acSetRescSchemeForCreate|&quot;$objPath&quot; like &quot;/ARCS/projects/IMOS/staging/SOOP/*&quot;|msiSetDefaultResc(emii.resource.tpac.org.au,preferred)|nop
5	acSetRescSchemeForCreate|&quot;$objPath&quot; like &quot;/ARCS/projects/IMOS/staging/SOTS/*&quot;|msiSetDefaultResc(emii.resource.tpac.org.au,preferred)|nop
6	acSetRescSchemeForCreate|&quot;$objPath&quot; like &quot;/ARCS/projects/IMOS/staging/ANFOG/*&quot;|msiSetDefaultResc(arcs-df.ivec.org,preferred)|nop
7	acSetRescSchemeForCreate|&quot;$objPath&quot; like &quot;/ARCS/projects/IMOS/staging/AUV/*&quot;|msiSetDefaultResc(arcs-df.vpac.org,preferred)|nop
8	acSetRescSchemeForCreate|&quot;$objPath&quot; like &quot;/ARCS/projects/IMOS/staging/ANMN/*&quot;|msiSetDefaultResc(emii.resource.tpac.org.au,preferred)|nop
9	acSetRescSchemeForCreate|&quot;$objPath&quot; like &quot;/ARCS/projects/IMOS/staging/ACORN/*&quot;|msiSetDefaultResc(arcs-df.vpac.org,preferred)|nop
10	acSetRescSchemeForCreate|&quot;$objPath&quot; like &quot;/ARCS/projects/IMOS/staging/AATAMS/*&quot;|msiSetDefaultResc(arcs-df.vpac.org,preferred)|nop
11	acSetRescSchemeForCreate|&quot;$objPath&quot; like &quot;/ARCS/projects/IMOS/staging/FAIMMS/*&quot;|msiSetDefaultResc(arcs-df.vpac.org,preferred)|nop
12	acSetRescSchemeForCreate|&quot;$objPath&quot; like &quot;/ARCS/projects/IMOS/staging/eMII/*&quot;|msiSetDefaultResc(emii.resource.tpac.org.au,preferred)|nop
13	acSetRescSchemeForCreate|&quot;$objPath&quot; like &quot;/ARCS/projects/IMOS/staging/SRS/*&quot;|msiSetDefaultResc(arcs-df.ivec.org,preferred)|nop
&lt;/pre&gt; 

Several significant iRODS functions are involved. Refinements such as the space reservation functions are optional and may be done in a second version.

---++++ Making a collection
   1. Devise schema and method of populating iCAT with SE authz/availability info from Pidgeon VO Storage Checker.
      1. Need schema for storage resource metadata; endpoint, path, etc info, to be used for transfers.
      1. Devise regular update mechanism.
   1. Test loading of iCAT with SE availability population for various VOs.
   1. Configure test iRODS for GSI authorization.
      1. Test rule for obtaining DN. It would be good if iRODS could handle roles.
      1. Obtain way of ascertaining the user&#39;s VO in a rules-based environment.
   1. Write acPreprocForCollCreate rule
      1. Check if the VO has any available Storage Elements.
         1. Return notification if not.
      1. Write microservice-based lookup of SE assignment for the VO.
         1. Parent collection match strategy.
         1. Random-selection strategy.
         1. Storage Element reliability score strategy.
         1. VO SE-preference strategy.
            1. Include hard user-specified SE. 
         1. SE VO-preference strategy.
         1. Space reservation match strategy.
      1. Refine lookup based on expected size of collection.
         1. It would be good if mkdir had a parameter for that.
         1. Link to space reservation.
            1. It would be good if mkdir had an option to request that a space reservation be made.
            1. Direct the user via the client-server channel to make a space reservation.
               1. The space token should be sent from the client back to the iRODS server for recording.
            1. Generate a request for the space to be reserved by the administrator.
               1. Leave mkdir status as PENDING. It would be good to have a status defined for the collection object.
         1. Possible post-mkdir custom command to ensure space is available.
            1. Could change the assigned SE based on size.
            1. Devise a way to relocate a collection based on size increase.
      1. Refine lookup based on an associated collection.
   1. Test client-server model of orchestrating directory creation on the Storage Element by the user.
      1. SRM has mkdir.
      1. gridftp write test file or leave state as ready.
   1. Write acPostprocForCollCreate rule
      1. Store in iCAT the SE info for the collection.
      1. Store default lifetime.
      1. Refinement of storing any space reservation information. Need space reservation schema.
         1. Space token would be used for transfers.
   1. Refine lookup applying of job and storage profile information to selection of Storage Element.
      1. Availability of SE mount on worker node.
      1. Number and size of files, etc.


&lt;img src=&quot;%ATTACHURLPATH%/ResourceRegCollectionCreation.png&quot; alt=&quot;ResourceRegCollectionCreation.png&quot; width=&#39;900&#39; height=&#39;600&#39; /&gt; 

---+++ OSG iRODS Program of Work for Shadow Storage Option

A plan sketch would be the following. The work starts with the Data Transfer function.

   1. Install iRODS and add several distributed gridftp resources in a resource group.
   1. Run various elementary rule files, with transfers only to local cache resource.
   1. Create and run elementary rules using rulegen.
   1. Run a rule with msiExecCmd invoking example hello script
   1. Write an example script and run a rule with msiExecCmd invoking it.
   1. Check the functionality of the Universal Mass Storage Driver with dummy scripts. 
   1. Copy the Universal Mass Storage Driver as a new driver.
      1. Follow the documentation outlining the creation of a new driver.
   1. Add a storage resource with the type of the new driver.
   1. Before extending, recheck the functionality of the supported command subset.
   1. Write a new univMSSFileWrite function.
      1. Include connection to client and protocol for return status
      1. *Study degree of difficulty before starting program of work.*
   1. Check the functionality with a file write and dummy driver script.
      1. Verify that pre and post-processing policy rules are invoked.
      1. *Study issues of why MSS is currently supported only as staging* -asynchronicity?
   1. Design actual univMSSFileWrite function.
      1. Do this design before starting the program of work.
   1. Repeat the previous three steps for all other functions.
   1. Devise and execute thorough transfer tests.
      1. In parallel -test each new function as it is written, continuous integration.
   1. Propose modification of UMSD in iRODS code base to extended version.
   1. Write and test rules using the msiExecCmd microservices for Discovery, Catalog, and Management functions.



---+++ Component Design for Shadow Storage Option

How the scripts that invoke specific operations can be written such that iRODS and currently available tools can work together and support the requirements of the model.

The complete list of file operations is: univMSSFileCreate, univMSSFileOpen, univMSSFileRead, univMSSFileWrite,
    univMSSFileClose, univMSSFileUnlink, univMSSFileStat, univMSSFileFstat, univMSSFileLseek,
    univMSSFileFsync, univMSSFileMkdir, univMSSFileChmod, univMSSFileRmdir, univMSSFileOpendir,
    univMSSFileClosedir, univMSSFileReaddir, univMSSFileStage, univMSSFileRename,
    univMSSFileGetFsFreeSpace, univMSSFileTruncate, univMSSStageToCache, univMSSSyncToArch. Some of the operations may not be possible with gridftp or SRM.

---++++clientsideFileRead

   1. preprocessing
   1. fileRead function
      1. Determine if the endpoint is gridftp or SRM.
         1. Look up the database entry for storage resource, or parse the URL.
      1. Obtain TURL or SURL. 
         1. Get server name from iCAT lookup based on the storage resource attributes.
         1. Use OSG Discovery Tool to find the example URL.
         1. Make substitution using logical path to compose URL.
      1. Communicate the URL to the user.
         1.
      1. Block while the user software reads the file.
         1. Open a connection to the user and wait.
         1. Or use iRODS session connection.
         1. Consider asynchronous model with data object in pending state, update on transfer completion. 
      1. Receive a report on the result of the read.
         1. Or, time out.
      1. Act based on the success or failure of the user&#39;s read.
         1.
         1.
      1. Exit with suitable return code. 
   1. postprocessing
         1. OSG Storage Federation accounting.

---++++clientsideFileWrite client-server model

Has the client connect directly to the file driver.

   1. A utility are provided to the user for puts. At an early stage, the utility forks, one thread calling the iRODS client comand iput or iget in the usual fashion and the other starts trying to connect on a socket.
   1. On the iRODS server side, the fileCreate driver is invoked, which is to return a file descriptor to be used by the fileWrite function. The custom fileCreate driver is written to call _rsExecCmd, a supplied iRODS function for doing system calls. This allows the driver to be written in shell script, python, etc. The driver script adds a row to the fd_info table. The only information it adds is the path of the file. The table has a serial ID column, which provides a unique integer for each row. This integer is obtained and returned as the file descriptor.
   1. On the iRODS server side, the fileWrite driver is invoked, given the file descriptor integer from the fileCreate function. The fileWrite driver script queries the fd_info table and obtains the path of the file to be written.
   1. The fileWrite script parses the file path and obtains the destination storage resource. The storage resource will later be present in a column of the database object for the file, but at this point the file has not been registered in the database.
   1. The fileWrite script queries the metadata of the storage resource entry in the database for the endpoint and path of the Storage Element and composes an SURL or TURL for the file.
   1. The fileWrite script starts listening on a socket, and the client connects.
   1. The URL is communicated to the client through the socket.
   1. The client uses the URL to write the file to the Storage Element.
   1. The client reports success or failure to the fileWrite script. If success, the fileWrite driver returns zero to iRODS and the file is subsequently registered in iCAT. If failure, an error code is generated and returned to the iput fork of the client script.


&lt;img src=&quot;%ATTACHURLPATH%/FilePutClientServer.png&quot; alt=&quot;FilePutClientServer.png&quot; width=&#39;900&#39; height=&#39;600&#39; /&gt; 

---++++clientsideFileWrite

The following is based on a alternative model to that described for clientsideFileRead. The model is meant to be more asynchronous and service-based than the client-server approach. The client and the file driver each connect to a transfer coordination service. The sequence is as follows.

   1. The user creates a VOMS proxy.
   1. The write utility contacts an OSG transfer coordination service with a write request function and waits.
   1. (Optional) Authorization is checked.
   1. The user&#39;s VO is obtained from the proxy or an iRODS username from a GUMS service.
   1. Delegation of the user&#39;s credentials is done to the transfer coordination service.
   1. The transfer coordination service creates a contextually unique integer and associates it with the file path.
   1. The transfer coordination service makes an put request via Jargon code to the OSG iRODS service.
   1. The OSG fileOpen driver gets the file descriptor integer from the transfer coordination service using the file path.
   1. iRODS code calls the OSG fileWrite driver with the file descriptor as an argument (not the file path).
   1. The OSG fileWrite driver gets the file path from the transfer coordination service using the file descriptor integer.
   1. The OSG fileWrite driver obtains the storage resource handle from the file path and constructs the URL from the resource metadata.
   1. The OSG fileWrite driver posts the URL with a status of PENDING to the transfer coordination service.
   1. The OSG fileWrite driver requests the status of the write request by URL and waits for the reply.
      1. It would be good for asynchronicity if the put could exit here, setting the data_status to PENDING.
   1. The transfer coordination service receives the status request from the driver, but will not reply until the transfer completes.
   1. The write utility gets the URL from the transfer coordination server in response to the write request.
   1. The write utility does the transfer.
   1. The write utility posts an update to the transfer coordination service, with a status of UPLOADED or FAILED.
   1. The transfer coordination service responds to the OSG fileWrite driver&#39;s request for status.
   1. The OSG fileWrite driver returns the file length to iRODS, or -1 if the status request timed out or returned FAILED.
   1. On success, iRODS registers the file in iCAT.
   1. iRODS forwards the fileWrite return code to the transfer coordination service in response to the Jargon put call.
   1. (Optional) On failure, the transfer coordination service performs a compensatory action such as marking the storage resource as questionable.

    &lt;img src=&quot;%ATTACHURLPATH%/FilePutSOA2.png&quot; alt=&quot;FilePutSOA.png&quot; width=&#39;900&#39; height=&#39;600&#39; /&gt;

---+++ OSG iRODS Program of Work for iCAT-only Option

   1. Decide on Catalog and Management capability requirements.
   1. Determine what iRODS functionality is available that does not involve data operations.
   1. Sketch a framework that would use available functionality and possible supplemental tools to meet requirements.
   1. Assess complexity/effort/risk if creating/acquiring the framework.

---++++ Results for iCAT-only Option

There are four user commands available for accessing iCAT.

ireg
   * Specifies resource group and name only.
   * File must exist, though no transfer is done.
   * Cannot be used for gridftp resources, because they are compound resources.

iquest
   * SQL-like syntax.
   * All data is effectively in one table -do not need &quot;from&quot; field.
   * sprint-like output formatting.

isysmeta
   * Can set/modify expiration time.
   * Can return long-form data object info.

imeta
   * Sets, modifies, and searches user-defined metadata
   * Can be used on data objects, collections, resources, and users.

For defining a dataset, one could

   1. Register zero-length files in a collection. It would be good to be able to use DATA_STATUS to show the file has not been uploaded. One could also use DATA_STATUS to show if a file upload is in progress. A useful option that could be added to ireg would be a &quot;force&quot;, which would not check for the existence of a file and perhaps the ability to specify the file size.
      1. A collection is created.
      1. The members of the dataset are put as zero-length files with the name being the VO-portion of the logical filename (and path).
      1. A status attribute of DEFINED is set in each files user-specified metadata.
   1. Add the dataset filenames as metadata in a collection with value as status, DEFINED, UPLOADING, etc. Use imeta ls or iquest to find dataset info.
      1. A collection is created.
      1. The names of the files in the dataset are added as name-value pairs with the name being the VO-portion of the logical filename (and path) and the value being DEFINED.
      1. An Attribute-Value-Unit triplet is created with the dataset name and value ALL_DEFINED.
      1. Push model: when the iRODS server orchestrates a file put, it
         1. Assigns a storage resource (via discovery) to the collection if it is empty. Sets the dataset AVU to PROCESSING.
         1. Parses the logical filename to find out if the file is part of a dataset. If so, the status is changed to UPLOADING.
         1. Gets the return status from the client.
         1. Sets the value to either UPLOADED or FAILED depending on the return status.
         1. Checks whether all files in the dataset have status UPLOADED.
         1. If so, sets the dataset value to ALL_UPLOADED.
      1. Pull model: when a job starts to run on a resource, it
         1. Queries the grid iCAT to see if there are collections on the associated storage resource with dataset AVU of ALL_DEFINED, ALL_UPLOADED, or PROCESSING.
         1. If so, sets the dataset AVU to PROCESSING.
         1. Queries iCAT to find a file with status of DEFINED or UPLOADED.
         1. If the status is DEFINED, transfers the file from the user to the storage resource or worker node.
         1. If the status is UPLOADED, accesses the file from the storage resource.
         1. Sets the status to IN_USE and begins processing.
         1. When processing is finished, sets the status to PROCESSED.
         1. Checks whether all files in the dataset have status PROCESSED.
         1. If so, sets the dataset value to ALL_PROCESSED.

&lt;img src=&quot;%ATTACHURLPATH%/DatasetCreationAndUse.png&quot; alt=&quot;DatasetCreationAndUse.png&quot; width=&#39;900&#39; height=&#39;600&#39; /&gt;

Here is an alternative design that puts the dataset management code in the transfer coordination service. 

&lt;img src=&quot;%ATTACHURLPATH%/DatasetManagementInService.png&quot; alt=&quot;DatasetManagementInService.png&quot; width=&#39;900&#39; height=&#39;600&#39; /&gt;


---+++ Summary of Operations

   * Admin Config
      * Resource registration
      * User registration
         * Addition to VO group
         * Addition to VO operator group

   * User Config
      * Accessibility update (admin via user) - mandatory periodic
      * Collection creation
      * Dataset definition

   * Preprocessing
      * authz by DN (later, and role)
      * vo detection
      * collection creation privilege by role
      * vo OSG quota
      * resource selection
      * vo resource quota

   * Storage service processing
      * (register) existence check
      * driver invocation - orchestration
      * (write) bytes written check
      * registration

   * Postprocessing
      * Replication
      * Metadata update
         * file status
         * expiration time
         * collection status PENDING or OK
         * VO bytes written
         * Resource bytes written
         * VO to resource bytes written
         * Collection bytes written
      * Merge job trigger
         * UDP status change signal

   * Dataset operations
      * aggregate (user)
      * replicate (user) 
      * relocate (admin via user) - advise user to invoke relocation
      * purge (adimin via user) - mandatory periodic w/preview
      * status monitoring

   * VO accounting (same per user)
      * total bytes
      * bytes per resource
      * bytes per collection

   * Resource accounting
      * total bytes
      * bytes per VO
  
---+++ A distributed iRODS zone of gridftp storage resources

---++++ Start iRODS.

&lt;pre&gt;
    3  cd /opt/iRODS/
    4  ./irodssetup 
    5  ./irodssetup 
    6  ./irodssetup 
    7  ls
    8  ./irodsctl start
    9  MSS universal driver
&lt;/pre&gt;

---++++ Make a resource group with local cache and gridftp server resources.

&lt;pre&gt;
   10  export PATH=$PATH:/opt/iRODS/clients/icommands/bin
   11  iadmin mkresc gwdca03 &quot;MSS universal driver&quot; compound gwdca03.fnal.gov /pnfs/fnal.gov/data
   12  iadmin atrg rg gridworks
   13  iadmin atrg rg data1
   14  iadmin mkresc gridworks &quot;unix file system&quot; cache gw014k1.fnal.gov /data1
   15  iadmin atrg rg gridworks
   16  iadmin atrg rg gwdca03
&lt;/pre&gt;

---++++ Add users and user groups

&lt;pre&gt;
   35  iadmin mkuser gwadmin rodsadmin
   36  iadmin mkuser tdh rodsuser
   38  iadmin mkuser testuser rodsuser
   40  iadmin mkgroup gwgroup
   41  iadmin atg gwgroup tdh
   42  iadmin atg gwgroup testuser
&lt;/pre&gt;

---++++ Create a password for a user.

&lt;pre&gt;
iadmin moduser tdh password
&lt;/pre&gt;

---++++ Add more resources to the resource group

&lt;pre&gt;
&lt;/pre&gt;

---++++ Make a collection

A collection may be thought of as a directory in the logical namespace.

&lt;pre&gt;
&lt;/pre&gt;

---++++ Rename the local zone

&lt;pre&gt;
iadmin modzone tempZone name GridWorksZone 
iadmin lz
&lt;/pre&gt;

---++++ Install client commands on user machine.

Follow the prompts from irodssetup. Use a file like this for ~/.irods/.irodsEnv.

&lt;pre&gt;
# iRODS server host name:
irodsHost &#39;gw014k1.fnal.gov&#39;
# iRODS server port number:
irodsPort 1247

# Default storage resource name:
irodsDefResource &#39;gwdca03&#39;
# Home directory in iRODS:
irodsHome &#39;/GridWorksZone/home/tdh&#39;
# Current directory in iRODS:
irodsCwd &#39;/GridWorksZone/home/tdh&#39;
# Account name:
irodsUserName &#39;tdh&#39;
# Zone:
irodsZone &#39;GridWorksZone&#39;
&lt;/pre&gt;


---++++ Put a file as a user to the cache and then MSS

&lt;pre&gt;
export LD_LIBRARY_PATH=/opt/vdt/globus/lib
ichmod own tdh /GridWorksZone/home/tdh
iput -R rg test1A1
ils -l test1A1
  tdh               0 gridworks                  143920 2010-06-01.10:35 &amp; test1A1
irepl -R gwdca03 test1A1
ils -l test1A1
  tdh               0 gridworks                  143920 2010-06-01.10:35 &amp; test1A1
  tdh               1 gwdca03                    143920 2010-06-01.11:29 &amp; test1A1
&lt;/pre&gt;

---++++ Register a file in local resource into iCAT

As the user &quot;rods&quot;. The file must exist, though no transfer will occur.

&lt;pre&gt;
touch ~/ireg_test1
ireg /home/irods/ireg_test1 /GridWorksZone/home/rods/ireg_test1
ireg -G rg -R gridworks /home/irods/ireg_test1 /GridWorksZone/home/rods/ireg_test1
ils
/GridWorksZone/home/rods:
  ireg_test1
  test7A1
  test7A2
  test7A3
ls /data1/home/rods/
test7A2  test7A3
&lt;/pre&gt;

Attempting to register a file on a remote gridftp resource fails

&lt;pre&gt;
ireg -G rg -R gwdca03 /home/irods/ireg_test3 /GridWorksZone/home/rods/ireg_test3
ERROR: regUtil: reg error for /GridWorksZone/home/rods/ireg_test3, status = -305111 status = -305111 USER_SOCK_CONNECT_ERR, Connection refused
&lt;/pre&gt;

because it is a compound resource.

---++++Querying the database

&lt;pre&gt;
iquest &quot;SELECT COLL_NAME WHERE COLL_NAME like &#39;/GridWorksZone/home/%&#39;&quot;
COLL_NAME = /GridWorksZone/home/gwadmin
------------------------------------------------------------
COLL_NAME = /GridWorksZone/home/gwgroup
------------------------------------------------------------
COLL_NAME = /GridWorksZone/home/public
------------------------------------------------------------
COLL_NAME = /GridWorksZone/home/rods
------------------------------------------------------------
COLL_NAME = /GridWorksZone/home/tdh
------------------------------------------------------------
COLL_NAME = /GridWorksZone/home/testuser
------------------------------------------------------------
&lt;/pre&gt;

&lt;pre&gt;
[irods@gw014k1 iRODS]$ iquest &quot;SELECT DATA_NAME, DATA_CHECKSUM, DATA_VERSION, DATA_PATH, DATA_COLL_ID, DATA_RESC_NAME, DATA_STATUS  WHERE DATA_PATH like &#39;%rods/test%&#39;&quot;
DATA_NAME = test7A1
DATA_CHECKSUM = 
DATA_VERSION = 
DATA_PATH = /home/irods/test7A1
DATA_COLL_ID = 10008
DATA_RESC_NAME = gridworks
DATA_STATUS = 
------------------------------------------------------------
DATA_NAME = test7A2
DATA_CHECKSUM = 
DATA_VERSION = 
DATA_PATH = /data1/home/rods/test7A2
DATA_COLL_ID = 10008
DATA_RESC_NAME = gridworks
DATA_STATUS = 
------------------------------------------------------------
&lt;/pre&gt;

---++++ Add metadata to a collection

&lt;pre&gt;
imkdir dataset1
imeta -C add dataset1 OurVOName/dataset/file8A1 DEFINED
imeta -C add dataset1 OurVOName/dataset/file8A2 DEFINED
imeta -C add dataset1 OurVOName/dataset/file8A3 DEFINED
imeta -C add dataset1 OurVOName/dataset/file8A1 UPLOADING
imeta -C mod dataset1 OurVOName/dataset/file8A2 DEFINED v:UPLOADING
iquest &quot;SELECT COLL_NAME, META_COLL_ATTR_VALUE WHERE COLL_NAME like &#39;/GridWorksZone/home/tdh/%&#39;&quot;
COLL_NAME = /GridWorksZone/home/tdh/dataset1
META_COLL_ATTR_VALUE = DEFINED
------------------------------------------------------------
COLL_NAME = /GridWorksZone/home/tdh/dataset1
META_COLL_ATTR_VALUE = UPLOADING
------------------------------------------------------------
iquest &quot;SELECT COLL_NAME, META_COLL_ATTR_NAME WHERE META_COLL_ATTR_VALUE like &#39;DEFINED&#39;&quot;
COLL_NAME = /GridWorksZone/home/tdh/dataset1
META_COLL_ATTR_NAME = OurVOName/dataset/file8A1
------------------------------------------------------------
COLL_NAME = /GridWorksZone/home/tdh/dataset1
META_COLL_ATTR_NAME = OurVOName/dataset/file8A3
------------------------------------------------------------
&lt;/pre&gt;

---++++ Register resources that use the &quot;clientside&quot; driver

The new resource group &quot;gw&quot; is automatically created.

&lt;pre&gt;
  623  iadmin mkresc cascade &quot;clientside&quot; cache  cascade.fnal.gov /pnfs/fnal.gov/data
  624  iadmin mkresc cd-97177 &quot;clientside&quot; cache  cd-97177.fnal.gov /pnfs/fnal.gov/data
  625  iadmin atrg gw cascade
  626  iadmin atrg gw cd-97177
&lt;/pre&gt;

---++++ Create aliases so that requests to remote registered resources are handled by the local server.  

Can be done on a running server.

&lt;pre&gt;
$ tail -2 server/config/irodsHost
localhost cascade.fnal.gov cascade 
localhost cd-97177.fnal.gov cd-97177
&lt;/pre&gt;

---++++ 

&lt;pre&gt;
&lt;/pre&gt;

---++++ 

&lt;pre&gt;
&lt;/pre&gt;

---+++ iRODS deployment guidelines

---++++ Platform

---++++ Maintenance

   * Database backup
   * Database vacuuming
   * Recompute database indices
   * Monitoring

---++++ Authorization

   * GSI deployment
   * Cert update procedure
   * Security alert procedure

---++++ SLA-like goals
 
   * Uptime target
   * Security alert policy
      * Incident reporting policy
   * Maintenance notices
   * Support hours

---++++ Administration

This assumes the SOA model.

   * Supply and update buildable package with custom drivers and policies
   * Create auxiliary tables after deployment
   * Create OSG iRODS resource group
   * Register storage resources
   * Register VOs as users
   * Trigger data relocation or replication contingencies.
   * Create database indices as needed.

If the SOA model is not used, also

   * Register individual users
   * Maintain association of users and VOs

The last is due to the fact that extended attributes are not supported by iRODS.

---++++ Support

   * Ticketing
   * Assignees
   * Escalation
      * Other OSG staff
      * Rules for escalation to iRODS

---++++ Troubleshooting Help


 
---++globus.org

globus.org might be used as the transfer orchestration component of an iRODS custom storage driver.

---++FTS

-- Main.TedHesselroth - 19 May 2010
      

