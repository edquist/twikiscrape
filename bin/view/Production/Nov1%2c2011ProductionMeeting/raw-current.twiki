-- Main.DanFraser - 04 Oct 2011
---++ Action/Significant Items:
   * 

---++ Attendees:
   * Xin, Armen, Alain, Rob Q., Marco, Chander
   * Unable to attend: Dan (Travel), Tony (Out Sick), Mine (Out Sick)
 
---++ CMS (Tony)


---++ Atlas (Armen &amp; Xin)

   * General production status
      * Past Sunday LHC finished the pp collision program for this year. So we finished with the total collected luminosity for ATLAS at 5.25fb-1. LHC preparation is underway for the Heavy Ion collisions. On the way they may try a 2 day run of proton to Heavy Ion collisions. The expected period for the Heavy Ion run is Nov.14 - Dec.8.
      * US ATLAS production during the week was mainly stable, at the average level of 12K running jobs, with the exception of a drop on Mon-Tue. The problem was caused by misconfiguration of Panda at one of the ATLAS T1 sites, which created a big number of holding jobs, and backlog to register big amount of files, and load on the database. All the clouds were set to brokeroff for half a day. Situation is back to normal now, but all this event is under investigation to understand the chain of events and prevent it from reoccurring.
      * _Armen will followup next week_
   * Job statistics for last week.      
      * Gratia report: USATLAS ran 2.1M pilot jobs, with cpu/walltime ratio of 87% 
      * Real Jobs processed by US sites for last week, reported from PanDA monitor 
         * 915K
   * Data Transfer statistics for last week
      * Data transfer rate was 350T~550T/day at BNL T1 in last week.
   * ATLAS tested the new BDII is5 at GOC, it works fine. 
      * _Hiro also has approved moving forward_
   * Issues

---++ LIGO (Britta)

---+++ Gratia Reports

   * Current week&#39;s total usage: 4 users utilized 13 sites
      * 65540 jobs total (46937 / 18603 = 71.6% success)
      * 109418.5 wall clock hours total (100357.0 / 9061.5 = 91.7% success)
   * Previous week&#39;s total usage: 4 users utilized 30 sites
      * 29085 jobs total (21346 / 7739 = 73.4% success)
      * 69091.6 wall clock hours total (61624.4 / 7467.2 = 89.2% success)


---+++ LIGO/PULSAR
   * One 50,000 job dag submitted to local glidein factory, running over 18 OSG sites
      * Monitoring progress, no issues
   * Local OSG ITB testbed &quot;LIGO_CIT&quot; will be decommisioned
      * LIGO would like to utilize OSG glidein factory
---++ Grid Operations Center (Rob Q.)

---+++ Operations Last Week
   * [[http://tinyurl.com/42j3mgl][GOC Services Availability/Reliability]]
   * [[http://myosg.grid.iu.edu/miscstatus/index?datasource=status&amp;count_sg_1=on&amp;count_active=on&amp;count_enabled=on][Current Status]]
   * Production release [[http://osggoc.blogspot.com/2011/10/goc-service-update-tuesday-october-25th.html][Release note]] was deferred.
   * OS updates on production machines. Some reboots were required.
   * The recent JAVA security issue:
      * http://www.oracle.com/technetwork/topics/security/javacpuoct2011-443431.html
      * We will update this in the next regularly scheduled maintenance window and are prepared to update in the event of an incident.
   * !FermiGrid Ops
      * Updated to most recent Tomcat
   * WMS Glide In Factory
      * Registered Engage VO frontend at Renci with GOC Production factory
      * Began installing itb test frontend that we will use to test changes we make to the GOC ITB factory

---+++ Operations This Week

   * BDII v5 Validation Status Check
   * ITB release
      * Adding capability to use attachments with ticket exchange
   * Next week will do previous release.

---++ Engage (Mats)


---++ Integration (Suchandra)
   * RPM testing
      * Limited availability release of wn-client, osg-client, glexec
      * Steve Timm at FNAL will do larger scalability testing of glexec as worker nodes become available
      * xrootd installed at UC_ITB, looking for more ATLAS sites to help test
      * CE testing is going well, running into some issues but being resolved
      * Tony @ FNAL is conducting interoperability testing, no major problems so far

---++ Site Coordination (Marco)
Note that this report lists the currently active resources in OSG.
If a site is down or not reporting it will not be counted.
Therefore there may be fluctuations.
Each line has the current number and variation from last week in parenthesis.
You can find a table with current OSG and VDT versions at http://www.mwt2.org/~marco/myosgldr.php
   * Site update status (from !MyOSG as of today):
      * Most recent production version is OSG 1.2.24
      *       98 (12) OSG 1.2.X resources (       5 are 1.2.24)
      *        2 (0) OSG 1.0.X resources (       0 are 1.0.6)
      *        2 (0) OSG 1.0.0 resources


---++ User Support (Chander)
Additional Gratia data problems identified and are being worked; latest is a suspected bug in the PBS gratia probe that incorrectly maps userid name to be a VO.  (Perhaps the problem at BU_ATLAS reporting very large usage has been fixed).

---++ Security (Mine)
   * I am out sick. Just a written report below
   * Operational Security: 
      * Open incident and vulnerability tickets are closed. CERN incident and Java vulnerability
      * Kevin Hill replaced Jim Barlow for operational security
      * No new vulnerabilities, incidents
   * Ongoing updates and tests
      * New CA packages are in ITB being tested as the default package for all software
      * Need to hear from ITB about test progress/results/problems
      * Once tests are over, we need Productions/Operations team&#39;s help to handle the transition to production
   * Related to new VDT infrastructure (Koji, svn servers, etc), we need help from Operations team to understand CA package release process.  

---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings
