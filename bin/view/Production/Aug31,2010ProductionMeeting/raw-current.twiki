-- Main.DanFraser - 10 Aug 2010
---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings

---++ Action/Significant Items:
   * The continued inability to get information via the WLCG call about issues with the CERN BDII is problematic and indicative of a WLCG process problem. One way this is impacting OSG is that without a steady stream of information, we cannot take the risk of upgrading our critical BDII software. Dan to have Ruth bring this concern up at the next WLCG management meeting (Burt, Dan). 
   * Last week the OSG hit a new Production high of 7.25 million hours.
   * Both LIGO and Engage noted that increases in CMS production (like last week) represent troughs in opportunistic usage. It is important for OSG to broaden resources beyond CMS. 

---++ Attendees:
   * Mats, Xin, Armen, Britta, Robert E., Brian, Suchandra, Burt, Marco, Scott, Mine, Derek, Dan
 
---++ CMS (Burt)
   * LHC: continues to perform well.  Instantaneous luminosity at 10^31 (goal for this year: 10^32).
   * Tier 1 now open to CMS Monte Carlo production -- priority temporarily higher due to transition in VOMS roles
   * Job statistics: 419 khour/day, 93% success.
   * BDII bug: continuing to try to find out through proper channels what the cause was.  (I now have a link to the RPM if I want to try and do diffs..)

---++ Atlas (Armen &amp; Xin)

   * General production status
      * LHC has another good week with significant collected luminosity. At the moment technical stop till Thursday. ATLAS production level during last week was quite low (2-4k running jobs), and not stable. Yesterday ramped back up to the normal level of average 9-10k running jobs.
   * Job statistics for last week. 
      * Gratia report: USATLAS ran 2.1M jobs, with CPU/Walltime ratio of 64%. 
      * Panda world-wide production report (real jobs): no report this week (shift captain is on vacation)
   * Data Transfer statistics for last week
      * BNL T1 data transfer rate last week was ~400TB/day.
   * Issues 
      * SE-only info publishing to WLCG BDII for all USATLAS T3 sites: under test now.  
      * Open more job slots to OSG users: no updates, people on vacation

---++ LIGO (Britta, Robert E.)

---+++ Gratia Reports
   * This week&#39;s total usage: 5 users utilized 37 sites
      * 49349 jobs total (22767 / 26582 = 46.1% success
      * 517340.9 wall clock hours total (331720.7 / 185620.2 = 64.1% success)
   * Last  week&#39;s total usage: 4 users utilized 39 sites
      * 69587 jobs total (46648 / 22939 = 67.0% success)
      * 964151.5 wall clock hours total (854478.8 / 109672.7 = 88.6% success)

---+++ LIGO / E@OSG
   * Recent Average Credit (RAC):1,707,021.74558, Last week: 2,249,756.08063
   * E@H rank based on RAC: 1 (+-0)
   * E@H rank based on accumulated Credits: 4 (+-0)

---+++ LIGO / INSPIRAL
   * OSG-LIGO storage task force
      * Wrote transfer script to enable file transfers via srm-copy
      * Testing and troubleshooting srm-copy transfers to UCSDT2, TTU_ANTAEUS, UMiss_HEP
      * Improving code: error handling
         * Writing improved/robust scripts for file transfers this week/next
         * Will test and document and hand code over to Robert for further testing by September 10
   * Glideins
      * Testing work-flow with SRM setup at Firefly - Running
      * Testing file transfer dag Nebraska --&gt; Firefly, 5000 files
         *  test run 1: run time 7.5 hours, no apparent ails  
         * test run 2: run time 29 minutes, no apparent fails

---++ Grid Operations Center (Scott T. for Rob Q.)

   * No release this week, 5th Tuesday of August.
   * Mine and Justin (IU IT security office) are in contact regarding the GOC security scan.
   * A plan for the repair of the RSV-SAM uploader system will be prepared by 7/Sep. This plan includes the retirement of &quot;sonofsam&quot;, target date: 1/Oct.
   * [[https://twiki.grid.iu.edu/bin/view/Operations/GOCServiceOutageAug232010][Updated outage report]]

---++ Engage (Mats, John)

   * Available opportunistic slots was way down last week due to CMS increase. Concern is that Trash/Engagement is so dependent on CMS resources.
   * No other production issues

---++ Integration (Suchandra)
   * Released OSG 1.2.13 on Thursday
   * Prepping for new ITB testing
      * Catch up release with several smaller fixes and updates
 
---++ Site Coordination (Marco)
Note that this report lists the currently active resources in OSG.
If a site is down or not reporting it will not be counted.
Therefore there may be fluctuations.
Each line has the current number and variation from last week in parenthesis.
You can find a table with current OSG and VDT versions at http://www.mwt2.org/~marco/myosgldr.php
   * Site update status (from !MyOSG as of today):
      * Most recent production version is OSG 1.2.13
      *       90 (0) OSG 1.2.X resources (       3 are 1.2.13)
      *        3 (-1) OSG 1.0.X resources (       0 are 1.0.6)
      *        5 (2) OSG 1.0.0 resources
      *        1 (0) OSG 0.8.0 resources
Site Coordination meeting this Thursday 9/9 at 11am central
   * Phone: 866-740-1260, code 8349885#
   * Adobe connect: http://osg.acrobat.com/osgsc100909/
   * Special topic to be defined

---++ Metrics (Brian)


---++ Virtual Organizations Group (Abhishek)


---++ Security (Mine)
   * Ticket 8872 is the concern. We wait for GOC to apply the patch to RSV probe. the probe tells us when our CA cache content falls out of synch from IGTF. This is not emergency but we like to get it done. 
   * The certificate request web page is ready to go. The atlas and cms users have strongly requested the page. We thought we were promised to be on the production today. but we understand we were wrong. 
   * Scott says both ticket 8872 and the request web page will go live on 9/14. This is OK by us. 
   * The pakiti server active and being monitored. We sent a first batch of emails to T3 admins with critical security patches missing. We work with Snihur to get each T3 site to sign up for Pakiti. We have 4 out of 10 . We wrote down a how-to page on how to use Pakiti, explaining the status flags. https://twiki.grid.iu.edu/bin/view/Security/PakitiHelp
   * There are no vulnerabilities or ongoing incidents reported. 
   * D0 data transfer is halted at UCSD due to service certificate usage. We approved the usage of service certificates today. The certificate is put into D0 VOMS server. Emailed Terrence to synch up his GUMS with D0 VOMS. 
   * We are writing a policy document on usage of service certificates in OSG.  
