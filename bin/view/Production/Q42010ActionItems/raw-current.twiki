%TABLE{ tablewidth=&quot;700&quot; columnwidths=&quot;5%, 15%, 80%, 10%, 10%&quot; cellpadding=&quot;2&quot; dataalign=&quot;left&quot; tablerules=&quot;all&quot; tableborder=&quot;2&quot; databg=&quot;#FFFFFF, #FFFFFF&quot;}%
| # | Owner | Action/Significant Item | Open Date | Close Date |
|41| All | CMS plans to test the new BDII (IS4) before the next production change cycle on Jan 11. | 12/21/2010 | |
|40| All | A power outage at CERN over the past weekend caused production issues with both Atlas and CMS for about 4 hours until power was restored. | 12/21/2010 | |
|39| Marcia | Glue-X reported that it has fixed the SE bug that was keeping DZero jobs from running at UConn. | 12/14/2010 | |
|38| All | There is growing pressure from both Atlas and CMS to inter-operate with the new CREAM CE; both are relying on the OSG Cream distribution in the VDT. | 12/14/2010 | |
|37| Burt |  CMS is planing to test the new BDII (IS4) this week before putting it into the production round robin. | 12/14/2010 | |
|36| All | Atlas pilot error rates were back to the normal range this week. Xin noted that there were a variety of issues that contributed including an LSF issue that was affecting Condor. Jamie Frey was called in from the Condor team to help. The fix was to cache some of the LSF commands that Condor relies on for its information. | 12/14/2010 | |
|35| Scott | GGUS certificate update, scheduled for 2:00 EST 9/Dec, have requested change to 8:00 EST. Ticket exchange will be down between GGUS&#39;s update and OSG&#39;s update of the trusted certs list. Notification sent to community. | 12/7/2010 | | 
|34| Scott | BDII timeout at CERN was changed back to the original 30 seconds from the stopgap 120 seconds of the last 4 weeks. No problems were encountered either end. | 12/7/2010 | |
|33| All | Error/failure rates of Atlas jobs were running much higher than normal. Initial thought from Armen was that this was due to a new Pilot version. Armen/Xin to double check. | 12/7/2010 | |
|32| All | New BDII v5 machine (IS4) had a few hiccups last week but is now ready for testing by Atlas, CMS. When testing is complete, we will put it into the production round-robin. | 12/7/2010 | |
|31| Dan to follow up | The OSG Council has requested a breakout of usage by science-type. We have data from the largest VOs, but still need a breakdown from GLOW. | 11/30/2010 | |
|30| All | There is a significant number of sites (5-10) that have been more than a month in installing critical patches. Mine to discuss with the OSG ET. | 11/30/2010 | |
|29| Rob | The GOC is coordinating with CERN on restoring the timeout back to 30s from the current 120s. The plan is to try and do this at a time when the GOC can watch closely for any initial problems. | 11/30/2010 | | 
|28| Rob, Burt, Xin | A new BDII v5 (IS4) has been setup on bare hardware (not a VM) and should be ready for testing on Thursday. Assuming that CMS and Atlas are able to test this and send approval, the plan will be to put it into the production round robin next Tuesday. | 11/30/2010 | |
|27| Rob | Since problems were discovered last week with OpenLDAP?&lt;https://twiki.grid.iu.edu/bin/edit/Production/OpenLDAP?topicparent=Production.Nov23,2010ProductionMeeting&gt; running inside a VM, a new v5 BDII (IS4) running on its own machine will be placed into production next week for testing. | 11/23/2010 | |
|26| All | The network problem at the Indiana POP has been fixed. Xin has restored the full Atlas publishing datasets into the BDII and no further problems have been seen. Rob has requested that CERN not restore the timeout settings until next week due to the upcoming holiday weekend. | 11/23/2010 | |
|25| All | There will be a power outage at FNAL on Thursday between 5am and 8am to fix a faulty breaker. This will affect Gratia, ReSS, and all FermiGrid?&lt;https://twiki.grid.iu.edu/bin/edit/Production/FermiGrid?topicparent=Production.Nov16,2010ProductionMeeting&gt;-managed gatekeepers (FNAL_FERMIGRID, FNAL_GPGRID_1). | 11/16/2010 | |
|24| Rob, Dan | A BDII issue on the ITB required an LDAP restart yesterday. Based on discussions with the BDII developers, there is a known issue with OpenLDAP?&lt;https://twiki.grid.iu.edu/bin/edit/Production/OpenLDAP?topicparent=Production.Nov16,2010ProductionMeeting&gt; when running in a VM, as the IS3 BDII v5 is currently doing at the GOC. Because of this issue, we will NOT move IS3 into the production round robin next week. We will be updating the plan on how to proceed with the v5 upgrade. | 11/16/2010 | |
|23| Xin | Assuming that the problem stays fixed for the next 12 hours or so, the next step will be for BNL to start publishing the full amount of data again sometime tomorrow. | 11/16/2010 | |
|22| Rob, Burt, Xin, Dan... | The issue where the CERN BDII was dropping BNL was temporarily corrected by lengthening the timeouts from 30s to 120s and decreasing the amount of data published by BNL. Last week however it was recognized that underlying issue was a network issue. Several folks from the GOC, Internet2, and FNAL spent some time looking into this. The issue was finally traced to the Indiana GigaPOP?&lt;https://twiki.grid.iu.edu/bin/edit/Production/GigaPOP?topicparent=Production.Nov16,2010ProductionMeeting&gt; and appears, as of earlier today, to have been resolved. | 11/16/2010 | |
|21| All | On Nov 4 &amp; 5 LIGO was running a significant number of jobs on the CMS T1, but Gratia reported no activity on the T1 for this period. Dan to follow up with the Gratia team. | 11/9/2010 | |
|20| Rob | A new BDII (IS3) running v5 was added in parallel to the production BDIIs according to the transition plan; it will not added into the BDII round robin until OSG has the all clear from Atlas and CMS. There was an issue however where IS3 stopped accepting new entries after a few hours and needed to be restarted. The GOC team is investigating this problem with the developers. | 11/9/2010 | |
|19| All | Atlas continues to have issues with the CERN BDIIs and Sam BDIIs where BNL (and some Atlas Tier-2) data is stale or unavailable. It is unclear if this problem is related to case sensitivity issues or another problem altogether. The data appears fine in the OSG BDIIs. Action is for Dan to start an email activity with the CERN BDII developers to help track down the problem. In parallel, Rob is planning to examine the &quot;-debug&quot; output from the BDIIs that will show when case sensitive issues appear. | 11/9/2010 | |
|18| Rob | There was an Atlas critical alarm at about 3:30 am on Sunday morning against the T1 dCache system. In addition to getting the problem resolved (in two hours), this demonstrated that the emergency communication channels are working properly. | 11/9/2010 | |
|17| All | The CMS T1 noted that when they tried to upgrade to the latest OSG CE version 1.2.15, CEMon failed to publish data so they failed back to 1.2.8. Burt is working with Parag to try and resolve this. | 11/9/2010 | |
|16| All | Doug Olsen is transitioning to a position with Magellan and will no longer be working as part of the OSG Security team. | 10/26/2010 | |
|15| Robert | LIGO is now up to 90% of its August peak. | 10/26/2010 | |
|14| All | Burt and Xin have given approval to begin the transition to BDII v5. Scott T. presented a transition plan that will introduce additional (virtualized) BDIIs into the round robin and allow for power user testing before incorporating these into production. In the future, as demand increases, this will enable the GOC to easily add extra virtual servers. | 10/26/2010 | |
|13| All | There was a problem with the Indianapolis-based BDII (is2.grid.iu.edu&lt;http://is2.grid.iu.edu&gt;) between the hours of 18:30 UTC and 21:45 UTC. The issue was traced back to a IP renumbering project (as part of the maintenance) which had unforeseen affects on the internal DNS and LDAP. As soon as the issue was identified, the maintenance was stopped and service was rolled back to the pre-maintenance configuration. | 10/26/2010 | |
|12| All | Marcia Teckenbrock will be taking over Abhishek&#39;s role for reporting VO data on the production call. Welcome Marcia! | 10/19/2010 | |
|11| All | LIGO usage on OSG \ is steadily building back up, still holding rank 1. | 10/19/2010 | |
|10| All |  Burt&#39;s team completed one round of data comparisons between BDII v4 and v5. A handful of discrepancies were found including a minor bug in the GIP (Burt to send out an email describing this) and several sites publishing incorrect data (these have been contacted), but no issues were found with the BDII itself. Burt is planning to rerun the comparison data script tomorrow before giving final approval to schedule the change. | 10/19/2010 | |
|9| All | Lots of folks at CHEP this week. | 10/19/2010 | |
|8| Mine | Pakiti now being used to monitor security patches on the CMS Tier-3 sites. | 10/12/2010 | |
|7| All | Opportunistic usage back at roughly 70% (LIGO), and the overall peak OSG usage is holding at ~8M hours per week. | 10/12/2010 | |
|6| All | Rob to discuss with Lawrence (next week at CHEP) the need for getting Soichi&#39;s fix for keeping the BDII update process from dying into a release version ASAP. | 10/12/2010 | |
|5| Burt | Time varying consistency checks between the BDII versions are needed from Burt&#39;s team as the next step in the possible BDII upgrade from v4 to v5. Should have these tests completed in the next few days. | 10/12/2010 | |
|4| Dan | BDII access has now scaled to the point that one BDII is no longer capable of maintaining the entire load. We need to either a) update to the latest v5 that has a factor of ~3 improvement very soon, or b) introduce another BDII server into the round robin, or c) upgrade the hardware on the BDIIs. | 10/5/2010 | |
|3| All | Burt has agreed to allow the GOC to upgrade to BDII v5 once the v5 system has been sufficiently stress tested, and the data has been proven to be consistent with the v4 system. (BDII stress testing is underway at the GOC). While Burt&#39;s team was investigating the consistent data issue however, they noticed that there were some inconsistencies between the production BDIIs. Burt&#39;s team is continuing to investigate and will provide detailed info in the next few days. | 10/5/2010 | |
|2| All | GOC is planning a machine room move of the BDIIs on Oct. 12. Notice will be sent out that there may be some SAM tests failing for ~10 minutes while the BDII is transitioned. | 10/5/2010 | |
|1| Dan | Plan to have a meeting in the next few weeks with Michael E, Chander, Dan, and Rob G. on opportunistic usage for Atlas T1s and T2s. Dan to setup. | 10/5/2010 | |



-- Main.SarahCushing - 11 Oct 2010
