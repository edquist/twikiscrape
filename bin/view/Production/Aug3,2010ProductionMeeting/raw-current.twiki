-- Main.DanFraser - 12 Jul 2010
---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings

---++ Action/Significant Items:
   * There is a potential !DoS Vulnerability in !OpenLDAP. The patch was applied to the ITB BDII, and will be applied to the production BDIIs next week. Analysis is ramping up again on the CMS and Atlas sites so we will wait to perform further BDII upgrades. 
   * The dCache Gratia transfer probe that groups transfers (as opposed to recording individual transfers) has been installed and verified at Fermilab. Load on the Gratia collectors dropped by ~40% as a result of this change. Atlas will deploy the probe this week. (Burt, Xin)
   * LIGO submissions were starting up too agressively at Nebraska and overwhelming the gatekeeper. The GRIDMANAGER_MAX_JOBMANAGERS_PER_RESOURCE parameter was changed from 150 to 15 to fix this problem. (Robert)
   * Kernel updates on ReSS? machines on Thursday, Aug. 4 2010. High Availability will be used to make sure one or the other ReSS? server is available throughout the reboot. (Rob)
   * DOE is switching away from the CISCO system so the phone dial-in coordinates for the production call will need to change sometime in the next several weeks.  

---++ Attendees:
   * Xin, Armen, Britta, Brian, Suchandra, Burt, Marco, Abhishek, Rob Q., Dan
 
---++ CMS (Burt)
   * 235 khour/day. 91% success rate
   * Much of that: WMAgent scale-testing and Monte Carlo production
   * Machine luminosity took another jump forward up to 25x25 bunches; last weekend got 125 nb^-1 delivered (roughly 25% increase in dataset)

---++ Atlas (Armen &amp; Xin)

   * General production status
      * After the technical stop LHC is back with quite improved luminosity. During the week period ATLAS doubled the collected luminosity (to 700 nb-1).Production was low at the beginning of the week and picked up to normal level of average 8-9k running jobs. Event generation of the new simulation campaign is going on. Will be proceeded with G4 simulation, and then reconstruction during September. 
   * Job statistics for last week. 
      * Gratia report: USATLAS ran 2.5M jobs, with CPU/Walltime ratio of 72%. 
      * Panda world-wide production report (real jobs): 
         * completed successfully 473k managed MC production, validation and reprocessing jobs 
         * average 68K jobs per day
         * failed 56K jobs
         * average efficiency:  jobs  - 90%
   * Data Transfer statistics for last week
      * BNL T1 data transfer rate last week was 200~400TB/day.
   * Issues 

---++ LIGO (Britta, Robert E.)
---+++ Gratia Reports
   * Current week&#39;s total usage: 5 users utilized 38 sites
      * 75715 jobs total (47016 / 28699 = 62.1% success)
      * 1042631.0 wall clock hours total (933233.0 / 109398.0 = 89.5% success)
   * Last week&#39;s total usage: 4 users utilized 35 sites
      * 98316 jobs total (48838 / 49478 = 49.7% success)
      * 1261989.2 wall clock hours total (996992.3 / 264996.9 = 79.0% success)

 ---+++ LIGO / E@OSG
   * Recent Average Credit (RAC):   2,316,619.81474, Last Week:2,094,259.83992
   * E@H rank based on RAC: 1 (+-0)
   * E@H rank based on accumulated Credits: 4 (+-0)

 ---+++ LIGO / INSPIRAL
   * OSG-LIGO  storage task force
      * Successfully ran 5000 file transfer LDG-&gt;Nebraska, run time:
      * Successfully ran 5000 file transfer Nebraska --&gt; FIREFLY, run time:
      * Running transfer Nebraska --&gt;CIT_CMS
      * Ran RLS population 60000 files, run time:
      * Writing documentation &#39;How To&#39; page on file transfer procedure
   * Testing Pegasus glidein tool on Firefly

---++ Grid Operations Center (Rob Q.)

---+++ Operations Last Week
   * Last week&#39;s ... 
      * [[http://tinyurl.com/37ou4gm][Reliability/Availability of GOC Services]] 
         * Host relocation at Indianapolis site:
            * twiki, OIM unavailable
            * BDII, all other services served from single site
      * [[http://osggoc.blogspot.com/2010/07/goc-service-update-tuesday-july-27th-at.html][Production release:]]
         * OIM 2.22
         * !MyOSG 1.23
         *  GOC Ticket 1.23
         *  OSG Display 1.0.6
         * GOC Ticket Synchronizer 1.9
      * [[https://twiki.grid.iu.edu/bin/view/Operations/GOCServiceOutageJuly162010][July 16th, Outage Report Available]]
      * [[https://twiki.grid.iu.edu/twiki/pub/Operations/Minutes2010July26/cron_audit.pdf][Audit of cron jobs available]]

---+++ Operations This Week

   * Normal ITB Release August 3rd
      * Production Release August 10th 
   * Potential !DoS Vulnerability in !OpenLDAP (http://rhn.redhat.com/errata/RHSA-2010-0542.html)
   * Two Tickets Opened on Long Standing ITB Tickets
      * configure-osg issue (https://ticket.grid.iu.edu/goc/viewer?id=9012)
      * GUMS RSV Probe (https://ticket.grid.iu.edu/goc/viewer?id=9013)

---++++ Gratia and !ReSS 
   * Kernel updates on ReSS machines on Thursday, Aug. 4 2010.  High Availability will be used to make sure
     one or the other ReSS server is available throughout the reboot. Likely 9AM or 10AM

---++ Engage (Mats, John)


---++ Integration (Suchandra)
   * Finishing up ITB 1.1.24 testing
      * Waiting for signoff from GIP
      * Ready to release after signoff
   * ITB 1.1.25 testing
      * Update to xrootd  and other components    
      * Will start after release of OSG 1.2.12


---++ Site Coordination (Marco)
Note that this report lists the currently active resources in OSG.
If a site is down or not reporting it will not be counted.
Therefore there may be fluctuations.
Each line has the current number and variation from last week in parenthesis.
You can find a table with current OSG and VDT versions at http://www.mwt2.org/~marco/myosgldr.php
   * Site update status (from !MyOSG as of today):
      * Most recent production version is OSG 1.2.11
      *       84 (1) OSG 1.2.X resources (      13 are 1.2.11)
      *        5 (0) OSG 1.0.X resources (       0 are 1.0.6)
      *        4 (0) OSG 1.0.0 resources
      *        1 (0) OSG 0.8.0 resources
OSG Site Administrators workshop August 10-11 2010
   * http://indico.fnal.gov/conferenceDisplay.py?confId=3429 
Site Coordination meeting this Thursday 8/5 at 11am central
   * SiteCoordination.SitesCoord100805
   * Phone: 510-665-5437, #1212
   * Adobe connect: http://osg.acrobat.com/osgsc100805/
   * Special topic will be planning for August Site Administrators meeting - requirements for attendees 


---++ Metrics (Brian)


---++ Virtual Organizations Group (Abhishek)

---+++ D0
   * *Milestone:*  D0 Collaboration has surpassed 1 Billion MC Events produced using the OSG.
   * Monte carlo production continuing at good rate.
   * Last week: 13 Million Evts/week. 
      * 80,000 hours/day at 87% efficiency.
      * D0 internal problems: Xindice DB issues in SAMGrid infrastructure. Now resolved.
      * OSG sites related issues: Low efficiency at MIT and !GridUNESP. 

---+++ GLUE-X
   * Discussions moving forward between Richard and Jefferson lab computing division. 
   * Cycles available for other VOs at UConn-OSG site.
   * Looking into the streamlined !GlideinWMS submit procedure document.
   * OSG Security providing assistance. GLUE-X has not heard yet on the review of the document: 
      * http://zeus.phys.uconn.edu/UConn-OSG/client-services.html

---+++ OSG-VO (CHARMM with Panda)
   * Discussed last week&#39;s issues with Maxim, Jose (BNL/Panda) and Tim (NHLBI/NIH).
   * %RED%Problem 1:%ENDCOLOR% An abrupt scale-up from 3 to 30 sites created some confusion for a few sites.
      * Arrival of pilots looked unexpected to some sites. 
      * System overload led to minor confusion that activity may be DDOS.
   * %RED%Problem 2:%ENDCOLOR% Not all sites supporting OSG-VO understand that it is used for actual production by specialized groups. 
   * Have recommended CHARMM group to pursue a more gradual approach, and focus on a smaller number of sites. 
   * Have asked CHARMM group for wall-hour needs and requirements.

---+++ !IceCube
   * Glidein submission front-end is getting ready to start the scale-up of production.
   * Some staff transition from !IceCube to Condor team expected in coming months.

---++ Security (Mine)
