-- Main.BrittaDaudert - 12 Sep 2011
---++ Action/Significant Items:
   * Gratia Reporting Outage due to bad upgrade followed by a hardware failure. Ops is following up with Gratia Operators to get previous reports distributed. 
   * Jon Bakken has moved to a different department at FNAL, Burt will be taking his place on October 1st, so Tony will soon be the regular attendee at this meeting. 

---++ Attendees:
   * Armen, Burt, Rob Q., Scott T.
 
---++ CMS (Burt)
   * Machine: colliding protons again after technical stop.
   * Metrics: no gratia reports this week

---++ Atlas (Armen &amp; Xin)

   * General production status
      * LHC is back in business since last Wednesday. Quite productive week for data taking. Total collected luminosity for ATLAS now is 2.8fb-1.
      * US ATLAS production during the week was quite stable, at the level of 12K running jobs, mainly simulation jobs. Preparation for a new round of reprocessing is going on.
   * Job statistics for last week.      
      * Gratia report: USATLAS ran 2.67M pilot jobs, with cpu/walltime ratio of 87% 
      * Real Jobs processed by US sites for last week, reported from PanDA monitor 
         * 960K 
   * Data Transfer statistics for last week
      * Data transfer rate was 300TB~530TB last week at BNL T1. 
   * Issues
      * Cancelled downtime still affects site availability calculation
         * GOC ticket https://ticket.grid.iu.edu/goc/10984
         * results need to be corrected, so that the monthly report won&#39;t be affected. 
         * GOC is helping trace it with SAM folks now. 

---++ LIGO (Britta, Robert E.)
   
---+++ Gratia Reports
   * No metrics report received this week

    | VO        |   Cores |     Njobs |     Delta |      Wall    |      Delta    | CpuToWall |     Delta | %Effi | Delta |
    | ligo        |       1    |   73,280 | -48,330 | 388,399.6 |   -308,926 |      0.65      |      0.06 |   65  | 6 |   

---+++ LIGO/E@OSG

   * Recent Average Credit (RAC):919,207.59715
   * E@H rank based on RAC: 2 (+-0) 
   * E@H rank based on accumulated Credits: 3 (+-0)

---+++LIGO/Pulsar Powerflux   
   * Monitoring 10GB data dags at 5 OSG sites via corral glidein service
      * Investigating hangup error at Purdue
   * Monitoring 50.000 job dag running via local glidein factory
     
---++ Grid Operations Center (Rob Q.)
---+++ Announcements
   * Rob and Scott at CERN, EGI Technical Forum 15-29/Sep (Geneva and Lyon, France)
      * Unless there is an emergency that requires our attendance Operations will not be in attendance at the next two Production Meetings.

---+++ Operations Last Week 
   * [[http://tinyurl.com/3k3lqjh][GOC Services Availability/Reliability]]
   * [[http://myosg.grid.iu.edu/miscstatus/index?datasource=status&amp;count_sg_1=on&amp;count_active=on&amp;count_enabled=on][Current Status]]
   * ITB release, [[http://osggoc.blogspot.com/2011/09/goc-service-update-september-13th-at.html][release notes]] are available
   * Gratia slowness reported on GRATIA-OSG-PROD twice on Thurs 9/1 eventually traced to bad disk.  Disk was replaced, OK by afternoon of 9/2.
   * Massive power outage in San Diego Thursday 9/8 3:30 pm (PT) until around Friday 9/9 12 am (PT)
      * Radius spanned from Orange County down to Baja Californa, and east to Arizona.
      * Believed to be caused by a problem during a utility repair job in Yuma, AZ.
      * Our machines and equipment were brought back up around 10:00 am (PT) on Friday 9/9
         * No damage to hardware
      * The UCSD Factory was up and running again by Friday 9/9 10:30 am (PT)
      * Effects of outage on UCSD Factory
         * Only negative effect is new glideins cannot be submitted
         * Glideins already running on grid are not effected
         * User jobs running on grid are not effected and should complete normally
         * Glideins already running can continue to accept new user jobs until they reach their retire time
      * Attached below are plots of monitoring during outage from UCSD factory
         * note the frontend monitoring depends on the factory being up to accurately report, during the outage the number of jobs running did *not* go to zero.
         * [[https://twiki.grid.iu.edu/twiki/pub/Operations/Minutes2011September12/outage_cms.png][Graph of CMS Frontend during power cut.]]
   * ITB Factory machine has high load due to insufficient CPU

---+++ Operations This Week
   * Production release, [[http://osggoc.blogspot.com/2011/09/goc-service-update-september-13th-at.html][release notes]] are available
   * OIM will move to Bloomington, service will be unavailable for a short period during the move.
   * We expect a Middleware Release from VDT containing the Apache DoS patch. 
   * New VO Package Release with LBNE expected. 

---++ Engage (Mats, John)


---++ Integration (Suchandra)
   * Released OSG 1.2.22
      * Addresses an apache httpd DOS vulnerability
   * working on rpm testing
      * External beta testing of worker node client and glexec continuing
      * About to switch to testing wn client based on globus 5.2

---++ Site Coordination (Marco)


---++ Virtual Organizations Group (Chander)


---++ Security (Mine)

---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings
