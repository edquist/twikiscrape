-- Main.DanFraser - 05 Jul 2011
---++ Action/Significant Items:
   * Record week for CMS at 592 khours/day.
   * The CERN based glide-in factory was brought up and a status update requested. 
   * Mats will bring an update on the ATLAS Opportunistic Engage process to next weeks Production Meeting. 
   * LIGO Request for additional opportunistic resources did not produce any results. Should we target individual resources? 

---++ Attendees:
   * Mats, Xin, Britta, Burt, Rob Q., Scott T., Mine, Chander, Armen, Marco, Suchandra
 
---++ CMS (Burt)
   * Machine: coming back from Technical Stop
   * Last week: 592 khours/day (!) , 82% success
   * Tier 1 opportunistic access still disabled -- will be until we *fix* our power issues.  

---++ Atlas (Armen &amp; Xin)

   * General production status
      * LHC was in Technical Stop until Friday last week. Is recovering with some technical glitches. Probably will be back today.
      * US ATLAS production was quite stable at the average level of about 12k running jobs. Big majority of the jobs are from Geant4 re-simulation campaign of all the existing MC samples. 
   * Job statistics for last week.      
      * Gratia report: USATLAS ran 1.6M jobs, with CPU/Walltime ratio of 91%. 
      * Panda world-wide production report (real jobs): 
         * completed 1.4M managed group, MC production, validation and reprocessing jobs 
         * average 196K jobs per day
         * failed 88K jobs 
         * average efficiency:  jobs - 94%
      * Real Jobs processed by US sites for last week, reported from PanDA monitor 
         * 1.0M 
   * Data Transfer statistics for last week
      * No report of transfer data for last week, due to gratia probe crash on the BNL node. Restarted, will recover the missing data and catch up shortly (in next week&#39;s report). 
   * Issues
      * OSG opportunistic access to USATLAS sites: 
         * HCC: roadblock cleared for SLAC, SLAC should be up soon; NET2 T2 still needs to find cycles to enable it. 
         * Engage: no update last week
      * update of LFC in VDT/OSG client packages : preliminary version under testing

---++ LIGO (Britta, Robert E.)
---+++ Gratia Reports

   * Previous week&#39;s total usage: 3 users utilized 34 sites
      * 49359 jobs total (40054 / 9305 = 81.1% success)
      * 310520.7 wall clock hours total (293148.7 / 17371.9 = 94.4% success)
   * Current week&#39;s total usage: 4 users utilized 32 sites
      * 54467 jobs total (42069 / 12398 = 77.2% success)
      * 370463.2 wall clock hours total (330243.2 / 40220.0 = 89.1% success)

---+++ LIGO / E@OSG
   * Recent Average Credit (RAC): 998,006.72413 , Last Week: 802,186.97374
   * E@H rank based on RAC: 1 (+1)
   * E@H rank based on accumulated credits: 3 (+-0)


---+++ LIGO / INSPIRAL
   * Caltech Glidein Frontend testing:
      * Successfully ran a small Powerflux test dag
      * Submitted larger test work-flow, no fails so far
      * Troubleshooting 32 bit install of LIGO code

---+++ LIGO/PULSAR
   * One 100,000 job dag running at UFlorida_PG, UCSDT2, LIGO_CIT, Nebraska
   * Twelve 50,000 job dags running at  12 OSG sites: USCMS-FNAL-WC1-CE3, GridUNESP_CENTRAL, LIGO_UWM_NEMO, Purdue-RCAC, Firefly, UFlorida-PG, 
     UCSDT2,  Nebraska, LIGO_CIT, SPRACE, STAR_BNL, CORNELL
   * submit host slow and at times unresponsive, possibly due to too many condor shadow processes or heavy I/O


---++ Grid Operations Center (Rob Q.)

---+++ Operations Last Week 
   * [[http://tinyurl.com/27fknc6][GOC Services Availability/Reliability]]
   * [[http://myosg.grid.iu.edu/miscstatus/index?datasource=status&amp;count_sg_1=on&amp;count_active=on&amp;count_enabled=on][Current Status]]
   * ITB release [[http://osggoc.blogspot.com/2011/07/goc-service-update-tuesday-july-12-2011.html][Release notes]]
   * Network maintenance in Indianapolis machine room [[http://osggoc.blogspot.com/2011/07/outage-notification-sunday-july-10.html][Outage notice]] Actual downtime was 1h20m, all within announced window.
   * New format CA distribution is available on software-itb.  
   * Conversations with ITB led to no change in process for ITB cache. The software-itb.grid.iu.edu site is an ITB instance and no standards for uptime will exist, development of the CA package will continue as necessary.
   * Gratia and !ReSS (Represented by !FermiGrid Ops)
      * Gratia Outage last weekend. Network Glitch around 2:30 that caused the issue.  Took some time to diagnose and bring Gratia back up.
   * Glide In Factory
      * Second factory delayed, hardware required specific drivers not in GOC default install. 
      * OSG Installation Ongoing as we speak. 

---+++ Operations This Week
   * Work continues on new format CA distribution as testing results become available. Interruptions on software-itb should be minimal.
   * Production release. Minor changes to ticket exchange and ticket.
   * Some network cables were moved, outages of a few seconds duration may occur on Bloomington service instances.
   * IU engineers will perform power maintenance 14 and 15/Jul Indianapolis machine room, we have been informed this should not interfere with existing power. We have [[http://osggoc.blogspot.com/2011/07/maintenance-notification-july-14-and-15.html][notified]] the community.
   * New VO Package [[https://twiki.grid.iu.edu/bin/view/Operations/PackageV38][Change Log]]
   * New Gratia version coming soon. 

---++ Engage (Mats, John)

   * Accounting issues with glideinWMS will be brought up on blue print meeting in July
   * Finding slots with high memory was made easier with Derek helping out with RSL for HCC resources 


---++ Integration (Suchandra)
   * Working on last pacman release
   * Should be on VTB testing this week with a quick turnaround to ITB testing.
   * Ongoing efforts on documentation continuing

---++ Site Coordination (Marco)
Note that this report lists the currently active resources in OSG.
If a site is down or not reporting it will not be counted.
Therefore there may be fluctuations.
Each line has the current number and variation from last week in parenthesis.
You can find a table with current OSG and VDT versions at http://www.mwt2.org/~marco/myosgldr.php
   * Site update status (from !MyOSG as of today):
      * Most recent production version is OSG 1.2.20
      *      100 (5) OSG 1.2.X resources (       5 are 1.2.20)
      *        2 (0) OSG 1.0.X resources (       0 are 1.0.6)
      *        2 (0) OSG 1.0.0 resources
      *        1 (0) OSG 0.8.0 resources
OSG Summer workshop, Aug 9 and 10 2011
   * https://indico.fnal.gov/conferenceDisplay.py?confId=4531
   * To choose topics: http://www.surveymonkey.com/s/7JRHT9Q

---++ Virtual Organizations Group (Chander)
See [[https://twiki.grid.iu.edu/bin/view/Trash/Trash/Trash/Trash/VirtualOrganizations/VOGroupMeeting20110707][report from Engage and Suragrid]].  The accounting probe for glideinWMS has been deployed by Engage and Derek is verifying the integrity of the resulting reports.

---++ Security (Mine)
   * No major incidents or vulnerabilities at OSG. One incident reported by TeraGrid -- not likely to affect OSG. Another compromise on a set of EGI machines.  No public info yet.   
   * There was a change in DOEGrids CA cert. It has been tested in ITB and made into the production last week. We worked with DOEGrids to make sure they can make this new cert into the IGTF release 1.40. Since there was no problems with the new DOEGrids CA cert, OSG has also switched to using IGTF1.40 in production. 
   * Made release of ITB 1.20 CA (itb,itbnew,igtfold, and igtfnew) cache. This release includes the contents of IGTF v1.40. There were still some hiccups with the GOC process, some of the symlinks were not properly installed on the new cache. All problems have been resolved. OSG will release the cache to production on July26th. 
   * Made changes to the RSV probes and vdt-ca-manage. Tested and released them to VDT on Friday. They should be released to the ITB this week. The changes in the software will make it into the final pacman release of VDT software. These changes in software necessary to switch to SHA-2. 
   * Thanks everyone for finishing their security test and controls. Majority of OSG area leaders have returned their answers. We are working on your answers and creating a summary for the OSG. 
   * Have been pinging Europeans about grading the last incident drill, no success so far.  


---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings
