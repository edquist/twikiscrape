-- Main.DanFraser - 06 Oct 2009
---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings

---++ Action/Significant Items:
   * OSG is now #2 user for E@H, may be #1 when condor jobs included.
   * CMS Physics challenge started on Oct 6. Burt to send messages if any production problems detected as a result of this. (Burt)
   * Atlas conducting a throughput test Oct 5-8. Will identify if any production problems (Armen, Xin)
   * RSV reporting has been corrected for BNL. (Brian)
   * Mats to send email regarding gram tmp cleanup (Mats)
   * Need to invite more sites to host the !NEBioGrid (Abhishek, Dan)
   * Preparations underway for the GOC machine room move on Oct 17 (Rob)

---++ Attendees:
   * Xin, Armen, Britta, Brian, Suchandra, Burt, Marco, Abhishek, Rob Q., Dan 
---++ CMS (Burt)
   * Computing: 100 khour/day, 88% success. CPU/wallclock at 81%.
   * Storage: Tier 1 transferred 1.2 PB last week (peak of 320 TB/day). Tier 2s transferred 315 TB (peak: 85 TB/day). Probes not functional at UERJ, MIT, Florida, Purdue.
   * OSG: now have 5 T2 CEs at OSG 1.2 (Nebraska, UCSD, .5 CIT). Tier 3s at 1.2: UCDavis, FIT, UMD, Vanderbilt, UCR, Notre Dame.
   * Physics challenge: started October 6.   Spike in number of jobs visible: http://home.fnal.gov/~burt/physchal.png
   * RSV: RSV Gratia Probe Delenda Est! (Status of gratia probe?)

---++ Atlas (Armen &amp; Xin)

   * RLast week USATLAS sites on average keep 6~7k running jobs. Big part of them were reprocessing jobs in T1 and T2s. The reprocessing now is over. No problem in US sites. The post-mortem is Oct.14 .

   * Throughput test for all T1s going on now (Oct. 5-8): Monday, Tuesday: every 60 seconds 4 datasets will be produced for a total of 12 files and 3.6 GB. All datasets will be shipped to all T1s. This will produce total of 17300 files/day per T1 corresponding to approx 5 TB/day of data volume per T1. Wednesday, Thursday: same of Monday/Tuesday but file sizes will be a factor 10 bigger. This means every site will get 17300 files/day, corresponding to approx 50TB of space.

   * Another big performance test will be User Analysis Test (UAT), with initial dates Oct.21-23. Several big datasets (100M events each) are in preparation. The exercise will include analysis by many expert users, and then transfer of the results to T3s and other T2s. The exercise must not disrupt the regular user analysis. Twiki with details, including how to run the exercise, is in preparation.

   * job statistics for last week. 
      * Gratia report: USATLAS ran 651K jobs, with CPU/Walltime ratio of 90.3%. 
      * PanDA world-wide production report (real jobs): 
         * completed successfully 582K managed MC production, validation and reprocessing jobs ( 271K of them in US cloud)
         * average 83K jobs per day
         * failed 60K jobs
         * average efficiency is very good:  jobs  - 90.7%,  walltime - 94.3%

   * Site issues
      * BNL availability numbers is still available in the daily RSV VO report, thanks Brian. 



---++ LIGO (Britta)
 * Gratia reports:
      * 4 users utilized 36 sites
      * 68864 jobs total (56689 / 12175 = 82.3% success)
      * 528797.6 wall clock hours total (497693.4 / 31104.2 = 94.1% success)

      * Last week: 4 users utilized 26 sites
      * 25970 jobs total (22090 / 3880 = 85.1% success)
      * 180739.3 wall clock hours total (173315.5 / 7423.8 = 95.9% success)

  * E@H reportsRecent Average Credit (RAC): 
      * Recent Average Credit (RAC): 908,209.63508, Last Week: 410,627.43632
      * E@H rank based on RAC: 2 (+2)
      * E@H rank based on accumulated Credits: 13 (+4)

  * Details:
      * Robert is ramping up
      * Running into space issues in $DATA at some sites (RCAC, Cornell)
      * Planning to extend to Fermilab sites in the future
      * Account name change!
         * &quot;Caltech Open Science Grid Team&quot;

---++ Integration (Suchandra)
   * Ongoing efforts underway to realign documentation and to improve it
   * Ongoing vtb testing of rsv gratia probes and other updates
      * Still working a few rsv gratia probe bugs out


---++ Site Coordination (Marco)
Note that this report lists the currently active resources in OSG.
If a site is down or not reporting it will not be counted.
Therefore there may be fluctuations.
   * Site update status (from !MyOSG as of today):
      * Most recent production version is OSG 1.2.3
      * 27 OSG 1.2.X resources (7 are 1.2.3)
      * 1 OSG 1.1.X (OSG 1.1.28 UColorado_ITB reporting to OSG, not ITB)
      * 33 OSG 1.0.X resources (19 are 1.0.4)                                                                                                                                                                  
      * 27 OSG 1.0.0
      * 2 OSG 0.8.0 (OU_OCHEP_SWT2, UIC_PHYSICS)
   * Site administrators meeting Thursday 10/1
      * minutes: https://twiki.grid.iu.edu/bin/view/Trash/Trash/Trash/Trash/SiteCoordination/SitesCoord091001
      * next one 10/22

---++ Engagement (Mats)

15 users utilized 34 sites

8558 jobs total (6828 / 1730 = 79.8% success)

30366.6 wall clock hours total (27704.1 / 2662.5 = 91.2% success)

No production issues. I still have to write the email about gram tmp clean ups (it is on my todo list..). I will not be on today&#39;s call as I&#39;m traveling.


---++ Metrics (Brian)
   * Bestman/Xrootd -&gt; SRMv2 renaming appears to have gone well; next on our list is the Gratia naming consistency
   * Tried to &quot;fix&quot; the various Gratia complaints Mats et al had coming from Omaha&#39;s Gratia setup.  This did not go well; will have to roll back and try again next week.
      * Did not go well because of incorrect Gratia configuration overlooked by me.

---++ Virtual Organizations Group (Abhishek)


---+++ VOs with High Activity

   * D0 -- MC Production average at 75,000 hours/day. Equivalent 10 Million Events/week. Job efficiency 55%, Wall efficiency 80%,  CPU/wall 65%. No major production issues reported.
   
   * Fermi-VO -- (i) Work ongoing to keep the parentVO/subVO classification uniform across OIM and Gratia. Steve and Keith&#39;s view is that both parentVO and subVOs to be mentioned in reports, case by case.  (ii) Fermilab VO is implementing GIP configuration changes to advertise subcluster parameters e.g., memory, OS versions. Jim Weichel is in contact; to include this in OSG Documentation. [Currently, some sites do not advertise these fine-grained subcluster parameters correctly.]
   
   * DOSAR -- Working as OSG liaison to bring up !GridUNESP (Sao Paolo), a multi-disciplinary state-level effort in Brazil. More updates expected in coming months.
   
---+++ VOs with Limited Activity
  
   * SBGrid/NEBioGrid -- A new NMR application is being pursued. Plan is to sustain increased wall hour rate (100-250 hours/day). !NEBioGrid VO is currently supported by only 5 remote sites, as reported by !ReSS: SBGrid-Harvard-Exp, SBGrid-Harvard-East, WQCG-Harvard-OSG, RENCI-Engagement, CIT_CMS_T2. Only 2/5 are remote sites. !NEBioGrid team has asked VO Group to request OSG Sites coordination group for support at more sites. 
   
   * NYSGrid -- Work starting on portal development; based on HUBzero. 
   
---+++ General

   * Accuracy of new accounting alert report (OIM/Gratia comparison) -- Some entries are due to site mappings of local subgroups/users, being interpreted as unregistered VOs. Need to find a fix.
    
   * VOs operational plans toward Year4 -- To be the main focus this month.

---++ Grid Operations Center (Rob Q.)


---+++ Operations Last Week 
   * !BestmanXrootd will be removed as a service on OIM on Wednesday. GOC has added [[http://tinyurl.com/nde4sd][SRMv2 service mapping for all resources that are currently mapped to the BestmadXrootd]] service. See [[https://ticket.grid.iu.edu/goc/viewer?id=7457][related ticket]]
   * [[MyOSG18][MyOSG 1.8 and OIM 2.8]] were released on Friday. No users were effected, except for those expecting bugfixes, which they received with the upgrade.
   * GOC Services - Status Last Week: [[http://tinyurl.com/y8wtdq3][BDII]]

---+++ Operations This Week
   * GOC will add DNS round-robin for the following services: MyOSG, Ticket, Software. [[http://osggoc.blogspot.com/2009/10/upcoming-goc-maintenance.html][RSS feed entry about maintenances]]
      * GOC will move DNS entry to point the following services to Indianapolis based instances: OIM, Twiki -- expect short outages. 
      * Expect notification from GOC with full details
   * Ticket 1.7 will be released on Tuesday - main change [[https://ticket.grid.iu.edu/goc/viewer?id=7498][related to security notifications]]  [[http://osggoc.blogspot.com/2009/10/upcoming-goc-maintenance.html][RSS feed entry about maintenances]]


---+++ Future Events
   * Machine Room Move in Bloomington October 17 2009 - Some non-critical GOC Services -- twiki, www -- in Bloomington are expected to be down. 
      * GOC has put (or will put) in place instances of critical services BDII, MyOSG, GOCTicket, Software cache -- and non-critical services OIM  -- on IUPUI based servers. GOC will attempt to move OSG twiki to IUPUI. 
