-- Main.DanFraser - 06 Nov 2012
---++ Action/Significant Items:
   * 

---++ Attendees:
   * Armen, Marco, Mine, Rob, Tony, Xin, Brian
 
---++ CMS (Tony)
   * Job statistics for last week
      * 21,985 jobs/day

   * Transfer statisics for last week
      * ~380 TB/day

   * http://jira.opensciencegrid.org/browse/SOFTWARE-689
---++ Atlas (Armen &amp; Xin)

   * General production status
      * LHC during the week had some machine development period and some trouble returning to its best ops mode due to various issues with components. Less than half of the usual delivered luminosity. Current total collected luminosity for ATLAS is ~20.8 fb-1.
      * US ATLAS production during the last week was very stable, at the average level around 24K running jobs. Reprocessing of the main data (bulk reprocessing) is successfully continuing, must be fully done by the end of next week.
   * Job statistics for last week.      
      * Gratia report: 1.2M pilot jobs run on USATLAS sites, with CPU/walltime ratio of 91%
      * Real Jobs processed by US sites for last week, reported from PanDA monitor 
         * 1.1 M
   * Data Transfer statistics for last week
      * Data transfer rate was around 400TB/day at BNL T1. 
   * Issues

---++ Grid Operations Center (Rob Q.)

---+++ Operations Last Week
   * [[http://tinyurl.com/9oh5bzh][GOC Services Availability/Reliability]]
   * [[http://myosg.grid.iu.edu/miscstatus/index?datasource=status&amp;count_sg_1=on&amp;count_active=on&amp;count_enabled=on][Current Status]]
   * No release, Thanksgiving holiday.
   * Reduced false alarms on CERN BDII, one instance there was configured for excessive logging, I/O bottlenecks caused timeouts.
   * RSV false positives on GOC services, believed fixed, may have returned.
   *  WMS Glide In Factory
      * Testing glideinWMS 2_6_3_rc1
      * GOC Factory disk partition started filling rapidly since Friday. It has stabilized to 85%.
         * Seems to just be increased glidein logs due to high activity.
         * We will investigate more and tweak the log cleanup / rotation as necessary.

---+++ Operations This Week
   * No release, Thanksgiving holiday.
   * Next release cycle: ITB December 4th, Production December 11th
   * Initial installation of OASIS, storage array in progress.
      * Wednesday Target for Systems Online
      * Wednesday Meeting with NoVA as first Beta User
   * Noticed a CERN outage took down ATLAS Production 
      * &quot;AFS problem triggered the whole atlas.web.cern.ch web site to be unavailable for hours, it was fixed this morning (INC:198000). Unavailability of TiersOfAtlasCache web copy affected ATLAS production. Possible ways to avoid it in the future are under discussion.&quot;
      * Can OSG Production/Operations Help?


---++ Campus Infrastructures / HTPC (Dan, Brooklin)


---++ Software (Tim)


---++ Integration (Suchandra)


---++ Site Coordination (Marco)
Note that this report lists the currently active resources in OSG.
If a site is down or not reporting it will not be counted.
Therefore there may be fluctuations.
Each line has the current number and variation from last week in parenthesis.
You can find a table with current OSG and VDT versions at http://www.mwt2.org/~marco/myosgldr.php
   * Site update status (from !MyOSG as of today):
      * Most recent production version is OSG 3.1.11 / 1.2.31
      *       55 (-2) OSG 3.x (      15 are 3.1.11)
      *       48 (-1) OSG 1.2.X resources (       1 are 1.2.31)
      *        0 (-1) OSG 1.0.X resources (       0 are 1.0.6)
      *        0 (0) OSG 1.0.0 resources


---++ User Support (Chander, Mats)


---++ Security (Mine)
   * Vulnerabilities/Incidents
      * Condor vulnerability is being watched. Mostly the same number of sites since last week&#39;s report are still vulnerable. Started opening tickets with sites. 
   * Operations
      * Made a change to the dev repo last week, testing SHA-2 certs. Received SHA-2 signed certs form ESNet CA and DOEgrids ca. Found out that when server and client have different versions of the certs, gsi breaks. The root cause of the problem is changes to the root CA. We will ask IGTF to stop any CA from transitioning their root CAs to SHA-2. Otherwise, our middleware will break. Transitioning intermediate CAs is most likely to be OK. we will do one more test. We asked ESnet team to revert ESNET CA back to sha-1 and keep intermediate CAs in SHA-2. They will do this by Dec 15. We will test this again after Dec 15. We will roll back the release form dev repo. It was never released to ITB. We will shortly make another  release to ITB. This release will contain the new IGTF release. It will have no changes related to SHA-2 transition. 
      * CIlogon Basic CA. This is released to GOC ITB services. Security team will test them with Basic ca end users certs. If succeeds, it will move onto production. 
          


---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings
