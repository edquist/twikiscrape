-- Main.DanFraser - 06 Nov 2012
---++ Action/Significant Items:
   * 

---++ Attendees:
   * (to be updated after the meeting) Xin, Armen, Brian, Tim, Suchandra, Tony, Marco, Rob Q., Scott T., Mine, Chander, Dan
 
---++ CMS (Tony)
   * Job statistics for last week
      * 26,199 jobs/day

   * Transfer statisics for last week
      * ~890 TB/day

   * Still open: http://jira.opensciencegrid.org/browse/SOFTWARE-689
---++ Atlas (Armen &amp; Xin)

   * General production status
      * LHC had very stable and productive operation during the last week. Current total collected luminosity for ATLAS is ~20.3 fb-1.
      * US ATLAS production during the last week was very stable, at the average level around 22-24K running jobs. Reprocessing of the main data (bulk reprocessing) is successfully continuing.
   * Job statistics for last week.      
      * Gratia report: 1.2M pilot jobs run on USATLAS sites, with CPU/walltime ratio of 90%
      * Real Jobs processed by US sites for last week, reported from PanDA monitor 
         * 1.5 M
   * Data Transfer statistics for last week
      * Data transfer rate was around 400~700TB/day at BNL T1. 
   * Issues
      
---++ Grid Operations Center (Scott T.)
---+++ Operations Last Week
   * [[http://tinyurl.com/9oh5bzh][GOC Services Availability/Reliability]]
   * [[http://myosg.grid.iu.edu/miscstatus/index?datasource=status&amp;count_sg_1=on&amp;count_active=on&amp;count_enabled=on][Current Status]]
   * Production release, [[http://osggoc.blogspot.com/2012/11/goc-service-update-tuesday-november.html][Release note]] is available. Reboots were required. Usual coordination methods were used.
      * Problem with false RSV alarms apparently fixed by this release. Mechanism not known.
      * Last update cycle this month.
   * Upgraded GOC Factory to glideinWMS 2.6.2 and Condor-G 7.8.6
   * Completed SDSC Factory install.  Envited a few frontend admins to try it out before making officially available as a Production service.
   * Began testing glideinWMS 2_6_3_rc1 on ITB Factory which has the popen update that should fix the file descriptor scalability issue.

---+++ Operations This Week
   * No release scheduled, Thanksgiving holiday.
   * Next release cycle: weeks 1,2 December.
   * Plan to continue testing glideinWMS 2_6_3_rc1


---++ Campus Infrastructures / HTPC (Dan, Brooklin)


---++ Software (Tim)
   * Defining next release (&lt;= 18 December 2012)
      * New !BeStMan 2 + !jGlobus with SHA-2 support
      * Upgrade glideinWMS
      * Upgrade !XRootD (new 3.3 or fixed 3.2)
      * Upgrade voms-admin-client
      * Fix max-walltime bug in HTCondor jobmanager
      * Fix small bugs in osg-configure
   * Possible small issue with EPEL Release RPM
      * They are moving from epel-release-6-7 to -6.8
      * They will not predict time of change, but it will break new installs
      * We can document change and both URLs (current + future)
      * We will catch the change in our automated testing within 24 hours


---++ Integration (Suchandra)


---++ Site Coordination (Marco)
Note that this report lists the currently active resources in OSG.
If a site is down or not reporting it will not be counted.
Therefore there may be fluctuations.
Each line has the current number and variation from last week in parenthesis.
You can find a table with current OSG and VDT versions at http://www.mwt2.org/~marco/myosgldr.php
   * Site update status (from !MyOSG as of today):
      * Most recent production version is OSG 3.1.11 / 1.2.31
      *       57 (1) OSG 3.x (      13 are 3.1.11)
      *       49 (4) OSG 1.2.X resources (       0 are 1.2.31)
      *        1 (0) OSG 1.0.X resources (       0 are 1.0.6)
      *        0 (0) OSG 1.0.0 resources


---++ User Support (Chander, Mats)


---++ Security (Mine)
   * Emergencies/Vulnerabilities
      * Dcache vulnerability was reported last week. High criticality. Security team evaluated and found out that it does not affect the libraries used by OSG. It affects EMI. So, no need to take action.
      * Condor vulnerabilities. Ran tests over the sites and generated a report of vulnerable sites. 
         * 15 gatekeepers (clusters) are patched and not vulnerable. 
         * 18 gatekeepers (clusters) are vulnerable to  remote job submission and control exploit. 
         * 12 gatekeepers (clusters) are vulnerable to the fake dns exploit. 
         * Could not run our tests on 10 gatekeepers (clusters). 
   * Operations
      * UK had a fire in the data center. All UK CAs are down. We are making an announcement.  
      * Put the new CA bundle with SHA-2 certs into ITB. The ESNet root CA and the DOEgrids intermediate CA both have SHA-2 signed certs for themselves. The CRL file is also signed with SHA-2. This is the most thorough test scneario for SHA-2 acceptance. Brian and Doug already found an error case. Please let us know if you find other components breaking. 

---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings
