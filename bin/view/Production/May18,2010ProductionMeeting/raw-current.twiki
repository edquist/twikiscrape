-- Main.DanFraser - 30 Apr 2010
---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings

---++ Action/Significant Items:
   * A jump in the number of CMS error rates (by hour) as noted last week were investigated by Brian and found to be internal to CMS. This reflects a change in the job mix as data is increasing from the experiment and users are running more grid jobs. Errors are roughly 50% stage out errors, 25% configuration errors, 13% output errors, and 12% other. Atlas error rates are not as visible since everything is bundled in pilots that usually complete complete successfully although jobs sometimes fail.
   *  The CEMON collector outage last week was attributed to a known problem with the NCSD after it has been running for long periods of time O(months) . The IS2 BDII was brought back online on Monday with a couple of patches, one to the BDII and one to the kernel. Plan is to switch NCSD to automatically restart itself every 24 hours at the next change cycle. (Rob)
   * Engage noted that there is a problem with enabling users on OSG who need large (~600GB) databases co-located. (John) This is not a short term issue. 
   * We now have a centralized collection of data from different VOs that characterize many of the problems they encounter when attempting to get jobs running across the OSG. Next step is to try and understand the issues and determine which can be tackled from a systematic perspective. https://twiki.grid.iu.edu/bin/view/Production/ProblemsEncounteredByVOsDuringJobSubmission (Abhishek, Dan, thanks to Robert E, Jim, and others as well for contributions).

---++ Attendees:
   * John, Mats, Xin, Armen, Britta, Rob E., Brian, Suchandra, Tony, Marco, Abhishek, Rob Q., Mine, Dan
 
---++ CMS (Tony for Burt)
   * Another excellent weekend of LHC running - again doubled integrated luminosity
   * Moved from 4x4 bunches to 6x6 bunches
      * Only 3x3 bunches were previously colliding
   * Job statistics for last week
      * 45 khours/day
      * 168759 Jobs/day
      * 93% success
   * Transfer statisics for last week
      * ~50 TB/day

---++ Atlas (Armen &amp; Xin)

   * General production status
      * LHC has a significant luminosity gain around the weekend, more than doubled. Collected luminosity now is about 9 nb-1 for ATLAS. Commissioning will continue over the weekend, and new high lumi run over the weekend. Last week first half was preparation for second round of the reprocessing, which started Thursday, and successfully finished over the weekend.
   * Job statistics for last week. 
      * Gratia report: USATLAS ran 2.5M jobs, with CPU/Walltime ratio of 74%. 
      * Panda world-wide production report (real jobs): 
         * completed successfully 679k managed MC production, validation and reprocessing jobs 
         * average 97K jobs per day
         * failed 120K jobs
         * average efficiency:  jobs  - 85%,  walltime - 96%
   * Data Transfer statistics for last week
      * BNL T1 data transfer rate was 200~400TB/day last week. 
   * Issues
      * Opportunistic SE usage for D0 : no update

---++ LIGO (Britta, Rob E.)
---+++ Gratia Reports
   * This week&#39;s total usage: 5 users utilized 38 sites
      * 59792 jobs total (23165 / 36627 = 38.7% success)
      * 590568.1 wall clock hours total (460984.9 / 129583.3 = 78.1% success)
   * Last week&#39;s total usage: 5 users utilized 35 sites
      * 62680 jobs total (26174 / 36506 = 41.8% success);
      * 895682.0 wall clock hours total (672090.6 / 223591.4 = 75.0% success);

---+++ LIGO / E@H
   * Recent Average Credit (RAC):1,169,942.99571,  Last Week: 1,288,948.61025
   * E@H rank based on RAC: 2 (+-0)
   * E@H rank based on accumulated Credits: 4 (+-0) 

---+++LIGO/E@OSG
   * Troubleshooting s6 code on ITB cluster
   * RLS server move from ISI to Caltech - in progress
---++ OSG Operations (Rob Q.)


---+++ Operations Last Week 
      * Reliability/Availability Last Week of [[http://tinyurl.com/36v63tq][GOC Services]]
      * Reliability/Availability Last Week of [[http://tinyurl.com/33qdatk][Security Services]]
   * BDII Issues 
      * [[https://ticket.grid.iu.edu/goc/viewer?id=8530][Ticket]]
      * [[http://osggoc.blogspot.com/2010/05/scheduled-maintenance-is2gridiuedu-goc.html][Maintenance Announcement]]
   * !TWiki Issues on Friday
      * [[http://osggoc.blogspot.com/2010/05/osg-twiki-brief-outage.html][Notification One]]
      * [[http://osggoc.blogspot.com/2010/05/osg-twiki-brief-outage.html][Notification Two]]    
      * The TWiki experienced problems due to heavy load queries from the documentation team. We have asked them to suspend these queries while we investigate.
   * Meeting with FNAL Remedy, May 13th
      * FNAL has given the GOC a script for testing. Work will continue...

---+++ Operations This Week

   * BDII Issues 
      * [[https://ticket.grid.iu.edu/goc/viewer?id=8530][Ticket]]
      * [[http://osggoc.blogspot.com/2010/05/scheduled-maintenance-is2gridiuedu-goc.html][Maintenance Announcement]]
      * NSCD Bug Fix in place and is2 online (though not in RR) all weekend without any issues. 
         * We&#39;d like to start running NSCD in &quot;Paranoid&quot; mode to prevent other reported issues in the near future. 
      * is2.grid.iu.edu will be returned to production at 2pm EDT today. 
         * There is now monitoring that to warn us if more than 10% of the resources drop out of either BDII. 
   * !TWiki 
      * Set up mirror non-production instance to allow docs group to do testing. 

---++ Engage (Mats, John, Chris)

8 users utilized 32 sites;

42166 jobs total (37509 / 4657 = 89.0% success);

189916.5 wall clock hours total (166808.6 / 23107.9 = 87.8% success);

No production issues.


---++ Integration (Suchandra)
   * Working on documentation efforts with Doc Team
   * Working on further ITB Robot enhancements / bringing up myproxy server

---++ Site Coordination (Marco)
Note that this report lists the currently active resources in OSG.
If a site is down or not reporting it will not be counted.
Therefore there may be fluctuations.
Each line has the current number and variation from last week in parenthesis.
You can find a table with current OSG and VDT versions at http://www.mwt2.org/~marco/myosgldr.php
   * Site update status (from !MyOSG as of today):
      * Most recent production version is OSG 1.2.9
      *       77 (-3) OSG 1.2.X resources (       9 are 1.2.9)
      *        6 (0) OSG 1.0.X resources (       1 are 1.0.6)
      *        7 (0) OSG 1.0.0 resources
      *        1 (0) OSG 0.8.0 resources
Minutes from last week site coordination meeting are available at SiteCoordination.SitesCoord100513 . Few key items:
   * special topic was Job workflows in OSG and presentations are available
   * OSG operation is providing special support to sites interested in deploying a local Gratia collector
      * some information will be dropped by the OSG collector (individual file transfers)
      * sites can query easily their data
      * central reporting is more efficient

---++ Metrics (Brian)


---++ Virtual Organizations Group (Abhishek)

   * D0 
      * Good rate last week: 10.2 Million Events/week; 121,000 wall-hours/day at 87% efficiency.
      * Ongoing site issues: 
         * Failures at GPN cluster: !GridFTP processes being stuck. Investigating on Fermilab site; will open ticket if necessary.
         * Jobs dispatched to Glue-X site failed (couldn&#39;t get files). Abhishek to follow up with Richard Jones.
         * Joel contacted Cornell for SE access; local admin will get back after consulting with site management staff.
         * UTA SE: Discussions with Robert Illingworth to run tests again.

   * SBGrid
      * Evaluating !GlideinWMS; encountered problems with Condor and NAT configuration. In discussion with Condor team.
      
   * VO Job Problems compilation
      * https://twiki.grid.iu.edu/bin/view/Trash/Trash/Trash/Trash/VirtualOrganizations/DirectFeedbackOnProductionProblemsOrBottlenecks
         * Talking to select VOs to collect direct feedback on production problems. Data coming in.
      * https://twiki.grid.iu.edu/bin/view/Production/ProblemsEncounteredByVOsDuringJobSubmission
         * Added extracts from VO inputs.
         * New subsections on problems with site selection, persistent data management, accounting. 

---++ Security (Mine)
