-- Main.DanFraser - 08 Jun 2009
---++ Attendees (to be updated after meeting):
   * Xin, Britta, Mats, Brian, Suchandra, Burt, Marco, Abhishek, Arvind, Chander, Dan
---++ Action Items
   * An issue was raised about moving to a centralized RSV probe
      * Worked with GOC; changes have been rolled back; discussions continuing
   * Burt to comment on GIP error report (sent by Abhishek)
   * Need to track RSV CA Probe updates submitted by Security team, identify when these will be available for nanoHub (Dan)
---++ CMS (Burt)
   * CMS ran about 208 khour/day last week with 92% success.   CPU/Wallclock is 72%.  
   * STEP09 is running.   We are fulfilling our commitments and have found scaling issues with some of the MSS (being worked on).  Tape rates overall are reasonable; processing with glideins are running well with over 13k jobs running from a single production intsance.  Analysis is ramping up.
   * We need to have a discussion on how availability metrics are generated -- we were caught by surprise with the announcement that GOC is recentralizing testing.

---++ Atlas (Armen &amp; Xin)

   * job statistics for last week. 
      * Gratia report: USATLAS ran 0.8M jobs, with CPU/Walltime ratio of 79.4%
      * PanDA world-wide production report (real jobs):
         * completed successfully 659,779 managed MC production, validation and reprocessing jobs
         * average  ~94,254 jobs per day
         * failed  112,026  jobs
         * average efficiency: 85.5% for jobs and 91.3% for walltime

   * STEP09 status
      * Step09 started at the beginning of the last week. 
      * So far US cloud was quite stable. No problems with staging, writing, data transfer. Production was always at the level of 6-7k running jobs.

   * Condor-G enhancement
      * condor team delivered new version of condor that implements multiple gridmanager processes, one for each remote CE. We are putting it into production and in the process of testing it  

---++ LIGO (Britta)
Current week&#39;s total usage: 2 users utilized 12 sites; &lt;br&gt;
                             6946 jobs total (6297 / 649 = 90.7% success); &lt;br&gt;
                             52057.6 wall clock hours total (50381.4 / 1676.2 = 96.8% success);&lt;br&gt;
Previous week&#39;s total usage: 4 users utilized 13 sites;&lt;br&gt;
                             6808 jobs total (6074 / 734 = 89.2% success); &lt;br&gt;
                             51427.9 wall clock hours total (48661.8 / 2766.2 = 94.6% success);&lt;br&gt;


Recent Average Credit (RAC) :160,069.4881&lt;br&gt;
E@H rank based on RAC: 8&lt;br&gt;
E@H rank based on accumulated Credits: 29&lt;br&gt;

 * problem on Harvard was resolved by the system administrator&lt;br&gt;

 * Robert is testing new code

 * Robert meets with Condor team June 29

---++ Integration (Suchandra)
   * ITB testing now underway
   * Switched to footprints ticketing system from rt
   * Working on subversion and repository changes to merge with GOC hosted repository and to unify vtb, itb, and production cache management


---++ Site Coordination (Marco)
Site Administrators meeting, August 6,7
   * https://twiki.grid.iu.edu/bin/view/Trash/Trash/Trash/Trash/SiteCoordination/SiteAdminsWorkshopAug2009
   * http://indico.fnal.gov/conferenceDisplay.py?confId=2497
   * http://www.surveymonkey.com/s.aspx?sm=mt3Lp1dxF3BQNoHHralA0w_3d_3d

Survey about OSG 1.0.1 update closed today. Summary:
   * 14 replies, 24 sites
   * 6 updated, 8 did not (and no plans)
   * of the not updated 2 sites have OSG 0.8, the remaining OSG 1.0
   * Installation from &quot;Very Easy&quot; (without instruction) to &quot;Difficult&quot; (needed support to complete). In order of increasing difficulty: CE, SE, GUMS
   * detailed results and comments: http://twiki.mwt2.org/bin/view/Main/SurveyUpdateOSG101

---++ Engagement (Mats)

&lt;pre&gt;
2009-06-01 - 2009-06-07
7 users utilized 30 sites;
22964 jobs total (21973 / 991 = 95.7% success);
30896.6 wall clock hours total (29998.0 / 898.5 = 97.1% success);
&lt;/pre&gt;

One production issue: we are considering moving the Engagement
VOMRS/VOMS service because we are not getting good service from RENCI.
We are still thinking about if the move is a good idea and if so, where
to move the service.


---++ Virtual Organizations Group (Abhishek)


   * D0 
      * D0 !MonteCarlo production is at an average consumption of 80,000 wall hours per day. Usual efficiencies.
      * D0 Event production is at 7.8 million events per week. 
              
   * nanoHUB 
      * Taskforce now closed, with key all goals successfully achieved. 
      * With current 6 application jobtypes, nanoHUB&#39;s production across OSG has ramped up manifold in May&#39;09. 
         * Sustained at 600-800 wall hours per day. 
         * OSG resource failure rate is less than 1%. 
         * Link failure rate (lack of OSG resource availability) is nearly 12%. 
      * Influx of nanoHUB end-user jobs is expected in near future.
      * Wider scoped items: [carryover items in last week&#39;s minutes]
      
   * Geant4
      * Work ongoing with Geant4 and Engagement.
      * Goal is to enable Geant4&#39;s regression testing cycles on OSG.
      * Now able to run on OSG. 
         * 60-100 jobs per day. 
         * Peak usage 1300 wall hours per day. Average usage 600 wall hours per day.
         * Using the same workflow model as LCG. 
         * Ganga/Diana software stack.
      * Work in progress. More updates next week.
   
   * ITB 1.1 validation by VOs
      * Schedule in formation - mid-June to mid-July.
      * Expecting 10-12 active VOs to participate - including ATLAS, CMS, LIGO.
            
