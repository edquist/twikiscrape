---+ A year’s research in a matter of hours: OSG accelerates Tyler Churchill’s cochlear implant modeling
September 14, 2012

     &lt;img src=&quot;%ATTACHURLPATH%/cochlear_implant.jpg&quot; alt=&quot;cochlear_implant.jpg&quot;width=&#39;200&#39; height=&#39;155&#39; style=&quot;float:right; margin: 10px 10px 10px 0;&quot; /&gt;  

     
Cochlear implants (CIs) are surgically implanted electronic devices that provide a sense of sound to a person who is profoundly deaf or severely hard of hearing. CIs deliver electric signals from an external microphone and processor to the auditory nerves, and they are designed to replace the function of hair cells in the inner ear that act as sound receptors. To further contributions to the treatment of hearing loss, CI research is determining which parameters of sound are most important to neural correlation or, in other words, how our brains bring together multiple signals when processing sound. 

 
     &lt;img src=&quot;%ATTACHURLPATH%/tyler.jpg&quot; alt=&quot;tyler.jpg&quot; width=&#39;130&#39; height=&#39;154&#39; style=&quot;float:left ; margin: 10px 10px 10px 0;&quot; /&gt;  
  

Through research at the University of Wisconsin at Madison’s Waisman Center, Tyler Churchill investigates ways to improve hearing with cochlear implants. After graduating from the US Naval Academy and serving active duty, Churchill returned to Wisconsin to pursue an advanced degree in physics at UW Madison, where he specializes in psychoacoustics (&quot;What did you hear?&quot;). In particular, he is exploring what is different, at the physiological level, between normal hearing and electric hearing. 

“We can neither adjust the physical parameters of the implanted hardware nor record nerve data from human subjects, so our lab does modeling and psychoacoustic experiments with normal hearing listeners and CI-implanted listeners,” says Churchill. 
 
     &lt;img src=&quot;%ATTACHURLPATH%/cochlear_implant2.jpg&quot; alt=&quot;cochlear_implant2.jpg&quot; width=&#39;200&#39; height=&#39;155&#39; style=&quot;float:right; margin: 10px 10px 10px 0;&quot; /&gt;  
 
This is where the Open Science Grid comes in: Churchill uses the OSG to generate thousands of test and control stimuli for evaluating strategies to improve signal processing. While conventional strategies ignore acoustic &quot;temporal fine structure&quot; (TFS) – which, for normal hearing, is key to pitch discrimination, localization of sounds, and understanding speech in noisy situations – Churchill’s experiments retain TFS in the timing of implants&#39; electric pulses, and take advantage of the accelerated analysis timeline provided by the OSG&#39;s distributed computing resources. 

The ear has 30,000 hair cell groups, or channels, and each has a different spontaneous firing rate. As sound travels through the cochlea in the inner ear, it also passes from higher to lower frequencies, with each channel picking up one frequency. Today’s CIs have an array of up to 22 electrodes spread throughout the cochlea, but signals reach beyond the regions of these electrodes – meaning those with CI devices experience only eight perceptible channels. 

Churchill’s modeling focuses on one nerve fiber at a time, and uses time-intensive Monte Carlo simulations for repeated random sampling. Thus far, he has been able to do over 5,000 simulations, far more than he would have been able to do without the OSG (one second of auditory stimulus takes a week to process on an office computer). These simulations comprise 50 words, which would take a year to process on his PC versus a couple of hours on the OSG. The other big advantage of the OSG is that it can process multiple small jobs in a short amount of time. All told, Churchill says he couldn’t do this research without the speed and efficiency that the OSG and distributed high throughput computing (DHTC) provides. 

“This is opening up new avenues,” he says. “Simulating biological phenomena requires huge amounts of computation. Our research is to improve processing. We can&#39;t do much about sound resolution given hardware limitations, but we can improve the integrated software. OSG and DHTC are helping us rapidly produce results that directly benefit CI wearers.” 

With the assistance of UW Madison’s [[http://chtc.cs.wisc.edu/][Center for High Throughput Computing]]
(CHTC), Churchill has been able to investigate phenomena that depend on thousands of variables, simulations, and calculations. He writes all of the modeling code, and CHTC staff help ensure his code works on the OSG – from his point of view, the process is as simple as logging onto the CHTC submit node and letting the scripts do the rest. His advice for other researchers looking into using the OSG: Make sure the problem is formulated for a large number of short jobs. Long jobs might run on machines used for something else and be interrupted, whereas short jobs have a better chance of finishing and returning results quickly. 

This approach has been very successful for the Waisman Center, and Churchill notes that they will continue using the OSG to adjust parameters in CI signal processing algorithms. They also plan to take advantage of the OSG&#39;s high throughput computing for yet another application: modeling the physiological mechanisms of normal hearing. Ultimately, their goal is to improve understanding of the benefits of bilateral CIs. 

“People who have two cochlear implants do much better,” notes Churchill. “Insurance will usually cover one, but there are not a lot of bilateral CIs out there (80-90% have unilateral implantation). We need to find parameters that influence that decision – and figuring out how to deliver more of the benefits of two normal hearing ears is key to that.” 


_Images courtesy of the Waisman Center’s Binaural Hearing &amp; Speech Lab_ &lt;br /&gt;


~ [[mailto:gmoore@indiana.edu][Greg Moore]]  and [[mailto:sjengel@indiana.edu][Sarah Engel ]]





-- Main.KimberlyMyles - 12 Sep 2012
 


