---+!! *OSG Newsletter, October 2012* 

*IN THIS ISSUE*

%TOC%

---+++_*Remember to register for the CIC Workshop [[https://indico.fnal.gov/conferenceDisplay.py?confId=5927][here]]!*_

----+++ *Research Highlight:* 

_State-of-the-art protein comparisons: Andreas Prli&amp;#263;’s client/server model for the OSG_

 &lt;img src=&quot;%ATTACHURLPATH%/prlic_protein_comparison1.jpg&quot; alt=&quot;prlic_protein_comparison1.jpg&quot; width=&#39;150&#39; height=&#39;123&#39; align=&quot;left ; margin: 10px 10px 15px 0;&quot; /&gt;


By performing large calculations on the OSG, Andreas Prli&amp;#263;, senior scientist at the [[http://home.rcsb.org/][Research Collaboratory for Structural Bioinformatics]] (RCSB) at the University of California, San Diego is able to create algorithms to study nontrivial relationships between proteins, relationships that have been preserved through evolution. Understanding how proteins are related is important to inferring functional and evolutionary relationships between protein families – and, as a result, to drug discovery, biodefense, and genomic research [[https://www.opensciencegrid.org/bin/view/Management/ResearchHighlight32][Read more]]....

_~ [[mailto:sjengel@indiana.edu][Sarah Engel ]]_
 



----+++ *Featured Site: Duke University*

 &lt;img src=&quot;%ATTACHURLPATH%/Duke-for-OSG.jpg&quot; alt=&quot;Duke-for-OSG.jpg&quot; width=&#39;150&#39; height=&#39;113&#39; align=&quot;left ; margin: 10px 10px 15px 0;&quot; /&gt;
 
Site name: !DukeTier3

Location: Durham, NC

Owner: Duke University ATLAS High Energy Physics group

Computing Resources: 168 cores with 118 TB useable storage

Used by: Various members of the ATLAS collaboration
 
What is the best part of collaborating with and contributing to OSG?
The technical staff is very helpful and has a collaborative focus. When we were developing the configuration and site design for the US ATLAS Tier 3 sites , we worked extensively with members of OSG. We traveled to Madison on two separate occasions for two-day working meetings. These trips were extremely helpful and provided the valuable information needed to finalize the design of the majority of the US ATLAS Tier 3 sites.  These sites have been very effective in the physics data analysis of data collected at the LHC.
 
What is unusual about your site?
Our site is a storage-only OSG site, configured according to the US ATLAS Tier 3 guidelines.  We run only the minimal services needed by the local users for their physics analysis. We add services that we find to be transformative and can reduce the required labor to maintain the site. We act as an early adopter and tester for technologies needed in the US ATLAS Tier 3 sites. In our early adopter/beta tester role, we used the !XrootD File System (!XrootdFS), CERN Virtual Machine File System (CVMFS) and have been testing and using the ATLAS Grid File Transfer Protocol (!GridFTP)- only data subscription.
 
What projects are you working on at your site?
We are a member of the !XrootD collaboration.  We participate in ATLAS storage federation work, US ATLAS Tier 3 support, ATLAS CVMFS support and advance development for US ATLAS Tier 3 sites.
 
If you could make one improvement to your site, what would it be?
If we could do more caching of the data needed for analysis so that end users would not have to worry about how to get their data- for example, if end users could start their analysis jobs and the data could be automatically staged to our site in a caching manner.  Data management is the most labor intensive operation that we have at Duke.

_~ [[mailto:benjamin@phy.duke.edu][Douglas Benjamin]]_

----+++ *OSG at the EGI Technical Forum*

 &lt;img src=&quot;%ATTACHURLPATH%/Rob-youtube.PNG&quot; alt=&quot;Rob-youtube.PNG&quot;width=&#39;150&#39; height=&#39;111&#39; align=&quot;left ; margin: 10px 10px 15px 0;&quot; /&gt;


Rob Quick, Bill Barnett and Keith Chadwick attended the recent  [[http://tf2012.egi.eu/][European Grid Initiative Technical Forum]]  in September. Talks and topics of discussion included the current status of interoperation of operations - ticketing, information, topology, accounting, and monitoring – tools, now in a mature state. Keith gave a presentation on the Fermilab private cloud, which is used by the OSG Software group for development and testing as well as being a testbed for applications running in the cloud on the [[http://cd-docdb.fnal.gov/cgi-bin/ShowDocument?docid=4905][Fermilab OSG site]]. Rob has an interview [[http://www.youtube.com/embed/Au0cAKH7kWw?feature=player_detailpage][online]] by !GridTalk. 

While at the meeting, Rob and Bill met with the iSGTW European Editors, working out some initial plans for the new iSGTW US OSG Satellite project and plans for the hiring of the new editor.   Rob has posted more information on the [[http://insideosgops.blogspot.com/2012/10/osg-operations-at-egi-technical-forum.html][OSG blogs]]. This was a useful occasion for planning future activities between OSG and EGI operations to benefit our international user communities.
 
_~[[mailto:osg-webmaster@opensciencegrid.org][OSG Communications]]_

----+++ *Campus Infrastructures Community Workshop*

 &lt;img src=&quot;%ATTACHURLPATH%/santa_cruz.jpg&quot; alt=&quot;santa_cruz.jpg&quot;width=&#39;150&#39; height=&#39;121&#39; align=&quot;left ; margin: 10px 10px 15px 0;&quot; /&gt;


We would like to invite you to a workshop on shared campus high throughput computing infrastructures, and engagement of science communities that use them, to be held November 14-15, 2012 at the University of California, Santa Cruz (*). 
 
While our focus in the OSG has, for many years, been on efficiently distributing workloads from stake-holding science organizations to resources linked by a nationwide set of grid endpoints, our colleagues on campus usually think and compute locally, optionally sending the overflow to the OSG.  Many OSG affiliated groups have recognized the economy of blending local and grid resources- usually transparently- and have accelerated their use across multiple science domains using campus grid techniques.  

A major focus of the meeting will be on practical discussions of these approaches, with emphasis on specific, enabling solutions.  This workshop is part of the new OSG Campus Infrastructures Community initiative, which aims to provide a forum for sharing tools, applications and best practices for creating similar environments - through webinars and in-person meetings.

_~ [[mailto:rwg@uchicago.edu][Rob Gardner, University of Chicago]]_

(*) https://indico.fnal.gov/conferenceDisplay.py?confId=5927


-- Main.JemiseLockhart - 23 Oct 2012

