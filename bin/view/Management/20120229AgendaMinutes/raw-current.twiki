---+ OSG Area Coordinators Meeting

---++ Meeting Phone Coordinates

%TABLE{tablewidth=&quot;550&quot; cellpadding=&quot;6&quot; dataalign=&quot;left&quot; tablerules=&quot;all&quot; tableborder=&quot;1&quot; databg=&quot;#FFFFFF, #FFFFFF&quot;}%
| Wednesday,  2:00 PM Central Time ||
| Phone (866) 740-1260 | Meeting ID 8405618, followed by # |

---++ Attendees
Alain, Chander, Mine, Brian, Rob Q, Gabriele, Dan, Ruth

---++ New Items for [[https://indico.fnal.gov/categoryDisplay.py?categId=86][OSG Calendar]]  
Jemise will update Indico
   * Apr 19-20 OSG Trash/Trash/Blueprint Meeting (Chicago Area)

---++ Follow-up Action Items
   * Alain is asked to send a weekly update on the GUMS release package and the actions to resolve the open issues to the Area Coordinators, till it is released. 
   * Alain is asked to develop a recommendation on jGlobus (for SHA-2) in time for review at the next CDIGS-OSG call on March 13. 

---++ Software Report - Alain Roy

Last report to the Area Coordinator Meeting [[20120125AgendaMinutes][January 25, 2012]]

---+++ Status &amp; Accomplishments

Highlights from the last five weeks:

   * *Improved Support:* The OSG Software Team now has a clear, shared support triage process and has unified on using the GOC ticket system.
      * [[SoftwareTeam.SoftwareSupport][Ticket handling process]]
      * [[SoftwareTeam.TriageDuty][Triage duty roster]]
      * [[SoftwareTeam.TransitionToGocTicket][Completed plan]]
   * *Scientific Linux 6 Support:* Yesterday we released the OSG Worker Node on Scientific Linux 6. 

We have made five software releases since the last meeting!

   1. OSG 3.0.6: Updated to Globus 5.2.0 (final) and miscellaneous bug fixes
   1. OSG 3.0.7: Primarily update to new CA certificates, minor bug fixes
   1. OSG 3.0.8: Primarily SL6 support for worker node, bug fixes
   1. OSG 1.2.27 (Pacman): Urgent security update
   1. OSG 1.2.28 (Pacman): Urgent security update

While it&#39;s good that we can release quickly, we risk user fatigue. I would prefer to make releases less frequently, on the order of once a month. Three of the update above were driven by security concerns (security updates &amp; CA certificates), so the quantity of releases was somewhat out of our control.

We know of 12 Compute Elements using the new OSG Software 3.0 release. Some of the below have multiple CEs:
   * UNL Firefly
   * UNL Red
   * UNL Prairiefire
   * !GridUNESP
   * OUHEP
   * RENCI Blueberry
   * SMU-HPC
   * Uconn-OSG_CE

I am aware that other sites are using it in part (worker nodes, etc), so this is not a complete picture. However, we don&#39;t have accurate information on anything except the CE.

---+++ Areas of Focus

These are the same areas that I reported on last time. That&#39;s good: these are still our areas of focus.

*1. Support for sites and VOs as they deploy the new OSG Software 3 release:* &lt;br&gt;
We continue to have a light support load. In the last few weeks, we&#39;ve had 1-3 new support tickets per week. My understanding is that a lot of user support is being handled within the VOs. 

*2. Transitioning software to RPMs that is missing:* &lt;br&gt;
GUMS is fully packaged, but our testing revealed a significant problem (large memory leak). John Hover has been working to fix the problem. Once this is fixed it will proceed to testing. 

We have not yet worked with Tanya on packaging the Gratia services because of work on Gratia probes.

*3. Scientific Linux 6 support:* &lt;br&gt;
CMS has asked for Scientific Linux 6 support by the end of February. Yesterday&#39;s release, OSG 3.0.8, added this support. In order to do it right, we did a lot of internal work on testing. We have:
   * Expanded our set of testing computers to include SL6
   * Improved our infrastructure to better report test results (still in progress, should be done this week)
   * Expanded our set of tests
 
Soon we will expand out set of platforms to test against pre-releases of the OS. 

We are now beginning to plan the remainder of the work for Scientific Linux 6 support and will report on that soon. 

*4. SHA-2 transition*: &lt;br&gt;
Since we last met, I organized a meeting to discuss jGlobus support. Globus, dCache, and Bestman developers attended. There are lots of details, but two main points stand out:

   1. If we want support for jGlobus, it will need to become a community effort. There is not expertise within the Argonne team to maintain it or fix problems, though they are willing to do basic work, such as cut releases.
   1. dCache and jGlobus have nearly identical code for using jGlobus. dCache developers have volunteered to dig into the integration with jGlobus 2.0 to understand what is missing and estimate how much work is before us. They asked for a month to do that work, and that month is nearly complete. I will be in touch with them soon.

*5. Improving Support*: &lt;br&gt;
Last time we met, I had just made [[SoftwareTeam.TransitionToGocTicket][a proposal for improving our support]]. This proposal has been fully implemented now. 

Every week, a different person on the OSG Software Team takes on triage duty. They are responsible for watching the incoming software tickets and either handling them directly or assigning them to the right person on the team. 

So far, this has been working well. We are watching tickets and following through on them. 

*6. Improving effort tracking:* &lt;br&gt;
I&#39;ve been working hard to understand how we will do effort tracking. Please consider this to be an &quot;in-progress status report&quot;, not a &quot;final plan&quot;. As I talk to people, it is evolving and improving. (Just this morning, Chander gave extensive feedback that will change what I have here.)

This effort is complicated slightly because the Condor Team is doing the same thing, and several OSG Software Team Members (myself, Tim, Scot, Mat) are also part of the Condor Team. I want the resulting effort tracking to be sufficiently coordinated: I do not want my team members to be required to do double-entry in systems that categorize effort differently. 

My effort towards this goal has been within the Condor Team. I&#39;ve recently drafted a proposal for how we will break down effort and we are working on the details. The basic big picture is that we will have a set of projects, each with activities and sub-activities. We want to keep the number of these as small as possible but no smaller. The activities include:

   * OSG (Software Team effort will entirely be here)
   * Condor
   * None
   * ... Others needed in the Condor Team

The activities and subactivities will be nearly identical between projects. Not all of them will apply to the Software Team. We try to balance having enough detail to answer all of our questions yet keeping the system sufficiently simple so that we can accurately collect the data. Where possible, we don&#39;t use a generic &quot;meeting&quot; category, but classify the meetings according to what real activity they support. They are:

| *Activity* | *Sub-activity* | *Comment or Example* |
| Development | Release Process | Software team meetings; Updating packages |
|| Fix Bugs | |
|| Enhance | CREAM; SL6 support etc... | 
| Outreach | New engagements | |
|| Ongoing Support | Many of our tickets would be here |
|| Teaching | The OSG User School |
| Infrastructure | Operations | Not often used for us; koji |
|| Unplanned | |
|| Projects | |
| Management | Hiring | |
|| Personnel | |
|| Grantsmanship | |
|| Misc | |
|| Meeting | OSG All-Hands Meeting |
| Sick | | Only used with Project &quot;None&quot; |
| Vacation | | Only used with Project &quot;None&quot; |
| Other | | Rarely used |

This isn&#39;t quite sufficient yet, because it&#39;s too hard to answer questions like &quot;How much effort did we spend on the SHA-2 effort?&quot;. 

We&#39;re considering different ways to collect the data, but have not made a decision yet. 

How does this overlap with the assessment goals? 

---++ Stakeholder Requests Update - Gabriele Garzoglio

Goal: assign pending requests 25, 29, 35 and discuss software request 34

http://jira.opensciencegrid.org/secure/Dashboard.jspa?selectPageId=10030
