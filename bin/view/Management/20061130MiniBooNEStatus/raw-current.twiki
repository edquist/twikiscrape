---++!! !MiniBooNE Status 2006/11/30

From Chris Polly:

&lt;blockquote&gt;
The following is a brief summary of the various problems encountered when trying to get the !MiniBooNE software suite to run on various OSG sites.  Thanks to a lot of help from Chris Green, Steve Timm, and Burt Holzman our software runs almost flawlessly on the GP, CDF, and CMS OSG sites at FNAL.  This summary refers to attempts to run on sites outside of the fnal.gov domain.  The short summary is that out of 12 grid sites that were tried, our software was able to run through completion on three offsite grids:

   * tp-osg.chicago.edu (UC_Teraport)
   * cmsgrid02.hep.wisc.edu (UWMadison)
   * vampire.accre.vanderbilt.edu (VAMPIRE-Vanderbilt)

However, in all three cases after an initial set of 50 or so jobs ran flawlessly over some fraction of a day the queues became unreliable. The issues resulting in the unreliability are still to be determined.  As 
of a few hours ago, the UWMadison site appears to be running our software suite successfully again.

The rest of this document is a dump of information, lessons learned, and problems solved for each site.


---+++ GRACE_CCR_U2 (us-grid.buffalo.edu:2119/jobmanager-pbs)
   * First submission resulted in a &quot;Host key verification file fails&quot; in the logfile with no other information.  Steve Timm traced this to a need to include a job_type=single globusRSL directive.
   * The second submission resulted in jobs getting through the scheduler and attempting to start.  Jobs then failed due to not being able to locate the grid setup.sh script from the worker nodes.  Have an e-mail in to admin asking why the script is not in the OSG_GRID=/opt/grid area.


---+++ OSG_ITB_OSU (ligo-db2.aset.psu.edu:2119/jobmanager-pbs)
   * Jobs held with &quot;Unspecified grid manager error&quot;.  No followup yet.


---+++ NERSC_PDSF (pdsfgrid2.ners.gov:2119/jobmangaer-sce)
   * Jobs held with &quot;Globus error 7: an authorization operation failed&quot;.  Chris Green has been in contact with sys admin and says that VOs need specific (per DN) access granted.


---+++ Purdue-ITaP (osg.rcac.purdue.edu:2119/jobmanager-condor)
   * First submissions went to jobmanager-pbs since jobmanager-condor is not advertised on VORS.  Jobs never started and were killed to use condor scheduler.
   * Second submission tried to run but were unable to copy the software to the OSG_APP area.  OSG_APP area is not writable and Chris Green has had an exchange with a sys admin about correcting the permissions.


---+++ Nebraska (red.unl.edu:2119/jobmanager-pbs)
   * Jobs held with &quot;Globus error 7: an authorization operation failed&quot;.  No followup yet.


---+++ UMATLAS (gate02.grid.umich.edu:2119/jobmanager-pbs)
   * First submissions failed due to exceeding wall clock limit. User has to reset the walltime with a maxWalltime=X in the globusRSL directive.
   * Second submission are submitted, but queue is down for maintenance.


---+++ UWMadison (cmsgrid02.hep.wisc.edu:2119/jobmanager-condor)
   * First submission died with confusion about whether to use a x86_64 or a i686 version of some library.  Chris Green implemented solution.
   * Second submission returned the first few jobs successfully.  A few dozen more started and were running when they suddenly started to be held with a &quot;Globus error 22: the job manager failed to create an internal script&quot;.  Released the jobs, several hundred started, and have just now started to return healthy output files.  


---+++ UWMilwaukee (nest.phys.uwm.edu:2119/jobmanager-condor)
   * First submission fails.  Best guess is that the worker nodes do not have outside network access.


---+++ UC_Teraport (tp-osg.uchicago.edu:2119/jobmanager-pbs)
   * This is the first offsite grid that our software ran on.  The first 50 or so jobs returned healthy data files to our servers.  However, since that first round only 1 out of every few hundred jobs return data.  The missing jobs just disappear without any evidence left behind.


---+++ IU_ATLAS_Tier2 (atlas.iu.edu:2119/jobmanager-pbs)
   * First submissions failed because the OSG_APP area was not defined the same on the head node and worker nodes.  Admins fixed the problem.
   * Second submission is in the queue and seems to be running, but jobs have not yet reached the point where the data should have been returned.


---+++ VAMPIRE-Vanderbilt (vampire.accre.vanderbilt.edu)
   * The first set of submission ran fine and returned data to our servers. After the first few jobs finished no others came back although a condor_q on fngp indicated that the jobs were still running. After running for much longer than usual, the jobs were eventually killed and had to be removed from the fnpg queue with a condor_rm -forcex.  A simple globus-job-run command was tried with the result:
   &lt;verbatim&gt;globus-job-run vampire.accre.vanderbilt.edu /bin/ls  
GRAM Job submission failed because the connection to the server failed (check host and port) (error code 12)&lt;/verbatim&gt;
   A repeat of that test today shows:
   &lt;verbatim&gt;globus-job-run vampire.accre.vanderbilt.edu /bin/ls
GRAM Job submission failed because an authorization operation failed (error code 7)&lt;/verbatim&gt;
&lt;/blockquote&gt;

-- Main.ChrisGreen - 30 Nov 2006
