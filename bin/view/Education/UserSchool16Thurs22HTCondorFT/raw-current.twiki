&lt;style type=&quot;text/css&quot;&gt;
pre em { font-style: normal; background-color: yellow; }
pre strong { font-style: normal; font-weight: bold; color: #008; }
&lt;/style&gt;

---+ File Compression and Testing Resource Requirements
%TOC%

The objective of this exercise is to refresh yourself on HTCondor file transfer, to implement file compression, and to begin examining the memory and disk space used by your jobs in order to plan larger batches, which we&#39;ll tackle in later exercises today.

---++ Setup

   * Make sure you are still logged into =osg-learn.chtc.wisc.edu=
   * Make a directory for today&#39;s blast exercises named =thur-blast-data=, and change into it.

The executable we&#39;ll use in this exercise and later today is the same  ==blastx== executable from yesterday&#39;s exercise 1.2.  Because we&#39;re going to end up using it many times, let&#39;s first copy the =ncbi-blast-2.4.0+= directory to your /home/user directory, so that it will always be accessible from the same location (rather than keeping multiple copies in your various exercise directories). In the location containing the =ncbi-blast-2.4.0+= directory from yesterday, run the following command:

&lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT_SHORT% &lt;strong&gt;cp -r ncbi-blast-2.4.0+ ~&lt;/strong&gt;
&lt;/pre&gt;

You should now see the =ncbi-blast-2.4.0+= directory in your =/home/user= location (which was indicated with the &quot;~&quot; shortcut in the command above), and this directory will still contain the ==blastx= executable within the =bin= directory.

Also copy the data from yesterday into the =thur-blast-data= directory. You&#39;ll need the =mouse.fa= file and the =pdbaa= directory from yesterday&#39;s exercise, but you&#39;ll end up making a new submit file.

---+++ Review: HTCondor File Transfer

&lt;center&gt;
&lt;img src=&quot;%ATTACHURLPATH%/data_tranfer_1.jpg &quot; alt=&quot;data_tranfer_1.jpg &quot; width=&#39;400&#39; height=&#39;150&#39;/&gt;
&lt;/center&gt;

Recall that OSG does not have a shared filesystem! Instead, HTCondor _transfers_ your executable and input files (listed with =transfer_input_files=) to a working directory on the execute node, regardless of how these files were arranged on the submit node.  In this exercise we&#39;ll use the same =blastx= example job that we used previously, but modify the submit file and test how much memory and disk space it uses on the execute node.

---++ Start with a test submit file

We&#39;ve started a submit file for you, below, which you&#39;ll add to in the remaining steps. 

&lt;pre class=&quot;file&quot;&gt;
executable = 
transfer_input_files = 
output = test.out
error = test.error
log = test.log
request_memory = 
request_disk = 
request_cpus = 1
requirements = (OpSys == &quot;LINUX&quot;)
queue
&lt;/pre&gt;

---+++ Implement file compression

In our first blast job from yesterday, the database files in the =pdbaa= directory were all transferred, as is, but we could instead transfer them as a single, compressed file using =tar=. For a second test job, let&#39;s compress our blast database files to send them to the submit node as a single =tar.gz= file, by following the below steps

1. Change into the =pdbaa= directory and compress the database files into a single file called =pdbaa_files.tar.gz= using the =tar= command. (NOTE: This file will be different from the =pdbaa.tar.gz= files you downloaded yesterday, because it will only contain the =pdbaa= files, and not the =pdbaa= directory, itself.)

A typical command for creating a tar file is:
&lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT_SHORT% &lt;strong&gt;tar -cvzf [compressed filename] [list of files]&lt;/strong&gt;
&lt;/pre&gt; 

Move this file to the =thur-blast-data= directory.

2. Create a wrapper script that will first decompress the =pdbaa_files.tar.gz= file, and then run blast. 

Because this file will now be our submit file =executable=, we&#39;ll also end up transferring the =blastx= executable with =transfer_input_files= (without the =ncbi-blast-2.4.0+= directory that it is located in on the submit node). In the =thur-blast-data= directory, create a new file, called =blast_wrapper.sh=, with the following contents:
&lt;pre class=&quot;file&quot;&gt;
#!/bin/bash

tar xvzf pdbaa_files.tar.gz

./blastx -db pdbaa -query mouse.fa -out mouse.fa.result

rm pdbaa.*
&lt;/pre&gt;

IMPORTANT: The last line removes the resulting database files that came from =pdbaa_files.tar.gz=, as these files would otherwise be copied back to the submit server as perceived output (because they&#39;re new files that HTCondor didn&#39;t transfer over as input).

---+++ List the executable and input files
Make sure to update the submit file with the following:
   * Add the new =executable= (the wrapper script you created above)
   * List the =blastx= binary, the =pdbaa_files.tar.gz= file, and the input query file in =transfer_input_files=

HINT: Remember that =transfer_input_files= accepts a comma separated list of files, and that you need to list the full location of the =blastx= executable (=/home/user/ncbi-blast-2.4.0+/bin/blastx=). There will be no arguments, since the arguments to the =blastx= command are now captured in the wrapper script.

---+++ Predict memory and disk requests from your data
Also, think about how much memory and disk to request for this job. It&#39;s good to start with values that are a little higher than you think a test job will need, but think about:
   * how much memory =blastx= would use if it loaded all of the database files _and_ the query input file into memory.
   * how much disk space will be necessary on the execute server for the executable, all input files, and all output files (hint: the log file only exists on the submit node).
   * whether you&#39;d like to request some extra memory or disk space, just in case

Look at the =log= file for your =blastx= job from yesterday, and compare the memory and disk &quot;Usage&quot; to what you predicted from the files. Make sure to update the submit file with more accurate memory and disk requests (you may still want to request slightly more than the job actually used).

---++ Run the test job

Once you have finished editing the submit file, go ahead and submit the job. It should a few minutes to complete, and then you can check to make sure that no unwanted files (especially the =pdbaa= database files) were copied back at the end of the job.

Run a ==du -sh== on the directory with this job&#39;s input. How does it compare to the directory from yesterday, and why?

When you&#39;ve completed the above, continue with the next exercise.


-- Main.LaurenMichael - 21 Jul 2016

