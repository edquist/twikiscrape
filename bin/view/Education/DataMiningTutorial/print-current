<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en_US" lang="en_US">
<head>
<link rel="stylesheet" href="https://twiki.opensciencegrid.org/twiki/pub/TWiki/HeadlinesPlugin/style.css" type="text/css" media="all" />
<title> DataMiningTutorial &lt; Education &lt; TWiki    </title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
<link rel="icon" href="/twiki/pub/Education/WebPreferences/favicon.ico    " type="image/x-icon" />
<link rel="shortcut icon" href="/twiki/pub/Education/WebPreferences/favicon.ico    " type="image/x-icon" />
<link rel="alternate" href="https://twiki.opensciencegrid.org/bin/edit/Education/DataMiningTutorial?_T=16 Feb 2017" type="application/x-wiki" title="edit DataMiningTutorial" />
<meta name="SCRIPTURLPATH" content="/bin" />
<meta name="SCRIPTSUFFIX" content="" />
<meta name="TEXT_JUMP" content="Jump" />
<meta name="TEXT_SEARCH" content="Search" />
<meta name="TEXT_NUM_TOPICS" content="Number of topics:" />
<meta name="TEXT_MODIFY_SEARCH" content="Modify search" />
<meta name="robots" content="noindex" /><link rel="alternate" type="application/rss+xml" title="RSS Feed" href="/bin/view/Education/WebRss" />    
<base href="https://twiki.opensciencegrid.org/bin/view/Education/DataMiningTutorial"></base>
<!--BEHAVIOURCONTRIB--><script type="text/javascript" src="/twiki/pub/TWiki/BehaviourContrib/behaviour.compressed.js"></script>
<script type="text/javascript" src="/twiki/pub/TWiki/TWikiJavascripts/twikilib.js"></script>
<script type="text/javascript" src="/twiki/pub/TWiki/TWikiJavascripts/twikiWindow.js"></script>
<script type="text/javascript" src="/twiki/pub/TWiki/TWikiJavascripts/twikiEvent.js"></script>
<script type="text/javascript" src="/twiki/pub/TWiki/TWikiJavascripts/twikiHTML.js"></script>
<script type="text/javascript" src="/twiki/pub/TWiki/TWikiJavascripts/twikiCSS.js"></script>
<script type="text/javascript" src="/twiki/pub/TWiki/TWikiJavascripts/twikiForm.js"></script>
<script type="text/javascript" src="/twiki/pub/TWiki/PatternSkin/pattern.js"></script><style type="text/css" media="all">
@import url('/twiki/pub/TWiki/TWikiTemplates/base.css');
</style><script type="text/javascript" src="/twiki/pub/TWiki/TWikiJavascripts/twikiStyles.js"></script><style type="text/css" media="all">


</style>
<style type="text/css" media="all">
@import url("/twiki/pub/TWiki/TWikiNetSkin/layout.css");
@import url("/twiki/pub/TWiki/TWikiNetSkin/style.css");
@import url("/twiki/pub/TWiki/TWikiNetSkin/colors.css");
@import url("/twiki/pub/TWiki/TWikiNetSkin/rounded_corners.css");
</style>
<style type="text/css" media="all">
	/* Styles that are set using variables */
	#patternLeftBar .patternWebIndicator,
	.patternBookView .twikiTopRow {
		background-color:#D0D0D0;
	}
	.patternBookView {
		border-color:#D0D0D0;
	}
	.patternPreviewPage #patternMain {
		/* uncomment to set the preview image */
		/*background-image:url("/twiki/pub/TWiki/PreviewBackground/preview2bg.gif    ");*/
	}
	
</style><style type="text/css" media="all">

@import url('/pub/Documentation/Tools/exercises.css ');

</style>
<style type="text/css" media="all">
	@import url("/twiki/pub/TWiki/TWikiNetSkin/print.css");
</style><!--GOOGLEANALYTICSPLUGIN--><!-- Google Analytics script -->
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-69012-21']);
  _gaq.push(['_setDomainName', 'none']);
  _gaq.push(['_setAllowLinker', true]);
  _gaq.push(['_trackPageview']);
  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
</head>
<body class="patternViewPage patternPrintPage">
<a name="PageTop"></a>
<div id="patternScreen">
<div id="patternPageShadow">
<div id="patternPage">
<div id="patternOuter">
<div id="patternFloatWrap">
<div id="patternMain">
<div id="patternMainContents">
<div class="patternContent"><div class="patternTopic"> <!-- deprecated -->
<p />
<h1><a name="Tutorial_Data_Mining"></a>  Tutorial: Data Mining </h1>
<div class="twikiToc"> <ul>
<li> <a href="?cover=print#Getting_set_up"> Getting set up</a>
</li> <li> <a href="?cover=print#The_Basic_Pattern"> The Basic Pattern</a>
</li> <li> <a href="?cover=print#Using_R_to_Compute_k_means_Clust"> Using R to Compute k-means Clusters</a>
</li> <li> <a href="?cover=print#Using_R_and_Globus_to_Compute_k"> Using R and Globus to Compute k-Means Clusters</a> <ul>
<li> <a href="?cover=print#run_job_py"> run-job.py</a>
</li> <li> <a href="?cover=print#angle_analysis_r"> angle-analysis.r</a>
</li></ul> 
</li> <li> <a href="?cover=print#Generalizing_to_a_List_of_Nodes"> Generalizing to a List of Nodes</a> <ul>
<li> <a href="?cover=print#run_multiple_py"> run-multiple.py</a>
</li></ul> 
</li> <li> <a href="?cover=print#Assignment_1"> Assignment 1</a>
</li> <li> <a href="?cover=print#Using_R_to_Compute_CART_Trees"> Using R to Compute CART Trees</a> <ul>
<li> <a href="?cover=print#Example_IRIS_Data"> Example - IRIS Data </a>
</li> <li> <a href="?cover=print#Overview_of_Building_a_Model"> Overview of Building a Model</a>
</li> <li> <a href="?cover=print#Example_Forest_Cover_Data"> Example -  Forest Cover Data</a>
</li> <li> <a href="?cover=print#analysis_read_data_r"> ~/analysis/read_data.r</a>
</li></ul> 
</li> <li> <a href="?cover=print#Using_R_and_Globus_to_Compute_CA"> Using R and Globus to Compute CART Trees </a> <ul>
<li> <a href="?cover=print#run_cart_globus_py"> run-cart-globus.py</a>
</li></ul> 
</li> <li> <a href="?cover=print#Assignment_2"> Assignment 2</a>
</li> <li> <a href="?cover=print#Hints"> Hints</a>
</li></ul> 
</div>
<p />
<p />
<p />
<a name="Getting_set_up"></a>
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Getting_set_up"></a> Getting set up </span></h2>
<p />
Check that you have a valid proxy.
<p />
<pre class="screen">
workshop1.lac.uic.edu$ <userinput>grid-proxy-init</userinput>
Your identity: /O=Grid/OU=OSG/CN=Training User 99
Enter GRID pass phrase for this identity:
Creating proxy ...................................... Done
Your proxy is valid until: Fri Mar 23 00:20:40 2007
</pre>
<p />
Now, make a working directory for this exercise. For the rest of this exercise, all your work should be done in there.
<p />
<pre class="screen">
workshop1.lac.uic.edu$ <userinput>mkdir dmex</userinput>
workshop1.lac.uic.edu$ <userinput>cd dmex</userinput>
</pre>
<p />
<p />
<p />
<a name="Patterns 1 and 2"></a> 
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="The_Basic_Pattern"></a> The Basic Pattern </span></h2>
Recall the two basic patterns from the lecture that we will deal with in this tutorial:
<p /> <ul>
<li> <em>Pattern 1</em> divides the data into several different segments, runs the same analysis on each to produce a report or model, and gathers the results.  
</li> <li> <em>Pattern 2</em> divides the parameter space into several different parameter ranges, runs the same analysis on each to produce a report or model, and gathers the results.  
</li></ul> 
<p />
(Of course, the two Patterns can be combined.)
<p />
To support these patterns, make the following directories on <em>each</em> of the nodes in the cluster you will be using.  These exercises assume that they exist. 
<p /> <ul>
<li> data
</li> <li> analysis 
</li> <li> models
</li> <li> reports 
</li> <li> collect
</li></ul> 
<p />
<p />
Here is an example of how to create the directory data on workshop4. 
<p />
<pre class="screen">
workshop1.lac.uic.edu$ <userinput>globus-job-run workshop4.lac.uic.edu "/bin/mkdir"  &#92;
  "/home/train99/data" </userinput>
Submitting job...Done.
Job ID: uuid:63bf25c6-d895-11db-a43b-00e081749872
Termination time: 03/23/2007 16:50 GMT
Current job state: Active
Current job state: CleanUp
Current job state: Done
Destroying job...Done.
</pre>
<p />
Create the other directories in a similar fashion.
<p />
<p />
<a name="Using R to Compute k-Means Clusters"></a>
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Using_R_to_Compute_k_means_Clust"></a> Using R to Compute k-means Clusters </span></h2>
<p />
Before using the grid for you computation, make sure you can do the computation first on a single machine that you can log in to, using R, but not Globus. 
<p />
<pre class="screen">
workshop1.lac.uic.edu$ <userinput>R</userinput>
> <userinput>library(pmml)</userinput>
Loading required package: XML
> <userinput>data(iris)</userinput>
> <userinput>a.data &lt;- iris </userinput>
> <userinput>summary(a.data)</userinput>
 Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   
 Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  
 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  
 Median :5.800   Median :3.000   Median :4.350   Median :1.300  
 Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  
 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  
 Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  
       Species  
 setosa    :50  
 versicolor:50  
 virginica :50  
> <userinput> a.data.1 &lt;- a.data[, c("Sepal.Length", "Sepal.Width", "Petal.Length", "Petal.Width")]</userinput>
> <userinput> m1 &lt;- kmeans(a.data.1, centers=3) </userinput>
> <userinput> m1$centers </userinput>
  Sepal.Length Sepal.Width Petal.Length Petal.Width
1     5.901613    2.748387     4.393548    1.433871
2     5.006000    3.428000     1.462000    0.246000
3     6.850000    3.073684     5.742105    2.071053
> <userinput> p1 &lt;- pmml(m1) </userinput>
> <userinput> saveXML(p1, file="iris-clusters.pmml") </userinput>
> <userinput> quit() </userinput>

</pre>
<p />
In this example, we use the Iris data that is part of the R distributionand available through the data() function.  We compute three k-means clusters for the four features:  <ul>
<li> Sepal.Length
</li> <li> Sepal.Width
</li> <li> Petal.Length
</li> <li> Petal.Width 
</li></ul> 
<p />
Save the resulting model as a PMML file. To make sure that this works, you should examine the PMML file and it should look like the following: 
<p />
<pre class="programlisting">
&lt;?xml version="1.0"?&gt;
&lt;PMML version="3.1" xmlns="http://www.dmg.org/PMML-3_1" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"&gt;
 &lt;DataDictionary numderOfFields="4"&gt;
  &lt;DataField name="Sepal.Length" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="Sepal.Width" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="Petal.Length" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="Petal.Width" optype="continuous" dataType="double"/&gt;
 &lt;/DataDictionary&gt;
 &lt;ClusteringModel modelName="KMeans_Model" functionName="clustering" algorithmName="KMeans" mo
delClass="centerBased" numberOfClusters="3"&gt;
  &lt;MiningSchema&gt;
   &lt;MiningField name="Sepal.Length" usageType="active"/&gt;
   &lt;MiningField name="Sepal.Width" usageType="active"/&gt;
   &lt;MiningField name="Petal.Length" usageType="active"/&gt;
   &lt;MiningField name="Petal.Width" usageType="active"/&gt;
  &lt;/MiningSchema&gt;
  &lt;ComparisonMeasure kind="distance"/&gt;
  &lt;Cluster name="1" size="62"&gt;
   &lt;Array n="4"&gt;5.90161290322581 2.74838709677419 4.39354838709678 1.43387096774194&lt;/Array&gt;
  &lt;/Cluster&gt;
  &lt;Cluster name="2" size="50"&gt;
   &lt;Array n="4"&gt;5.006 3.428 1.462 0.246&lt;/Array&gt;
  &lt;/Cluster&gt;
  &lt;Cluster name="3" size="38"&gt;
   &lt;Array n="4"&gt;6.85 3.07368421052632 5.74210526315789 2.07105263157895&lt;/Array&gt;
  &lt;/Cluster&gt;
 &lt;/ClusteringModel&gt;
&lt;/PMML&gt;
</pre>
<p />
<p />
<p />
<!-- <strong>*</strong>  Comments plugin to create comments table for section   <strong>*</strong>    -->
<span class="educationWebAddComment">ADD A COMMENT</span>
<span id="twid_1show" class="twistyMakeVisible">
       <a href="#" class="twistyTrigger"><em><strong>Show...</strong></em></a>
     </span>
     <span id="twid_1hide" class="twistyHidden">
       <a href="#" class="twistyTrigger"><em><strong>Hide</strong></em></a>
     </span>
     <div id="twid_1toggle" class="twistyMakeHidden">
<p />
<p />
<table cellspacing="0" cellpadding="0" border="0" class="twikinetWrapperTable" rules="none">
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableT twikinetWrapperTableTL"></td>
<td class="twikinetWrapperTableT twikinetWrapperTableTR"></td>
</tr>
<tr class="twikinetWrapperTableRow">
<td colspan="2" class="twikinetWrapperTableMain">
<table cellspacing="0" id="table1" cellpadding="0" class="twikiTable" rules="cols" border="1">
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<th bgcolor="#d8dde4" align="center" valign="top" class="twikiTableCol0 twikiFirstCol twikiLast"> <a rel="nofollow" href="/bin/view/Education/DataMiningTutorial?cover=print;sortcol=0;table=1;up=0#sorted_table" title="Sort by this column"><font color="#252b37">COMMENT</font></a> </th>
			<th bgcolor="#d8dde4" align="center" valign="top" class="twikiTableCol1 twikiLast"> <a rel="nofollow" href="/bin/view/Education/DataMiningTutorial?cover=print;sortcol=1;table=1;up=0#sorted_table" title="Sort by this column"><font color="#252b37">NAME</font></a> </th>
			<th bgcolor="#d8dde4" align="center" valign="top" class="twikiTableCol2 twikiLastCol twikiLast"> <a rel="nofollow" href="/bin/view/Education/DataMiningTutorial?cover=print;sortcol=2;table=1;up=0#sorted_table" title="Sort by this column"><font color="#252b37">DATE</font></a> </th>
		</tr></table>
</td>
</tr>
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableB twikinetWrapperTableBL"></td>
<td class="twikinetWrapperTableB twikinetWrapperTableBR"></td>
</tr>
</table>
<form method="post" action="https://twiki.opensciencegrid.org/bin/save/Education/DataMiningTutorial" enctype="multipart/form-data" name="tableappend0" id="tableappend0">
<p />
<div class="commentPlugin commentPluginPromptBox">
<table><tr valign="middle"><td><textarea  rows="3" cols="70" name="comment" wrap="soft" onfocus="if(this.value=='')this.value=''" onblur="if(this.value=='')this.value=''"></textarea></td><td><input  type="submit" value="Add comment" /></td></tr></table>
</div><!--/commentPlugin-->
<p />
<input type="hidden" name="comment_action" value="save"  />
<input type="hidden" name="comment_type" value="tableappend"  />
<input type="hidden" name="comment_index" value="0"  /></form>
<p />
</div>
<!-- <strong>*</strong>  End Comment                                    <strong>*********</strong>    -->
<p />
<p />
<p />
<p />
<a name="Using R and Globus to Compute k-Means Clusters"></a>
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Using_R_and_Globus_to_Compute_k"></a> Using R and Globus to Compute k-Means Clusters </span></h2>
<p />
Once you can use R to compute clusters locally on a node that you can login to and invoke R directly, it is relatively easy to invoke the script on a remote node.  Here is an example.  
<p />
First, we invoke the script directly on a machine that we can login to: 
<p />
<pre class="screen">
$ <userinput>R &lt; angle-analysis.r --no-save </userinput>

R version 2.4.0 Patched (2006-11-25 r39997)
Copyright (C) 2006 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.
 
> <userinput>a.data.file &lt;- "data/angle-data.csv"</userinput>

<em>[etc]</em>
</pre>
<p />
Next, we perform the following steps. We assume that we have a coordinating node and one or more compute nodes.
<p />
<ol>
<li> Divide the data into segments.
<li> Copy a segment of the data to a compute node.
<li> Copy the corresponding analysis script.
<li> Invoke R, with the input coming from the analysis script.
<li> Copy the resulting PMML model back to the coordinating node.
</ol>
<p />
<p />
To obtain the angle data files, execute following commands on the controlling node:
<p />
<p />
<pre class="programlisting">
$ <userinput>wget http://angle.ncdm.uic.edu/globus/angle-data-workshop1.lac.uic.edu.csv</userinput>
$ <userinput>wget http://angle.ncdm.uic.edu/globus/angle-data-workshop2.csv</userinput>
$ <userinput>wget http://angle.ncdm.uic.edu/globus/angle-data-workshop3.csv</userinput>
$ <userinput>wget http://angle.ncdm.uic.edu/globus/angle-data-workshop4.csv</userinput>
</pre>
<p />
Here is a Python script which will do this. The assumption is that the data is divided into several parts, labeled <code>angle-data-1.csv</code>, <code>angle-data-2.csv</code>, etc.  The same R analysis will be run on each segment to produce a separate PMML file, which will be collected and combined into a single model. In the example below, we look at the analysis for <code>angle-data-4.csv</code>, which we assume is one of the segments. 
<p />
<h3><a name="run_job_py"></a> <code><b>run-job.py</b></code> </h3>
<p />
<pre class="programlisting">
#! /usr/bin/env python                                                       
                                                                     
from os import system                             
 
# copy local data file to remote machine 
cmds = "globus-url-copy file:///home/train99/data/angle-data-workshop4.csv " 
cmds = cmds + "gsiftp://workshop4.lac.uic.edu/home/train99/data/angle-data.csv" 
print "*** running: " + cmds + "\n"
system(cmds) 
 
# copy r script to compute clusters to remote machine 
cmds = "globus-url-copy file:///home/train99/angle-analysis.r " 
cmds = cmds + "gsiftp://workshop4.lac.uic.edu/home/train99/angle-analysis.r" 
print "*** running: " + cmds + "\n"
system(cmds) 
 
# invoke R script on remote machine 
cmds = "globus-job-run workshop4.lac.uic.edu " 
cmds = cmds + " /bin/sh -c '/usr/bin/R &lt /home/train99/angle-analysis.r --no-save' " 
print "*** running: " + cmds + "\n"
system(cmds) 
 
# collect PMML file 
cmds = "globus-url-copy gsiftp://workshop4.lac.uic.edu/home/train99/models/angle-model.pmml " 
cmds = cmds + "file:///home/train99/collect/angle-model-4.pmml" 
print "*** running: " + cmds + "\n"
system(cmds) 
</pre>
<p />
Here is the R script that is being run on the node. 
<p />
<h3><a name="angle_analysis_r"></a> <code><b>angle-analysis.r</b></code> </h3>
<p />
<pre class="programlisting">

library(pmml) 
 
# data file 
a.data.file &lt;- "data/angle-data.csv" 
 
# output file 
a.model.file &lt;- "models/angle-model.pmml" 
 
a.col &lt;- list(ts=0,  
  src="",  
  sprt=0,  
  sCOUNTRY="",  
  dst="",  
  dprt=0,  
  dCOUNTRY="",  
  ip.4min=0,  
  ip.2min=0,  
  ip.1min=0,  
  ipprt.4min=0,  
  ipprt.2min=0,  
  ipprt.1min=0,  
  clusters="" 
) 
 
a.raw &lt;- scan(file=a.data.file, what=a.col, skip=1, sep=',') 
a.data &lt;- as.data.frame(a.raw) 
 
a.data.1 &lt;- a.data[,c('ip.4min', 'ip.2min', 'ip.1min',  
  'ip.4min', 'ip.2min', 'ip.1min')] 
 
 
m1 &lt;- kmeans(a.data.1, centers=10) 
 
p1 &lt;- pmml(m1) 
saveXML(p1, file=a.model.file) 
</pre>
<p />
<p />
<a name="Generalizing to a List of Nodes"></a>
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Generalizing_to_a_List_of_Nodes"></a> Generalizing to a List of Nodes </span></h2>
<p />
It is now easy to modify the Python code so that it will work with any list of available nodes, say a list provide by the Globus MDS service. Here is a slightly modified Python script that does this: 
<p />
<h3><a name="run_multiple_py"></a> <code><b>run-multiple.py</b></code> </h3>
<p />
<pre class="programlisting">
#! /usr/bin/env python

from os import system

nodes = ["workshop1.lac.uic.edu", "workshop2", "workshop3", "workshop4"]

# local files are of the form filebase/filename
filebase = "file:///home/train99"

# remote files are of the form: gsiftp:///filename
nodebase = ".lac.uic.edu/home/train99"


# copy local data file to remote machine
for node in nodes:
  cmds = "globus-url-copy " + filebase + "/data/angle-data-"
  cmds = cmds + node + ".csv "
  cmds = cmds + "gsiftp://"
  cmds = cmds + node
  cmds = cmds + nodebase + "/data/angle-data.csv"
  print "*** running: " + cmds + "\n"
  system(cmds)

# copy r script to compute clusters to remote machine
for node in nodes:
  cmds = "globus-url-copy " + filebase + "/analysis/angle-analysis.r "
  cmds = cmds + "gsiftp://"
  cmds = cmds + node
  cmds = cmds + nodebase + "/angle-analysis.r"
  print "*** running: " + cmds + "\n"
  system(cmds)

# invoke R script on remote machine
for node in nodes:
  cmds = "globus-job-run "
  cmds = cmds + node
  cmds = cmds + ".lac.uic.edu "
  cmds = cmds + " /bin/sh -c '/usr/bin/R &lt /home/train99/angle-analysis.r --no-save' "
  print "*** running: " + cmds + "\n"
  system(cmds)

# collect PMML file
for node in nodes:
  cmds = "globus-url-copy gsiftp://"
  cmds = cmds + node
  cmds = cmds + nodebase + "/models/angle-model.pmml "
  cmds = cmds + filebase + "/collect/angle-model-"
  cmds = cmds + node
  cmds = cmds + ".pmml"
  print "*** running: " + cmds + "\n"
  system(cmds)
</pre>
<p />
<p />
<a name="Assignment 1"></a>
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Assignment_1"></a> Assignment 1 </span></h2>
<p />
This assignment has two parts: 
<p />
<ol>
  <li>Take several Angle data files, and use R and Globus to compute k-means clusters, with k=5, where different processors compute the k-means clusters for different data files. Collect all the resulting PMML files and analyze how different the clusters are. </li>
  <li>Repeat the task above, but this time use the same data file, but use different processors to compute clusters for different values of k. </li>
</ol>
<p />
<p />
<a name="Using R to Compute CART Trees"></a>
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Using_R_to_Compute_CART_Trees"></a> Using R to Compute CART Trees </span></h2>
<p />
<h3><a name="Example_IRIS_Data"></a> Example - IRIS Data </h3>
<p />
To warm up, we begin by reviewing how to compute a classification and regression (CART) tree using R.  First, we load the Iris data, which, as we have already seen, can be accessed with the data() command.  Next, we compute the tree using the rpart library.  Finally, we save the tree as a PMML file.  
<p />
<pre class="screen">
> <userinput>data(iris)</userinput>
> <userinput>a.data &lt;- iris</userinput>
> <userinput>summary(a.data)</userinput>
  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width          Species  
 Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100   setosa    :50  
 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300   versicolor:50  
 Median :5.800   Median :3.000   Median :4.350   Median :1.300   virginica :50  
 Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199                  
 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800                  
 Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500                  

> <userinput>library(rpart)</userinput>
> <userinput>m1 &lt;- rpart(Species ~ ., data=a.data)</userinput>
> <userinput>print(m1)</userinput>
n= 150 

node), split, n, loss, yval, (yprob)
      * denotes terminal node

1) root 150 100 setosa (0.33333333 0.33333333 0.33333333)  
  2) Petal.Length&lt; 2.45 50   0 setosa (1.00000000 0.00000000 0.00000000) *
  3) Petal.Length>=2.45 100  50 versicolor (0.00000000 0.50000000 0.50000000)  
    6) Petal.Width&lt; 1.75 54   5 versicolor (0.00000000 0.90740741 0.09259259) *
    7) Petal.Width>=1.75 46   1 virginica (0.00000000 0.02173913 0.97826087) *

> <userinput>library(pmml)</userinput>
Loading required package: XML
> <userinput>p1 &lt;- pmml(m1)</userinput>
> <userinput>saveXML(p1, "iris.pmml")</userinput>
</pre>
<p />
<p />
Here is a slightly more general version of the command used to compute a classification tree using R: 
<p />
<pre class="programlisting">
m2 &lt;- rpart(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, 
  data=a.data, method = "class", control=rpart.control(cp=0, maxdepth=5))
</pre>
<p />
Here is the PMML file produced: 
<p />
<pre class="programlisting">
&lt;?xml version="1.0"?&gt;
&lt;PMML version="3.1" xmlns="http://www.dmg.org/PMML-3_1" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"&gt;
 &lt;DataDictionary numderOfFields="5"&gt;
  &lt;DataField name="Species" optype="categorical" dataType="string"&gt;
   &lt;Value value="setosa"/&gt;
   &lt;Value value="versicolor"/&gt;
   &lt;Value value="virginica"/&gt;
  &lt;/DataField&gt;
  &lt;DataField name="Sepal.Length" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="Sepal.Width" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="Petal.Length" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="Petal.Width" optype="continuous" dataType="double"/&gt;
 &lt;/DataDictionary&gt;
 &lt;TreeModel modelName="RPart_Model" functionName="classification" algorithmName="rpart" splitCharacteristic="binarySplit"&gt;
  &lt;MiningSchema&gt;
   &lt;MiningField name="Species" usageType="predicted"/&gt;
   &lt;MiningField name="Sepal.Length" usageType="active"/&gt;
   &lt;MiningField name="Sepal.Width" usageType="active"/&gt;
   &lt;MiningField name="Petal.Length" usageType="active"/&gt;
   &lt;MiningField name="Petal.Width" usageType="active"/&gt;
  &lt;/MiningSchema&gt;
  &lt;Node score="setosa" recordCount="150"&gt;
   &lt;True/&gt;
   &lt;Node score="setosa" recordCount="50"&gt;
    &lt;SimplePredicate field="Petal.Length" operator="lessThan" value="2.45"/&gt;
   &lt;/Node&gt;
   &lt;Node score="versicolor" recordCount="100"&gt;
    &lt;SimplePredicate field="Petal.Length" operator="greaterOrEqual" value="2.45"/&gt;
    &lt;Node score="versicolor" recordCount="54"&gt;
     &lt;SimplePredicate field="Petal.Width" operator="lessThan" value="1.75"/&gt;
    &lt;/Node&gt;
    &lt;Node score="virginica" recordCount="46"&gt;
     &lt;SimplePredicate field="Petal.Width" operator="greaterOrEqual" value="1.75"/&gt;
    &lt;/Node&gt;
   &lt;/Node&gt;
  &lt;/Node&gt;
 &lt;/TreeModel&gt;
&lt;/PMML&gt;
</pre>
<p />
<p />
<!-- <strong>*</strong>  Comments plugin to create comments table for section   <strong>*</strong>    -->
<span class="educationWebAddComment">ADD A COMMENT</span>
<span id="twid_2show" class="twistyMakeVisible">
       <a href="#" class="twistyTrigger"><em><strong>Show...</strong></em></a>
     </span>
     <span id="twid_2hide" class="twistyHidden">
       <a href="#" class="twistyTrigger"><em><strong>Hide</strong></em></a>
     </span>
     <div id="twid_2toggle" class="twistyMakeHidden">
<p />
<p />
<table cellspacing="0" cellpadding="0" border="0" class="twikinetWrapperTable" rules="none">
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableT twikinetWrapperTableTL"></td>
<td class="twikinetWrapperTableT twikinetWrapperTableTR"></td>
</tr>
<tr class="twikinetWrapperTableRow">
<td colspan="2" class="twikinetWrapperTableMain">
<table cellspacing="0" id="table2" cellpadding="0" class="twikiTable" rules="cols" border="1">
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<th bgcolor="#d8dde4" align="center" valign="top" class="twikiTableCol0 twikiFirstCol twikiLast"> <a rel="nofollow" href="/bin/view/Education/DataMiningTutorial?cover=print;sortcol=0;table=2;up=0#sorted_table" title="Sort by this column"><font color="#252b37">COMMENT</font></a> </th>
			<th bgcolor="#d8dde4" align="center" valign="top" class="twikiTableCol1 twikiLast"> <a rel="nofollow" href="/bin/view/Education/DataMiningTutorial?cover=print;sortcol=1;table=2;up=0#sorted_table" title="Sort by this column"><font color="#252b37">NAME</font></a> </th>
			<th bgcolor="#d8dde4" align="center" valign="top" class="twikiTableCol2 twikiLastCol twikiLast"> <a rel="nofollow" href="/bin/view/Education/DataMiningTutorial?cover=print;sortcol=2;table=2;up=0#sorted_table" title="Sort by this column"><font color="#252b37">DATE</font></a> </th>
		</tr></table>
</td>
</tr>
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableB twikinetWrapperTableBL"></td>
<td class="twikinetWrapperTableB twikinetWrapperTableBR"></td>
</tr>
</table>
<form method="post" action="https://twiki.opensciencegrid.org/bin/save/Education/DataMiningTutorial" enctype="multipart/form-data" name="tableappend1" id="tableappend1">
<p />
<div class="commentPlugin commentPluginPromptBox">
<table><tr valign="middle"><td><textarea  rows="3" cols="70" name="comment" wrap="soft" onfocus="if(this.value=='')this.value=''" onblur="if(this.value=='')this.value=''"></textarea></td><td><input  type="submit" value="Add comment" /></td></tr></table>
</div><!--/commentPlugin-->
<p />
<input type="hidden" name="comment_action" value="save"  />
<input type="hidden" name="comment_type" value="tableappend"  />
<input type="hidden" name="comment_index" value="1"  /></form>
<p />
</div>
<!-- <strong>*</strong>  End Comment                                    <strong>*********</strong>    -->
<p />
<p />
<h3><a name="Overview_of_Building_a_Model"></a> Overview of Building a Model </h3>
<p />
It is helpful to structure the process of building a data mining or statistical model into several discrete steps.  Here is a standard way to this.  For more complicated problems, there would be more steps and in turn these steps would be broken up further. 
<p />
<ol>
   <li> <em>Reading the data.</em>  In the examples below, we will use a script called <code>read_data.r</code> to do this. </li>
   <li> <em>Computing derived attributes.</em>  For simplicity, in the examples below, we omit this step, but it is usually one of the most important.   </li>
   <li> <em>Building the model.</em>  In the examples below, we will use a script called <code>build_model.r</code> to do this. </li>
  <li> Validate the model.  In the examples below, we will use a script called <code>validate_model.r</code> to do this. </li>
</ol>
<p />
<p />
<h3><a name="Example_Forest_Cover_Data"></a> Example -  Forest Cover Data </h3>
<p />
We next look a slighly more complicated example - computing a classification tree on file with about 580,000 data records and 54 attributes that can be used to classify 7 types of forest cover.
<p />
This data is from a study of Jock A. Blackard from Colorado State University and is available from the UCI Data Archive. 
<p />
<p />
To obtain the data files, execute following commands on the controlling node:
<p />
<p />
<pre class="programlisting">
$ <userinput>cd ~/</userinput>
$ <userinput>mkdir data</userinput>
$ <userinput>cd data</userinput>
$ <userinput>wget http://angle.ncdm.uic.edu/globus/forest-cover-full.txt</userinput>
$ <userinput>wget http://angle.ncdm.uic.edu/globus/forest-cover.txt</userinput>
$ <userinput>wget http://angle.ncdm.uic.edu/globus/forest-cover-workshop1.lac.uic.edu.txt</userinput>
$ <userinput>wget http://angle.ncdm.uic.edu/globus/forest-cover-workshop2.txt</userinput>
$ <userinput>wget http://angle.ncdm.uic.edu/globus/forest-cover-workshop3.txt</userinput>
$ <userinput>wget http://angle.ncdm.uic.edu/globus/forest-cover-workshop4.txt</userinput>
$ <userinput>cd ~/</userinput>
</pre>
<p />
<p />
Here is the R program to read the data: 
<p />
<h3><a name="analysis_read_data_r"></a> <code><b>~/analysis/read_data.r</b></code> </h3>
<p />
<pre class="programlisting">
a.data.file &lt;- "data/forest-cover.txt"

a.col &lt;- list(elevation=0,
  aspect=0,
  slope=0,
  h.hydrology=0,
  v.hydrology=0,
  h.roadways=0,
  shade.0900=0,
  shade.1200=0,
  shade.1500=0,
  h.fire=0,
  wilderness.1=0,
  wilderness.2=0,
  wilderness.3=0,
  wilderness.4=0,
  soil.01=0,
  soil.02=0,
  soil.03=0,
  soil.04=0,
  soil.05=0,
  soil.06=0,
  soil.07=0,
  soil.08=0,
  soil.09=0,
  soil.10=0,
  soil.11=0,
  soil.12=0,
  soil.13=0,
  soil.14=0,
  soil.15=0,
  soil.16=0,
  soil.17=0,
  soil.18=0,
  soil.19=0,
  soil.20=0,
  soil.21=0,
  soil.22=0,
  soil.23=0,
  soil.24=0,
  soil.25=0,
  soil.26=0,
  soil.27=0,
  soil.28=0,
  soil.29=0,
  soil.30=0,
  soil.31=0,
  soil.32=0,
  soil.33=0,
  soil.34=0,
  soil.35=0,
  soil.36=0,
  soil.37=0,
  soil.38=0,
  soil.39=0,
  soil.40=0,
  cover=0)

a.raw &lt;- scan(file=a.data.file, what=a.col, skip=1, sep=',')
a.data &lt;- as.data.frame(a.raw)
</pre>
<p />
<p />
Here is how to start R and to invoke this R script.  Note that we have divided the data into four segments. This reads only the first segment of data.
<p />
<p />
<pre class="screen">
train99@workshop1.lac.uic.edu:~$ <userinput>R</userinput>

R version 2.4.1 (2006-12-18)

<em>[etc.]</em>

train99@workshop1.lac.uic.edu:~$ <userinput>source('~/analysis/read_data.r')</userinput>
Read 145252 records

> <userinput>summary(a.data)</userinput>
   elevation        aspect          slope        h.hydrology    
 Min.   :1863   Min.   :  0.0   Min.   : 0.00   Min.   :   0.0  
 1st Qu.:2747   1st Qu.: 54.0   1st Qu.: 7.00   1st Qu.:  95.0  
 Median :2909   Median :108.0   Median :11.00   Median : 212.0  
 Mean   :2874   Mean   :141.1   Mean   :11.93   Mean   : 251.7  
 3rd Qu.:3004   3rd Qu.:216.0   3rd Qu.:15.00   3rd Qu.: 362.0  
 Max.   :3849   Max.   :360.0   Max.   :61.00   Max.   :1343.0  
  v.hydrology        h.roadways     shade.0900      shade.1200   
 Min.   :-146.00   Min.   :   0   Min.   :  0.0   Min.   : 99.0  
 1st Qu.:   7.00   1st Qu.:1842   1st Qu.:207.0   1st Qu.:216.0  
 Median :  23.00   Median :3416   Median :222.0   Median :226.0  
 Mean   :  34.54   Mean   :3311   Mean   :217.4   Mean   :224.9  
 3rd Qu.:  51.00   3rd Qu.:4671   3rd Qu.:232.0   3rd Qu.:236.0  
 Max.   : 554.00   Max.   :7117   Max.   :254.0   Max.   :254.0  

[etc.] 

</pre>
<p />
<p />
Here is a simple R script called <code>~/analysis/build_model.r</code> to build a classification tree using some of the variables to get started. 
<p />
<pre class="programlisting">
a.formula &lt;- y.cover ~ elevation + aspect + slope + 
  h.hydrology + v.hydrology + h.roadways + 
  shade.0900 + shade.1200 + shade.1500 + h.fire +
  wilderness.1 +  wilderness.2 + wilderness.3 +  wilderness.4

a.tree.method &lt;- 'class'
a.tree.depth &lt;- 5

m1 &lt;- rpart(formula = a.formula, data = a.data.tr, 
  method=a.tree.method, control=rpart.control(cp=0, maxdepth=a.tree.depth))

# summary(m1)
# plot(m1)
# text(m1, use.n=TRUE)

p1 &lt;- pmml(m1)
saveXML(p1, file="models/forest-cover.pmml")
</pre>
<p />
<p />
Next, we run the following R script called <code>~/analysis/go.r</code> to split the data into training and validation sets and to invoke the <code>build_model.r</code> function. 
<p />
<pre class="programlisting">
library(rpart)
library(pmml)

a.data.file &lt;- "data/forest-cover.txt"
source('analysis/read_data.r')

a.data[, 'y.cover'] &lt;- factor(a.data[, 'cover'])

# determine number of records in training and valiation data sets
control.tr &lt;- 100000
control.vr &lt;- 40000

# Set training and validation sets
a.data.tr &lt;- a.data[1:control.tr,]
vs &lt;- control.tr+1
ve &lt;- control.tr + control.vr
a.data.validate &lt;- a.data[vs:ve,]

source('analysis/build_model.r')
</pre>
<p />
Here is the result of running the R script <code>go.r</code>.  
<p />
<pre class="screen">
$ <userinput>source('~/analysis/go.r')</userinput>

Loading required package: XML
Call:
rpart(formula = a.formula, data = a.data.tr, method = a.tree.method, 
    control = rpart.control(cp = 0, maxdepth = a.tree.depth))
  n= 100000 

             CP nsplit rel error    xerror        xstd
1  0.1938103402      0 1.0000000 1.0000000 0.004480635
2  0.0430088123      1 0.8061897 0.8065506 0.004213390
3  0.0423170622      2 0.7631808 0.7520828 0.004118668
4  0.0346476586      3 0.7208638 0.7247135 0.004067487
5  0.0343468977      4 0.6862161 0.7038407 0.004026768
6  0.0270083311      5 0.6518692 0.6527715 0.003920677
7  0.0121507414      6 0.6248609 0.6249812 0.003858883
8  0.0096243496      9 0.5839875 0.5975819 0.003794982
9  0.0081806972     10 0.5743631 0.5794159 0.003750912
10 0.0080002406     11 0.5661824 0.5761376 0.003742809
11 0.0065565882     12 0.5581822 0.5675058 0.003721254
12 0.0056543054     13 0.5516256 0.5603778 0.003703207
13 0.0047520226     15 0.5403170 0.5488887 0.003673641
14 0.0016241090     16 0.5355650 0.5436254 0.003659896
15 0.0011729676     17 0.5339409 0.5421817 0.003656104
16 0.0003759512     18 0.5327679 0.5421216 0.003655946
17 0.0003609131     20 0.5320160 0.5419712 0.003655550
18 0.0002706848     21 0.5316551 0.5419110 0.003655392
19 0.0000000000     23 0.5311137 0.5417607 0.003654996

Node number 1: 100000 observations,    complexity param=0.1938103
  predicted class=2  expected loss=0.33249
    class counts: 22027 66751  2160  2160  2582  2160  2160
   probabilities: 0.220 0.668 0.022 0.022 0.026 0.022 0.022 
  left son=2 (86939 obs) right son=3 (13061 obs)
  Primary splits:
      elevation    &lt; 3077.5 to the left,  improve=7006.051, (0 missing)
      wilderness.1 &lt; 0.5    to the right, improve=5918.671, (0 missing)
      wilderness.4 &lt; 0.5    to the left,  improve=3943.152, (0 missing)
      wilderness.3 &lt; 0.5    to the left,  improve=2545.846, (0 missing)
      h.fire       &lt; 1557.5 to the right, improve=2157.961, (0 missing)
  Surrogate splits:
      wilderness.2 &lt; 0.5    to the left,  agree=0.874, adj=0.036, (0 split)
      h.roadways   &lt; 6811.5 to the left,  agree=0.871, adj=0.012, (0 split)
      h.hydrology  &lt; 965    to the left,  agree=0.870, adj=0.008, (0 split)
      v.hydrology  &lt; 259.5  to the left,  agree=0.870, adj=0.006, (0 split)

<em>[etc.]</em>
</pre>
<p />
<p />
This produces the following PMML model: 
<p />
<p />
<pre class="programlisting">
&lt;?xml version="1.0"?&gt;
&lt;PMML version="3.1" xmlns="http://www.dmg.org/PMML-3_1" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"&gt;
 &lt;DataDictionary numderOfFields="15"&gt;
  &lt;DataField name="y.cover" optype="categorical" dataType="string"&gt;
   &lt;Value value="1"/&gt;
   &lt;Value value="2"/&gt;
   &lt;Value value="3"/&gt;
   &lt;Value value="4"/&gt;
   &lt;Value value="5"/&gt;
   &lt;Value value="6"/&gt;
   &lt;Value value="7"/&gt;
  &lt;/DataField&gt;
  &lt;DataField name="elevation" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="aspect" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="slope" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="h.hydrology" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="v.hydrology" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="h.roadways" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="shade.0900" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="shade.1200" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="shade.1500" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="h.fire" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="wilderness.1" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="wilderness.2" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="wilderness.3" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="wilderness.4" optype="continuous" dataType="double"/&gt;
 &lt;/DataDictionary&gt;
 &lt;TreeModel modelName="RPart_Model" functionName="classification"
  algorithmName="rpart" splitCharacteristic="binarySplit"&gt;
  &lt;MiningSchema&gt;
   &lt;MiningField name="y.cover" usageType="predicted"/&gt;
   &lt;MiningField name="elevation" usageType="active"/&gt;
   &lt;MiningField name="aspect" usageType="active"/&gt;
   &lt;MiningField name="slope" usageType="active"/&gt;
   &lt;MiningField name="h.hydrology" usageType="active"/&gt;
   &lt;MiningField name="v.hydrology" usageType="active"/&gt;
   &lt;MiningField name="h.roadways" usageType="active"/&gt;
   &lt;MiningField name="shade.0900" usageType="active"/&gt;
   &lt;MiningField name="shade.1200" usageType="active"/&gt;
   &lt;MiningField name="shade.1500" usageType="active"/&gt;
   &lt;MiningField name="h.fire" usageType="active"/&gt;
   &lt;MiningField name="wilderness.1" usageType="active"/&gt;
   &lt;MiningField name="wilderness.2" usageType="active"/&gt;
   &lt;MiningField name="wilderness.3" usageType="active"/&gt;
   &lt;MiningField name="wilderness.4" usageType="active"/&gt;
  &lt;/MiningSchema&gt;
  &lt;Node score="2" recordCount="50000"&gt;
   &lt;True/&gt;
   &lt;Node score="2" recordCount="29928"&gt;
    &lt;SimplePredicate field="h.fire" operator="greaterOrEqual" value="2862"/&gt;
    &lt;Node score="2" recordCount="28917"&gt;
     &lt;SimplePredicate field="elevation" operator="lessThan" value="3094"/&gt;
     &lt;Node score="2" recordCount="5520"&gt;
      &lt;SimplePredicate field="v.hydrology" operator="greaterOrEqual" value="62.5"/&gt;
      &lt;Node score="2" recordCount="2660"&gt;
       &lt;SimplePredicate field="h.roadways" operator="lessThan" value="5188"/&gt;
       &lt;Node score="1" recordCount="1598"&gt;
        &lt;SimplePredicate field="shade.0900" operator="lessThan" value="224.5"/&gt;
       &lt;/Node&gt;
       &lt;Node score="2" recordCount="1062"&gt;
        &lt;SimplePredicate field="shade.0900" operator="greaterOrEqual" value="224.5"/&gt;
       &lt;/Node&gt;
      &lt;/Node&gt;
      &lt;Node score="2" recordCount="2860"&gt;
       &lt;SimplePredicate field="h.roadways" operator="greaterOrEqual" value="5188"/&gt;
       &lt;Node score="1" recordCount="34"&gt;
        &lt;SimplePredicate field="h.fire" operator="lessThan" value="3030"/&gt;
       &lt;/Node&gt;
       &lt;Node score="2" recordCount="2826"&gt;
        &lt;SimplePredicate field="h.fire" operator="greaterOrEqual" value="3030"/&gt;
       &lt;/Node&gt;
      &lt;/Node&gt;
     &lt;/Node&gt;
     &lt;Node score="2" recordCount="23397"&gt;

    [etc.]

      &lt;Node score="6" recordCount="2867"&gt;
       &lt;SimplePredicate field="elevation" operator="greaterOrEqual" value="2370"/&gt;
       &lt;Node score="2" recordCount="220"&gt;
        &lt;SimplePredicate field="wilderness.1" operator="greaterOrEqual" value="0.5"/&gt;
       &lt;/Node&gt;
       &lt;Node score="6" recordCount="2647"&gt;
        &lt;SimplePredicate field="wilderness.1" operator="lessThan" value="0.5"/&gt;
       &lt;/Node&gt;
      &lt;/Node&gt;
     &lt;/Node&gt;
    &lt;/Node&gt;
   &lt;/Node&gt;
  &lt;/Node&gt;
 &lt;/TreeModel&gt;
&lt;/PMML&gt;
</pre>
<p />
<p />
Here is a R program called <code>~/analysis/validate_model.r</code> to validate models, which can be run directly from the command line.  This script could be executed by including the line <code>source('analysis/validate_model.r')</code> in the <code>go.r</code> script above.  
<p />
<pre class="programlisting">
a.report &lt;- "reports/report-validate.txt"
a.factors &lt;- c(1, 2, 3, 4, 5, 6, 7)
a.factors.n &lt;- length(a.factors)

a.data.validate[, 'actual.cover'] &lt;-  factor(a.data.validate[, 'cover'])
y &lt;- predict(m1, newdata=a.data.validate, type='class')
a.data.validate[, 'predicted.cover'] &lt;- y

b.count &lt;- matrix(0, ncol = a.factors.n, nrow = a.factors.n)
b.ratio &lt;- matrix(0, ncol = a.factors.n, nrow = a.factors.n)

for (jj in 1:a.factors.n) {
 jj.f &lt;- a.factors[jj]
 actual.f &lt;- a.data.validate[ a.data.validate$actual.cover == jj.f,
'predicted.cover']
for (ii in 1:a.factors.n) {
  p &lt;- (jj-1)*a.factors.n + ii
  b.count[p] &lt;- length(actual.f[actual.f == a.factors[ii]])
  b.ratio[p] &lt;- (b.count[p] / length(actual.f)) * 100
  }
}
 
cat('\nConfusion Matrix (Counts)\n\n', file = a.report, append=T)
for (jj in 1:a.factors.n) {
 m.start &lt;- (jj-1)*a.factors.n + 1
 m.end &lt;- (jj-1)*a.factors.n + a.factors.n
 rline &lt;- sprintf("%i\t", b.count[m.start:m.end])
 cat(rline, file = a.report, append=T)
 cat('\n', file = a.report, append=T)
}
 
cat('\nConfusion Matrix (Percent)\n\n', file = a.report, append=T)
for (jj in 1:a.factors.n) {
 m.start &lt;- (jj-1)*a.factors.n + 1
 m.end &lt;- (jj-1)*a.factors.n + a.factors.n
 rline &lt;- sprintf("%.1f\t", b.ratio[m.start:m.end])
 cat(rline, file = a.report, append=T)
 cat('\n', file = a.report, append=T)
}
</pre>
<p />
<p />
Running the <code>validate_model.r</code> R script (after go.r) produces the following confusion matrix (stored in <code>reports/report-validate.txt</code>), which clearly shows that this is not a very good model. 
<p />
<pre class="screen">
$ <userinput>source('~/analysis/validate_model.r')</userinput>

Confusion Matrix (Counts)

11239	 10989	 0	 0	 0	 0	 443	
18280	 58387	 0	 0	 9	 0	 0	
0	 0	 0	 0	 0	 0	 0	
0	 0	 0	 0	 0	 0	 0	
123	 530	 0	 0	 0	 0	 0	
0	 0	 0	 0	 0	 0	 0	
0	 0	 0	 0	 0	 0	 0	

Confusion Matrix (Percent)

49.6	 48.5	 0.0	 0.0	 0.0	 0.0	 2.0	
23.8	 76.1	 0.0	 0.0	 0.0	 0.0	 0.0	
NaN	 NaN	 NaN	 NaN	 NaN	 NaN	 NaN	
NaN	 NaN	 NaN	 NaN	 NaN	 NaN	 NaN	
18.8	 81.2	 0.0	 0.0	 0.0	 0.0	 0.0	
NaN	 NaN	 NaN	 NaN	 NaN	 NaN	 NaN	
NaN	 NaN	 NaN	 NaN	 NaN	 NaN	 NaN	
</pre>
<p />
We can easily see what is going on by looking at the  distribution of the factors in the training and validation data: 
<p />
<p />
<pre class="screen">
$ <userinput>summary(a.data.tr$y.cover)</userinput>
    1     2     3     4     5     6     7 
10151 28794  2160  2160  2415  2160  2160 
$ <userinput>summary(a.data.validate$y.cover)</userinput>
    1     2     3     4     5     6     7 
22671 76676     0     0   653     0     0 
</pre>
<p />
The validation set doesn't have instances of data from all the classes that are present. 
<p />
To improve the model, we need to define better features, more carefully tune the parameters in the tree, and to make sure that each training and validation set reflects the overall class distribution.  In addition, we need to define a hold out validation set, that also reflects the class distribution of the entire data set.  This hold out validation will be used to validate the ensemble model we will be building. 
<p />
<p />
<!-- <strong>*</strong>  Comments plugin to create comments table for section   <strong>*</strong>    -->
<span class="educationWebAddComment">ADD A COMMENT</span>
<span id="twid_3show" class="twistyMakeVisible">
       <a href="#" class="twistyTrigger"><em><strong>Show...</strong></em></a>
     </span>
     <span id="twid_3hide" class="twistyHidden">
       <a href="#" class="twistyTrigger"><em><strong>Hide</strong></em></a>
     </span>
     <div id="twid_3toggle" class="twistyMakeHidden">
<p />
<p />
<table cellspacing="0" cellpadding="0" border="0" class="twikinetWrapperTable" rules="none">
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableT twikinetWrapperTableTL"></td>
<td class="twikinetWrapperTableT twikinetWrapperTableTR"></td>
</tr>
<tr class="twikinetWrapperTableRow">
<td colspan="2" class="twikinetWrapperTableMain">
<table cellspacing="0" id="table3" cellpadding="0" class="twikiTable" rules="cols" border="1">
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<th bgcolor="#d8dde4" align="center" valign="top" class="twikiTableCol0 twikiFirstCol twikiLast"> <a rel="nofollow" href="/bin/view/Education/DataMiningTutorial?cover=print;sortcol=0;table=3;up=0#sorted_table" title="Sort by this column"><font color="#252b37">COMMENT</font></a> </th>
			<th bgcolor="#d8dde4" align="center" valign="top" class="twikiTableCol1 twikiLast"> <a rel="nofollow" href="/bin/view/Education/DataMiningTutorial?cover=print;sortcol=1;table=3;up=0#sorted_table" title="Sort by this column"><font color="#252b37">NAME</font></a> </th>
			<th bgcolor="#d8dde4" align="center" valign="top" class="twikiTableCol2 twikiLastCol twikiLast"> <a rel="nofollow" href="/bin/view/Education/DataMiningTutorial?cover=print;sortcol=2;table=3;up=0#sorted_table" title="Sort by this column"><font color="#252b37">DATE</font></a> </th>
		</tr></table>
</td>
</tr>
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableB twikinetWrapperTableBL"></td>
<td class="twikinetWrapperTableB twikinetWrapperTableBR"></td>
</tr>
</table>
<form method="post" action="https://twiki.opensciencegrid.org/bin/save/Education/DataMiningTutorial" enctype="multipart/form-data" name="tableappend2" id="tableappend2">
<p />
<div class="commentPlugin commentPluginPromptBox">
<table><tr valign="middle"><td><textarea  rows="3" cols="70" name="comment" wrap="soft" onfocus="if(this.value=='')this.value=''" onblur="if(this.value=='')this.value=''"></textarea></td><td><input  type="submit" value="Add comment" /></td></tr></table>
</div><!--/commentPlugin-->
<p />
<input type="hidden" name="comment_action" value="save"  />
<input type="hidden" name="comment_type" value="tableappend"  />
<input type="hidden" name="comment_index" value="2"  /></form>
<p />
</div>
<!-- <strong>*</strong>  End Comment                                    <strong>*********</strong>    -->
<p />
<p />
<p />
<p />
<p />
<a name="Using R and Globus to Compute CART Trees"></a>
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Using_R_and_Globus_to_Compute_CA"></a> Using R and Globus to Compute CART Trees </span></h2>
<p />
The pattern here is the same as we used for computing k-means clusters.  We need to do the following steps: 
<p /> <ol>
<li> <em>Set up. </em>  <ol>
<li type="a"> Create the requried directories on each node: data, analysis, models, and reports.
</li> <li type="a"> Use Grid-FTP to move the required R scripts to each processor.  We will be using four R scripts: <code>go.r</code>, <code>read_data.r</code>, <code>build_model.r</code>, and <code>validate_model.r</code>.
</li></ol> 
</li> <li> <em>Partition the data.</em> Partition the data into several different data segments.
</li> <li> <em>Scatter the data.</em> Use Grid-FTP to move each data segment to the appropriate processor. 
</li> <li> <em>Build the models.</em>  Use GRAM to invoke R using input from the  <code>go.r</code> script on each processor. 
</li> <li> <em>Gather the models.</em>  Use Grid-FTP to gather each of the resulting PMML files.
</li> <li> <em>Gather and analyze the reports.</em> Use Grid-FTP to gather each of the resulting report files.
</li> <li> <em>Build and ensemble model.</em> Build an ensemble model by assembling each of the PMML files.
</li> <li> <em>Validate the ensemble model.</em> Evaluate the ensemble model on a hold out set.
</li></ol> 
<p />
Here is an R script that can be used to compute CART trees using R and and Globus for a single compute node.  In the Assignment 2 below, you will modify this so that it can work using multiple compute nodes.  
<p />
Before running the script, prepare a project directory:
<p />
<pre class="programlisting">
$ <userinput>cd ~/</userinput>
$ <userinput>mkdir forest-cover/</userinput>
$ <userinput>tar cf - data analysis | tar xvf - -C ~/forest-cover/</userinput>
$ <userinput>mv forest-cover/data forest-cover/control_data</userinput>
$ <userinput>mv forest-cover/analysis forest-cover/control_analysis</userinput>
</pre>
<p />
<h3><a name="run_cart_globus_py"></a> <code><b>run-cart-globus.py</b></code> </h3>
<p />
<pre class="programlisting">
#!/usr/bin/env python
from os import system

nodes = ['workshop4.lac.uic.edu']
home_dir = '/home/train99/'
project = 'forest-cover'
rfiles = ["go.r", "read_data.r", "build_model.r", "validate_model.r"]

node = nodes[0]
node_name  = node.split('.')[0]

# prepare remote directories
cmds = "globus-job-run " + node + " /bin/mkdir -p " + home_dir + "/data";
print "*** running: " + cmds + "\n"
system(cmds)

cmds = "globus-job-run " + node + " /bin/mkdir -p " + home_dir + "/analysis";
print "*** running: " + cmds + "\n"
system(cmds)

cmds = "globus-job-run " + node + " /bin/mkdir -p " + home_dir + "/models";
print "*** running: " + cmds + "\n"
system(cmds)

cmds = "globus-job-run " + node + " /bin/mkdir -p " + home_dir + "/collect";
print "*** running: " + cmds + "\n"
system(cmds)

# copy local data file to remote machine
cmds = "globus-url-copy file://" + home_dir + project + "/" + "control_data/"
cmds = cmds + project + "-" + node_name + ".txt "
cmds = cmds + "gsiftp://" + node + home_dir + "data/" + project + ".txt"
print "*** running: " + cmds + "\n"
system(cmds)

# copy r script to compute clusters to remote machine
for rfile in rfiles:
  cmds = "globus-url-copy file://" + home_dir + project + "/"
  cmds = cmds + "control_analysis/" +  rfile + " "
  cmds = cmds + "gsiftp://" + node + home_dir + "analysis/" + rfile
  print "*** running: " + cmds + "\n"
  system(cmds)

# invoke R script on remote machine
cmds = "globus-job-run " + node + " "
cmds = cmds + " /bin/sh -c '/usr/bin/R &lt " + home_dir + "/analysis/go.r --no-save' "
print "running: " + cmds + "\n"
system(cmds)

# collect PMML file
cmds = "globus-url-copy gsiftp://" + node + home_dir + "models/" + project + ".pmml "
cmds = cmds + "file://" + home_dir + "collect/" + project + "-" + node_name + ".pmml"
print "running: " + cmds + "\n"
system(cmds)
</pre>
<p />
The script works by taking the data in <code>forest-cover/control_data</code> and the scripts in <code>forest-cover/control_analysis</code> and copying them, using <span class="twikiNewLink">GridFTP<a href="/bin/edit/Education/GridFTP?topicparent=Education.DataMiningTutorial" rel="nofollow" title="GridFTP (this topic does not yet exist; you can create it)">?</a></span>, to the appropriate compute node.  
<p />
on      This script processes data sequentially for demonstrations purposes. Globus jobs can be submitted in parallel and their status can be monitored until results are ready for retrieval.
<p />
<pre class="screen">
<userinput>train99@workshop1.lac.uic.edu:~$ ls -R forest-cover/ <userinput>

forest-cover/:
control_analysis  control_data

forest-cover/control_analysis:
build_model.r  go.r  read_data.r  validate_model.r

forest-cover/control_data:
forest-cover.txt            forest-cover-workshop2.txt  forest-cover-workshop4.txt
forest-cover-workshop1.lac.uic.edu.txt  forest-cover-workshop3.txt

<em>[etc.]</em>
</pre>
<p />
The Python script then uses globus-job-run to invoke R on the compute node using the <code>go.r</code> R script.  The PMML model is then collected using Grid-FTP to the collect directory where it can be assembled into an ensemble model. 
<p />
<p />
<pre class="screen">
train99@workshop1.lac.uic.edu:~$ <userinput>ls collect</userinput>
forest-cover-workshop1.lac.uic.edu.pmml
<em>[etc.]</em>
</pre>
<p />
<p />
<p />
<a name="Assignment 2"></a>
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Assignment_2"></a> Assignment 2 </span></h2>
<p />
This assignment has three parts: 
<p /> <ol>
<li> Generalize the Python code above that builds CART trees using Globus to work with several compute nodes.
</li> <li> Expand the Python code above that builds CART trees using Globus to also include the <code>validate_model.r</code> scripts.  Write the confusion matrix and related information to the <code>reports</code> directory and then gather them them into the <code>collect</code> directory.
</li> <li> Write a function that given several PMML functions, produces an ensemble model.
</li></ol> 
<p />
<p />
<a name="Hints"></a>
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Hints"></a> Hints </span></h2>
<p />
Here are some hints to keep in mind. 
<p /> <ul>
<li> Make sure that your analysis program (for example, your R script) works on your login machine first.
</li> <li> Make sure Globus script works on your login machine first, before trying it on another machine.
</li> <li> Make sure you have created all the proper directories required.
</li> <li> Make sure all your files have the proper permissions.
</li></ul> 
<p />
<p />
<p />
<!-- <strong>*</strong>  Comments plugin to create comments table for section   <strong>*</strong>    -->
<span class="educationWebAddComment">ADD A COMMENT</span>
<span id="twid_4show" class="twistyMakeVisible">
       <a href="#" class="twistyTrigger"><em><strong>Show...</strong></em></a>
     </span>
     <span id="twid_4hide" class="twistyHidden">
       <a href="#" class="twistyTrigger"><em><strong>Hide</strong></em></a>
     </span>
     <div id="twid_4toggle" class="twistyMakeHidden">
<p />
<p />
<table cellspacing="0" cellpadding="0" border="0" class="twikinetWrapperTable" rules="none">
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableT twikinetWrapperTableTL"></td>
<td class="twikinetWrapperTableT twikinetWrapperTableTR"></td>
</tr>
<tr class="twikinetWrapperTableRow">
<td colspan="2" class="twikinetWrapperTableMain">
<table cellspacing="0" id="table4" cellpadding="0" class="twikiTable" rules="cols" border="1">
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<th bgcolor="#d8dde4" align="center" valign="top" class="twikiTableCol0 twikiFirstCol twikiLast"> <a rel="nofollow" href="/bin/view/Education/DataMiningTutorial?cover=print;sortcol=0;table=4;up=0#sorted_table" title="Sort by this column"><font color="#252b37">COMMENT</font></a> </th>
			<th bgcolor="#d8dde4" align="center" valign="top" class="twikiTableCol1 twikiLast"> <a rel="nofollow" href="/bin/view/Education/DataMiningTutorial?cover=print;sortcol=1;table=4;up=0#sorted_table" title="Sort by this column"><font color="#252b37">NAME</font></a> </th>
			<th bgcolor="#d8dde4" align="center" valign="top" class="twikiTableCol2 twikiLastCol twikiLast"> <a rel="nofollow" href="/bin/view/Education/DataMiningTutorial?cover=print;sortcol=2;table=4;up=0#sorted_table" title="Sort by this column"><font color="#252b37">DATE</font></a> </th>
		</tr></table>
</td>
</tr>
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableB twikinetWrapperTableBL"></td>
<td class="twikinetWrapperTableB twikinetWrapperTableBR"></td>
</tr>
</table>
<form method="post" action="https://twiki.opensciencegrid.org/bin/save/Education/DataMiningTutorial" enctype="multipart/form-data" name="tableappend3" id="tableappend3">
<p />
<div class="commentPlugin commentPluginPromptBox">
<table><tr valign="middle"><td><textarea  rows="3" cols="70" name="comment" wrap="soft" onfocus="if(this.value=='')this.value=''" onblur="if(this.value=='')this.value=''"></textarea></td><td><input  type="submit" value="Add comment" /></td></tr></table>
</div><!--/commentPlugin-->
<p />
<input type="hidden" name="comment_action" value="save"  />
<input type="hidden" name="comment_type" value="tableappend"  />
<input type="hidden" name="comment_index" value="3"  /></form>
<p />
</div>
<!-- <strong>*</strong>  End Comment                                    <strong>*********</strong>    -->
<p />
<p />
<p />
<p />
<p />
<p />
<!--                                                                             <ul>
 <li>
 <ul>
<li> Set LOGINHOST = workshop1.lac.uic.edu
</li> <li> Set LOGINIP = 131.193.181.56
</li> <li> Set GRIDHOST = tg-login.sdsc.teragrid.org
</li> <li> Set OTHERHOST = workshop2.lac.uic.edu
</li> <li> Set CERTSUBJECT = /O=Grid/OU=OSG/CN=Training User 99
</li> <li> Set LOGINNAME = train99
</li> <li> Set HOMEDIR = /home/train99
</li></ul> 
</li></ul> 
<p />
<p />
<a href="/bin/view/Main/MichaelWilde" class="twikiLink">MichaelWilde</a> - 22 Mar 2007
<a href="/bin/view/Main/ForrestChristian" class="twikiLink">ForrestChristian</a> - 24 Mar 2007 - Added VARIABLES
<a href="/bin/view/Main/ForrestChristian" class="twikiLink">ForrestChristian</a> - 25 Mar 2007 - Changed with Michal and Bob's new materials
--></div><!-- /patternTopic-->
<p />
<p />
</div><!-- /patternContent-->
<hr />
This topic: Education<span class='twikiSeparator'>&nbsp;&gt;&nbsp;</span><a href="/bin/view/Education/GridWorkshops" class="twikiLink">GridWorkshops</a> &gt; <a href="/bin/view/Education/MidwestGridWorkshop" class="twikiLink">MidwestGridWorkshop</a> &gt; <a href="/bin/view/Education/MidwestSyllabus" class="twikiLink">MidwestSyllabus</a><span class='twikiSeparator'>&nbsp;&gt;&nbsp;</span>DataMiningTutorial</span> <br />    
Topic revision: r6 - 03 May 2007 - 21:47:34 - <span class="twikiNewLink">ForrestChristian<a href="/bin/edit/Education/ForrestChristian?topicparent=Education.DataMiningTutorial" rel="nofollow" title="ForrestChristian (this topic does not yet exist; you can create it)">?</a></span>
</div><!-- /patternMainContents-->
</div><!-- /patternMain-->
</div><!-- /patternFloatWrap-->
<div class="clear">&nbsp;</div>
</div><!-- /patternOuter--><div id="patternBottomBar"><div id="patternBottomBarContents"><div id="twikinetBadge"><a href="http://www.twiki.net/"><img src="https://twiki.opensciencegrid.org/twiki/pub/TWiki/TWikiNetSkin/twiki-badge-88x31.gif" alt="TWIKI.NET" width="88" height="31" border="0" /></a></div><!--/twikinetBadge--><div id="patternWebBottomBar"><p>
<font size="-1">
TWiki |
<a href="https://ticket.grid.iu.edu/goc/twiki">Report Bugs</a> |
<a href="https://twiki.grid.iu.edu/bin/view/Operations/IUPrivacyPolicy">Privacy Policy</a>
</p>
<p>
<font size="-2">
<span class="twikiRight"> <a href="http://twiki.org/"><img src="/twiki/pub/TWiki/TWikiLogos/T-logo-80x15.gif" alt="This site is powered by the TWiki collaboration platform" width="80" height="15" title="This site is powered by the TWiki collaboration platform" border="0" /></a></span>Copyright by the contributing authors. All material on this collaboration platform is the property of the contributing authors..
</font>
</p></div><!--/patternWebBottomBar--></div><!-- /patternBottomBarContents--></div><!-- /patternBottomBar-->
</div><!-- /patternPage-->
</div><!-- /patternPageShadow-->
</div><!-- /patternScreen-->
</body></html>
<p />