---+Exercises for Lecture 4:  Grid Data Management

%TOC%


---++Getting set up

Check that you have a valid proxy.

&lt;pre&gt;
gridlab$ grid-proxy-init
Your identity: /C=US/O=Globus Alliance/OU=User/CN=10bd8f410f6.5f0086b4
Enter GRID pass phrase for this identity:
Creating proxy ................................................ Done
Your proxy is valid until: Thu Jun 22 22:15:25 2006
&lt;/pre&gt;

Now, make a working directory for this exercise. For the rest of this exercise, all your work should be done in there.

&lt;pre&gt;
gridlab$ mkdir dataex
gridlab$ cd dataex
&lt;/pre&gt;

Next create some files of different sizes, to use for exercises. Each file should have a unique name, so use your name or something similar below. For example, do the following:

&lt;pre&gt; 
dd if=/dev/zero of=./smallfile-train30 bs=1M count=10
dd if=/dev/zero of=./mediumfile-train30 bs=1M count=50
dd if=/dev/zero of=./largefile-train30 bs=1M count=200
$ ls -sh
total 261M
201M largefile-train30   51M mediumfile-train30   11M smallfile-train30
&lt;/pre&gt;


---++Moving files with !GridFTP

---+++A Simple Transfer

Use globus-url-copy to move your small file from your home directory on gridlab1 to your home directory on one of the other gridlab machines (you have a choice of gridlab2, gridlab3 or gridlab4):

&lt;pre&gt; 
$ globus-url-copy file:///home/train30/dataex/smallfile-train30 gsiftp://gridlab2.phys.utb.edu/home/train30/ex1
echo $?
0
&lt;/pre&gt;

The echo $? checks to see what the return value was for the previous command. If you see a zero (0) then globus-url-copy succeeded.

A different number indicates a problem. In that case you should also see an error message.

---+++Measuring transfer speed
See how fast the file transfer is happening by using the -vb flag when copying the large file. Since this is a transfer over a local network that should probably not be too busy it should be fairly quick:

&lt;pre&gt;
$ globus-url-copy -vb file:///home/train30/dataex/largefile-train30 gsiftp://gridlab2.phys.utb.edu/home/train30/ex1
Source: file:///home/train30/dataex/
Dest:   gsiftp://gridlab2.phys.utb.edu/home/train30/
  largefile-train30  -&gt;  ex1
    207618048 bytes         8.81 MB/sec avg         9.09 MB/sec inst
&lt;/pre&gt;

---+++Transfers to a remote site
Now try transferring a file to a remote site. Use the small file, because you will be sharing the off-island link with everyone else. This example uses skynet-login as the remote site. However, there are various other sites that you could use - the instructors can tell you.

First you will need some scratch space on the remote system. You could use your home directory, but in this case we will use the official scratch space. Use globusrun-ws to make a scratch directory:

&lt;pre&gt;gridlab$ globusrun-ws -s -submit -F skynet-login.isi.edu -Ft Fork -c /bin/mkdir /scratch/train30
Delegating user credentials...Done.
Submitting job...Done.
Job ID: uuid:d895c108-05a4-11db-b624-000feae0c5a8
Termination time: 06/28/2006 06:19 GMT
Current job state: Active
Current job state: CleanUp-Hold
Current job state: CleanUp
Current job state: Done
Destroying job...Done.
Cleaning up any delegated credentials...Done.
&lt;/pre&gt;

Now copy the file over to this directory:
&lt;pre&gt;
gridlab$ globus-url-copy -vb file:///home/train30/dataex/smallfile-train30 gsiftp://skynet-login.isi.edu/scratch/train30/ex1
Source: file:///home/train30/dataex/smallfile
Dest:   gsiftp://skynet-login.isi.edu/scratch/train30/
  largefile-train30  -&gt;  ex1
    208666624 bytes         1.41 MB/sec avg         1.43 MB/sec inst
&lt;/pre&gt;

You will probably find that the transfer rate is much lower than when copying to local machines.

You can try copying to other sites in addition to skynet. Remember that you might need to make a scratch directory on each one, and that the place for this will be different for each site.

---++URL formats

A quick reminder on URL formats: We&#39;ve seen two kind of URLs so far.

   * &lt;code&gt;file:///home/train30/dataex/largefile&lt;/code&gt; - this refers to a file called &lt;code&gt;largefile&lt;/code&gt; on the local file system, in directory &lt;code&gt;/home/train30/dataex/&lt;/code&gt;.

   * &lt;code&gt;gsiftp://skynet-login.isi.edu/scratch/train30/&lt;/code&gt; - this refers to a directory accessible via gsiftp on the host called &lt;code&gt;skynet-login.isi.edu&lt;/code&gt; in directory &lt;code&gt;/scratch/train30&lt;/code&gt;.


---++Parallel streams

Trying using 4 parallel data streams by adding the -p flag with an argument of 4:

First, we want to connect to the Teragrid, so from one of the gridlab machines:

gsissh tg-login.ncsa.teragrid.org

Now that you&#39;re on the Teragrid, use the dd commands you issued earlier in the exercise to create the small, medium, and large files to create those files in your home directory on the Teragrid site.

Now use the following globus-url-copy command to transfer the file from your location on the Teragrid to the site at ISI:

&lt;code&gt;globus-url-copy -p 4 -vb file:///home/ac/train30/dataex/smallfile-train30 gsiftp://skynet-login.isi.edu/scratch/train30/ex1&lt;/code&gt;

Experiment with transferring different file sizes and numbers of parallel streams, to both local and remote sites and see how the speed varies.

---++Third party transfers
Next try a third-party transfer. You do this by specifying two gsiftp: URLs instead of one gsiftp: and one file: URL.

globus-url-copy will control the transfers but data will *not* pass through. Instead, it will go directly between the source and destination machines.

Transfer a file between two remote sites, and see if it is faster than if you had transferred it to gridlab1 and then back out again.

Try to make up a command line for this yourself - you should use two gsiftp URLs, instead of a file url and a gsiftp URL.

---++Reliable File Transfer (RFT)

Next we&#39;ll use RFT, the reliable file transfer service, to transfer a block of files between two sites.

First, we need to create a transfer job file, which lists some RFT parameters and then all of the files to transfer. You can get an example from gridlab1:~benc/rft.xfr. Read through this and change the URLs at the end to copy your files.

This example lists three transfers. largefile will be transfered three times, once to gridlab2, once to gridlab3, once to gridlab4.

You can launch it as follows. The client will periodically output transfer status. You can watch jobs move from the pending state, to the Active state and then to the Finished state.

&lt;pre&gt;
$ cp ~train30/rft.xfr .
$ EDIT rft.xfr
$ rft -h gridlab1.phys.utb.edu -f ./rft.xfr 
Number of transfers in this request: 3
Subscribed for overall status
Termination time to set: 60 minutes

 Overall status of transfer:
Finished/Active/Failed/Retrying/Pending
0/1/0/0/2

 Overall status of transfer:
Finished/Active/Failed/Retrying/Pending
1/0/0/0/2

 Overall status of transfer:
Finished/Active/Failed/Retrying/Pending
1/1/0/0/1

 Overall status of transfer:
Finished/Active/Failed/Retrying/Pending
2/0/0/0/1

 Overall status of transfer:
Finished/Active/Failed/Retrying/Pending
2/1/0/0/0

 Overall status of transfer:
Finished/Active/Failed/Retrying/Pending
3/0/0/0/0
All Transfers are completed
&lt;/pre&gt; 

Initally all jobs start in the pending state, move to active state and then hopefully to finished state (but maybe fail, in which case they go to the failed state).

The transfer file has a number of options, documented in-line. You can experiment changing them. Interesting ones to try:
   * Add more URLs to transfer
   * Transfer between two remote sites
   * Use parallel streams
   * Increase the transfer concurrency

In particular you should check that you understand the difference between parallel streams (the number of streams used when transferring one file) and concurrency (the number of files that can be transferred at once).

---++Finding replicas with RLS

The above sections have dealt with moving data around, and always made the assumption that you knew where the files you wanted were located.

Next we will deal with the Replica Location Service, RLS.

---+++Check that we can connect to an RLS server.

&lt;pre&gt;
$ globus-rls-admin -p rls://gridlab1.phys.utb.edu
ping rls://gridlab1.phys.utb.edu: 0 seconds
&lt;/pre&gt;

---+++Querying an RLS server

First perform a simple query for an example logical filename that has been placed in the RLS by the instructors:

&lt;pre&gt;
$ globus-rls-cli rls://gridlab1.phys.utb.edu
rls&gt; query lrc lfn example
  example: gsiftp://gridlab1.phys.utb.edu/scratch/example
  example: gsiftp://gridlab3.phys.utb.edu/scratch/example
&lt;/pre&gt;

This queries for a logical filename &lt;code&gt;example&lt;/code&gt;. The results show that this file can be retrieved via either of two URLs (one in scratch space on gridlab1, and one in scratch space on gridlab3).

Now try querying for logical filename &lt;code&gt;another-example&lt;/code&gt;.

---+++Adding mappings to the RLS

You can also publish your own logical filename into the RLS, with mappings to physical files, using the &lt;code&gt;create&lt;/code&gt; command:

&lt;pre&gt;
rls&gt; create
Incomplete command: create &lt;lfn&gt; &lt;pfn&gt;

rls&gt; create train30-first-lfn gsiftp://gridlab1.phys.utb.edu/home/train30/dataex/largefile-train30
&lt;/pre&gt;

This creates an LFN called &lt;code&gt;train30-first-lfn&lt;/code&gt; and then adds a mapping to &lt;code&gt;gsiftp://home/train30/dataex/largefile-train30&lt;/code&gt;.

Note that this does *NOT* check that the gsiftp:// URL is valid; if you enter the wrong information here, then RLS will report the wrong information when you later query it.

&lt;pre&gt;
rls&gt; query lrc lfn train30-first-lfn
  train30-first-lfn: gsiftp://home/train30/dataex/largefile-train30
&lt;/pre&gt;

Now copy largefile to another place (on another gridlab machine or on one of the remote sites), and
register it into the RLS, with the same LFN. You will need to use the &lt;code&gt;add&lt;/code&gt; command instead of the &lt;code&gt;create&lt;/code&gt; command, because the LFN already exists and you just need to add a new mapping.

Get a neighbour to query the RLS for your logical filename, and see that the mappings you have made are public for everyone to see.

---+++Multiple RLS servers

---++++Other LRCs

So far, you have only been using the RLS server on gridlab1. There are servers running on all four of the gridlab machines.

Use &lt;code&gt;globus-rls-admin&lt;/code&gt; to ping the other three gridlab servers and check that they are online.

Then, connect to one of the other servers using &lt;code&gt;globus-rls-cli&lt;/code&gt; and query for the &lt;code&gt;example&lt;/code&gt; LFN that we used above. You should see that there are some other locations from which you can get the example file.

Try adding your own LFN into one of the other servers, using &lt;code&gt;globus-rls-cli&lt;/code&gt;

---++++RLIs

So far, you have interacted with the Local Replica Catalog on each installation. This is where LFNs and mappings are created.

RLS has another component, called a Replica Location Index. This gathers information from several LRCs, so that you can find LFN mappings from all of those LRCs in one place.

There is an RLI on gridlab1 that gathers information from all four gridlab LRCs.

You can query it like this:
&lt;pre&gt;
rls&gt; query rli lfn example
rls&gt; query rli lfn example
  example: rls://gridlab1.phys.utb.edu:39281
&lt;/pre&gt;

What comes back from the RLI is *not* a list of physical files. Instead, it is a list of LRCs that have some information about the requested LFN.

To find all the replicas, you need to query all of the listed LRCs in turn. In the above paste, only gridlab1 is listed. During the tutorial, you will hopefully find that other LRCs also know some information about example LFN.

Although it may not happen immediately, the RLIs will also learn about the logical filenames that you have created for yourself.

Query the RLI to see if the logical names that you added above have appeared in the RLI. If they haven&#39;t yet, wait a while and try again.

---+++RLS server statistics

Next use the -S flag to check the status/statistics of each of the two servers. You should see output similar to that below: 


&lt;pre&gt;
globus-rls-admin -S rls://gridlab1
Version:    2.1.5
Uptime:     00:28:15
LRC stats
  update method: lfnlist
  update method: bloomfilter
  updates bloomfilter: rls://gk2.phys.utb.edu:39281 last 06/21/04 22:44:45
  lfnlist update interval: 86400
  bloomfilter update interval: 900
  numlfn: 1
  numpfn: 1
  nummap: 1
RLI stats
  updated by: rls://gk2.phys.utb.edu:39281 last 06/21/04 22:44:35
  updated via bloomfilters
globus-rls-admin -S rls://gk2
Version:    2.1.5
Uptime:     00:32:33
LRC stats
  update method: lfnlist
  update method: bloomfilter
  updates bloomfilter: rls://gk1.phys.utb.edu:39281 last 06/21/04 22:44:40
  lfnlist update interval: 86400
  bloomfilter update interval: 900
  numlfn: 2
  numpfn: 2
  nummap: 2
RLI stats
  updated by: rls://gk1.phys.utb.edu:39281 last 06/21/04 22:44:49
  updated via bloomfilters
&lt;/pre&gt;


---++Treasure hunt
There are three files with logical filename treasure1, treasure2 and treasure3 stored on the grid. Use RLS to find them and RFT to move them into your home directory.

