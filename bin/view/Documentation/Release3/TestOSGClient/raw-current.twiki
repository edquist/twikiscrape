%DOC_STATUS_TABLE%

---+!! Testing the OSG Client
%TOC%

---+ About this Document

&lt;!-- conventions used in this document
   * Local UCL_CWD  = %URLPARAM{&quot;INPUT_CWD&quot; encode=&quot;quote&quot; default=&quot;~&quot;}%
   * Local UCL_HOST = %URLPARAM{&quot;INPUT_HOST&quot; encode=&quot;quote&quot; default=&quot;client&quot;}%
   * Local UCL_USER = %URLPARAM{&quot;INPUT_USER&quot; encode=&quot;quote&quot; default=&quot;user&quot;}%
   * Local UCL_DOMAIN = %URLPARAM{&quot;INPUT_DOMAIN&quot; encode=&quot;quote&quot; default=&quot;opensciencegrid.org&quot;}%
   * Local UCL_CE = %URLPARAM{&quot;INPUT_CE&quot; encode=&quot;quote&quot; default=&quot;ce.opensciencegrid.org&quot;}%
   * Set TWISTY_OPTS_DETAILED = mode=&quot;div&quot; showlink=&quot;Show Detailed Output&quot; hidelink=&quot;Hide&quot; showimgleft=&quot;/twiki/pub/TWiki/TWikiDocGraphics/toggleopen-small.gif&quot; hideimgleft=&quot;/twiki/pub/TWiki/TWikiDocGraphics/toggleclose-small.gif&quot; remember=&quot;on&quot; start=&quot;hide&quot; 

--&gt;

%ICON{hand}% This document is for OSG users. Simple tests will be introduced which may help testing the correct authentication with and operation of grid resources. This document also provides a _step-by-step guide_ to determine the approximate cause of an error followed by recommendations when a ticket with the %LINK_GOC_OPEN_TICKET% should be opened. 

%NOTE% This document does not demonstrate how the Open Science Grid should be used for production runs. None of the techniques presented will _scale_ to production levels! %RED%Do not use these tools for large scale productions runs%ENDCOLOR%, as these will cause the remote site to crash and possible get your account banned - [[Documentation/CondorSubmittingSingleJob][Condor-G]] will work much better.

---+ Customize this Document
This form allows you to customize the content of the examples in this document.

&lt;form action=&quot;%SCRIPTURLPATH{&quot;view&quot;}%/%WEB%/%TOPIC%&quot;&gt;
&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;
      Server (CE) Host Name
    &lt;/td&gt;
    &lt;td&gt;
      &lt;input type=&quot;text&quot; name=&quot;INPUT_CE&quot; value=&quot;%UCL_CE%&quot;/&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;
      Client Host Name
    &lt;/td&gt;
    &lt;td&gt;
      &lt;input type=&quot;text&quot; name=&quot;INPUT_HOST&quot; value=&quot;%UCL_HOST%&quot;/&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;
      Client Login Name
    &lt;/td&gt;
    &lt;td&gt;
      &lt;input type=&quot;text&quot; name=&quot;INPUT_USER&quot; value=&quot;%UCL_USER%&quot;/&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;
     &amp;nbsp;
     &lt;input type=&quot;submit&quot; class=&quot;twikiSubmit&quot; value=&quot;Customize&quot; /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
&lt;/form&gt;

---+ Introduction

Using a grid resource involves a series of steps that differ from the steps taken on a Unix resource. The following sections introduce and demonstrate each step required to run a basic grid job submission scenario. By understanding these simple tests you will be well prepared to understand, operate and debug complex grid scenarios. The series of tests are:

   1 [[#Authentication_Test][Authentication Test]]: create and verify your grid proxy used to authenticate yourself with a grid resource
   1 [[#Job_Submission_Test][Job Submission Test]]: execute a program on a grid resource
   1 [[#Data_Transfer_Test][Data Transfer Test]]: copy data to and from a grid resource

%NOTE% The *Data Transfer Tests* and the *Job Submission Tests* all depend on the successful completion of the *Authentication Test*. All tests except the authentication test are independent of each other for the purpose of this document and you can select to run only the ones you choose. The _Job Submission Tests_ require access to a %LINK_GLOSSARY_CE%, which is the terminology used in the OSG to describe a grid resource that can run jobs. Most OSG %LINK_GLOSSARY_CE%s have also a !GridFTP server that allows to complete the basic _Data Transfer Tests_ . More complex _Data Transfer Tests_ , the ones using SRM, require access to a SRM %LINK_GLOSSARY_SE%.

---+ Requirements

   1 access to a resource that has [[InstallOSGClient][OSG client tools]] installed
   1 a [[Documentation.CertificateWhatIs][grid user certificate]] installed on the same resource in =$HOME/.globus=
   1 access to a potential test resource ( see next paragraph )

---+ Choose a Test Resource

%ICON{hand}% Except for the [[#Authentication_Test][Authentication Test]] all tests require a grid resource to test against. Consider [[Documentation.FindAvailableResource][this guide]] for choosing an OSG grid resource to run the tests. Make sure to know what your membership %LINK_GLOSSARY_VO% is and that the grid resource you choose supports this VO! This document uses =%UCL_CE%= as an example. It can be customized in the form above. The default is =ce.opensciencegrid.org= which should not be used to run your tests!


---+ Authentication Test

The purpose of your [[Documentation.CertificateWhatIs][grid certificate]] is to authenticate yourself with every service provided by a %LINK_GLOSSARY_CE%. The authentication process is based on the [[http://en.wikipedia.org/wiki/X.509][X.509 Public Key Infrastructure]] which consists of a private key (=userkey.pem=) and a public key (=usercert.pem=). Both files together form your _certificate_ and are by default located in =$HOME/.globus=:

&lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% ls -al $HOME/.globus
total 68
drwxr-x---  4 %UCL_USER% %UCL_USER%  4096 Mar 18 18:50 .
drwx------ 29 %UCL_USER% %UCL_USER% 12288 Jul 28 08:38 ..
drwxrwxr-x  5 %UCL_USER% %UCL_USER%  4096 Jul 20 11:18 .gass_cache
drwx------  4 %UCL_USER% %UCL_USER%  4096 Mar 27 12:14 job
-rw-r-----  1 %UCL_USER% %UCL_USER%  1724 Dec 16  2008 usercert.pem
-r--------  1 %UCL_USER% %UCL_USER%  1919 Dec 16  2008 userkey.pem
&lt;/pre&gt;

Your certificate can be used to create a limited life-time %LINK_GLOSSARY_GRID_PROXY% or a %LINK_GLOSSARY_VOMS_PROXY%. You should use a VOMS Proxy if your membership %LINK_GLOSSARY_VO% supports VOMS Proxies and is providing a VOMS Server. Some OSG sites may require the use of a VOMS Proxy and will reject authentication requests using Grid Proxies.

%NOTE% If uncertain please contact the *VO Manager* for your membership *VO*.

%STARTSECTION{&quot;AuthenticationTest&quot;}%
#AuthenticationTest
---%SHIFT%++ Authentication using a Grid Proxy

To display detailed information about your grid proxy =grid-proxy-info= can be used:

&lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% grid-proxy-info
subject  : /DC=org/DC=doegrids/OU=People/CN=Firstname Lastname 392994/CN=1692124231
issuer   : /DC=org/DC=doegrids/OU=People/CN=Firstname Lastname 392994
identity : /DC=org/DC=doegrids/OU=People/CN=Firstname Lastname 392994
type     : Proxy draft (pre-RFC) compliant impersonation proxy
strength : 512 bits
path     : /tmp/x509up_u500
timeleft : 291:11:00  (12.1 days)
&lt;/pre&gt;

_Identity_ is sometimes also referred to as _Grid Identity_ or more frequently as %LINK_GLOSSARY_DN%. The last line of the output above indicates how long your current grid proxy will be valid. A grid proxy is said to have _expired_ if there is not time left on it. To _renew_  your grid proxy the program =grid-proxy-init= is used together with your grid password:

&lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% grid-proxy-init -valid 500:00
Your identity: /DC=org/DC=doegrids/OU=People/CN=Firstname Lastname 392994
Enter GRID pass phrase for this identity:
Creating proxy ................................. Done
Your proxy is valid until: Tue Aug 18 08:06:35 2009
&lt;/pre&gt;


---%SHIFT%++ Authentication using a VOMS Proxy

To display detailed information about your voms proxy =voms-proxy-info= can be used:

&lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% voms-proxy-info -all
WARNING: Unable to verify signature! Server certificate possibly not installed.
Error: Cannot verify AC signature!
subject   : /DC=org/DC=doegrids/OU=People/CN=Firstname Lastname 392994/CN=proxy
issuer    : /DC=org/DC=doegrids/OU=People/CN=Firstname Lastname 392994
identity  : /DC=org/DC=doegrids/OU=People/CN=Firstname Lastname 392994
type      : proxy
strength  : 1024 bits
path      : /tmp/x509up_u506
timeleft  : 388:18:27
%RED%=== VO LIGO extension information ===
VO        : LIGO
subject   : /DC=org/DC=doegrids/OU=People/CN=Firstname Lastname 392994
issuer    : /DC=org/DC=doegrids/OU=Services/CN=voms.ligo.org
attribute : /LIGO/Role=NULL/Capability=NULL
timeleft  : 0:00:00
uri       : voms.phys.uwm.edu:15001%ENDCOLOR%
&lt;/pre&gt;

_Identity_ is sometimes also referred to as _Grid Identity_ or more frequently as %LINK_GLOSSARY_DN%. Note the display of the %RED%extended attributes%ENDCOLOR% The first line marked =timeleft= of the output above indicates how long your current voms proxy will be valid. A voms proxy is said to have _expired_ if there is not time left on it. To _renew_  your voms proxy the program =voms-proxy-init= is used together with your grid password:


&lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% voms-proxy-init %RED%-voms LIGO:/LIGO%ENDCOLOR% -valid 500:00
Enter GRID pass phrase:
Your identity: /DC=org/DC=doegrids/OU=People/CN=Firstname Lastname 392994
Creating temporary proxy ................................ Done
Contacting  voms.phys.uwm.edu:15001 [/DC=org/DC=doegrids/OU=Services/CN=voms.ligo.org] &quot;LIGO&quot; Done
Creating proxy ......................................................... Done
&lt;/pre&gt;

%NOTE% The command line option =%RED%-voms LIGO:/LIGO%ENDCOLOR%= tells =voms-proxy-init= to contact the VOMS server for the LIGO VO. This may be different for your VO. Locate a file named =vomses= on your submission host to find out more about available VOMS servers. 

%TWISTY{%TWISTY_OPTS_DETAILED% showlink=&quot;Show the example of a failed request&quot;}%

Here what happens with a group you do not belong to, e.g., _/MyGroup_:

&lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% voms-proxy-init --voms VDT:/MyGroup
Your identity: /DC=org/DC=doegrids/OU=People/CN=Firstname Lastname 392994
Enter GRID pass phrase: 
Creating temporary proxy .......................................... Done
Contacting  voms.phys.uwm.edu:15001 [/DC=org/DC=doegrids/OU=Services/CN=voms.ligo.org] &quot;LIGO&quot; Failed

Error: LIGO: Unable to satisfy G/MyGroup Request!

Failed to contact servers for LIGO.
&lt;/pre&gt;

%NOTE% If a subsequent attempt at a voms proxy fails, as ours did here, the previously generated proxy is still in effect. You can do another =voms-proxy-info --all= to verify this.
%ENDTWISTY%


%ENDSECTION{&quot;AuthenticationTest&quot;}%

%STARTSECTION{&quot;MappingTest&quot;}%
#MappingTest
---%SHIFT%++ Mapping Test

A valid grid proxy does not guarantee that you may successfully authenticate with a remote grid resource. For a successful authentication your %LINK_GLOSSARY_DN% must be _mapped_ on the remote resource. A simple and quick way to check if your *DN* is mapped is to use =globus-run=:

&lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% globusrun -a -r %UCL_CE%

GRAM Authentication test successful
&lt;/pre&gt;

%NOTE% This example requires the _Grid Resource Allocation Manager (%LINK_GLOSSARY_GRAM%)_ to be available on the resource. This is usually the case on a %LINK_GLOSSARY_CE%, but not on a  %LINK_GLOSSARY_SE%. If you want to test authentication with a Storage Element, use the next example instead.
%ENDSECTION{&quot;MappingTest&quot;}%


---+ Job Submission Test

%STARTSECTION{&quot;GramTest&quot;}%
#GramTest
---++%SHIFT% Job Submission using GRAM

The &lt;b&gt;G&lt;/b&gt;rid &lt;b&gt;R&lt;/b&gt;esource &lt;b&gt;A&lt;/b&gt;llocation &lt;b&gt;M&lt;/b&gt;anager (%LINK_GLOSSARY_GRAM%) is a service running on a %LINK_GLOSSARY_CE% that services your job submission request and which puts your job into execution after successful authentication.

Here we use the =globus-job-run= command to execute the =id= command on the remote resource using the default *fork* %LINK_GLOSSARY_JM%: &lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% globus-job-run %UCL_CE% /usr/bin/id
uid=506(ligo) gid=506(ligo) groups=506(ligo)
&lt;/pre&gt;

Upon success =/usr/bin/id= returns information about the user account which has been used to execute the program itself on the grid resource. This is the account that your %LINK_GLOSSARY_DN% is mapped to. Unlike the [[#Mapping_Test][Mapping Test]] this test also verifies that the account exists and that the job manager was able to run the command on your behalf on the compute element.

%NOTE%  If you have a restrictive firewall in place, some of this testing will not work, and you will likely get Globus error 74 or 43. See the [[InstallOSGClient#Firewall_tunning][Condor firewall tuning]] section on how to solve this.&lt;br&gt;
Moreover, if your client is on a home network behind a NAT, you will also need to configure a GLOBUS_TCP_SOURCE_RANGE (range of non privileged ports) on your home router to forward them to the server.

%NOTE% Please open a ticket with the %LINK_GOC_OPEN_TICKET% for the resource in case all your configurations are correct and the command did not succeed.

---+++%SHIFT% Test the Availability of a Job Manager

A %LINK_GLOSSARY_JM% is a process running on the %LINK_GLOSSARY_CE% which is managing the execution of your job. By default the job manager =fork= will be used to _fork_ your program directly on the compute element. As a general rule of thumb you should %RED%avoid to use fork%ENDCOLOR% and to execute programs on the compute element unless that is your intention. A not complete list of job managers includes =fork=, =managedfork=, =ccs=, =condor=, =lsf=, =pbs= and =sge=. Depending on the setup of the grid resource more than one job manager may be supported.

Just like in the previous example we can use =globus-job-run= to verify that the =fork= job manager is available and used for the execution: &lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% globus-job-run %UCL_CE%/jobmanager-fork /usr/bin/id
uid=506(ligo) gid=506(ligo) groups=506(ligo)
&lt;/pre&gt;

Notice how we append =/jobmanager-fork= to the grid resource to explicitly request it. This can be used to detect if a certain job managers such as =condor= is available: &lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% globus-job-run %UCL_CE%/jobmanager-condor /bin/hostname
dom118
&lt;/pre&gt;

Because the job is scheduled to be executed through %LINK_GLOSSARY_CONDOR% this command will likely require more time to complete. Here we used the =/bin/hostname= command to return the _hostname_ of the worker node executing the job.

To specify a job manager that is not supported by the grid resource creates a convenient way to find out what job managers are supported by the resource from the comfort of the command line: &lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% globus-job-run %UCL_CE%/jobmanager-pbs /bin/hostname
GRAM Job submission failed because the gatekeeper failed to find the requested service (error code 93)
%UCL_PROMPT% echo $?
93
&lt;/pre&gt;

%NOTE% The &lt;b&gt;names for job managers are case sensitive&lt;/b&gt; and are &lt;b&gt;all lower case for %LINK_GLOSSARY_GRAM%&lt;/b&gt;.

%ENDSECTION{&quot;GramTest&quot;}%


%STARTSECTION{&quot;CondorTest&quot;}%
#CondorTest
---++ Job submission using Condor-G
This section only applies, if you have installed Condor-G in your client. Skip to the next section if otherwise.

This is a simple test. The [[CondorSubmittingSingleJob][Condor-G tutorial]] documents better more complex examples and you can find even more information in the [[http://www.cs.wisc.edu/condor/condorg/][Condor-G documentation]].

   1. Create a dummy shell script &lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% cat &lt;&lt; SCRIPT &gt; test.sh
#!/bin/bash
uname -a
id
SCRIPT
%UCL_PROMPT% chmod a+x test.sh
&lt;/pre&gt;
   1. Create a job submit file (replace the %RED%jobmanager-pbs%ENDCOLOR% with the jobmanager you want to use on the CE)&lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% cat &lt;&lt; JOB &gt; submit.job
universe = grid
grid_resource = gt2 %UCL_CE%/%RED%jobmanager-pbs%ENDCOLOR%
executable = test.sh
log = log
output = output
error = error
Transfer_Executable = True
transfer_Input_files = 
transfer_Output_files = 
WhenToTransferOutput  = ON_EXIT
Notification = Never
queue
JOB
&lt;/pre&gt;
   1. Submit job &lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% condor_submit submit.job
Submitting job(s).
1 job(s) submitted to cluster 1.
&lt;/pre&gt;
   1. Monitor the job with job &lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% condor_q

-- Submitter: submit.my.org : &lt;1.2.3.4:22878&gt; : submit.my.org
 ID      OWNER            SUBMITTED     RUN_TIME ST PRI SIZE CMD               
   1.0   user           10/7  19:03   0+00:00:00 I  0   0.0  test.sh           

1 jobs; 1 idle, 0 running, 0 held
&lt;/pre&gt;
   1. Once the job finishes (i.e. is not in the queue anymore), you will get the output in the =output= file.  Check the =log= file for reports on progress or if the job fails.

%ENDSECTION{&quot;CondorTest&quot;}%


---+ Data Transfer Test

Data can be transferred to and from a grid resource using a version of ftp that supports grid authentication called %LINK_GLOSSARY_GRIDFTP%. Each %LINK_GLOSSARY_CE% has a %LINK_GLOSSARY_GRIDFTP% server. Also all %LINK_GLOSSARY_SE% have %LINK_GLOSSARY_GRIDFTP% servers, either public or behind a different frontend like %LINK_GLOSSARY_SRM%. The =globus-url-copy= command can be used to transfer files using %LINK_GLOSSARY_GRIDFTP%.

To verify that !GridFTP is working correctly we will 

   1 create a file using =dd=
   1 transfer the file _to_ the grid resource using =globus-url-copy=
   1 transfer the file back _from_ the grid resource using =globus-url-copy=
   1 compare both files using =diff=

First let&#39;s create the test file: &lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% dd if=/dev/zero of=/tmp/%UCL_CE%.test.0 bs=1k count=1024
1024+0 records in
1024+0 records out
1048576 bytes (1.0 MB) copied, 0.005332 seconds, 197 MB/s
&lt;/pre&gt;

Next let&#39;s transfer the file to the grid resource: &lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% globus-url-copy file:///tmp/%UCL_CE%.test.0 gsiftp://%UCL_CE%/~/%UCL_CE%.test.0
%UCL_PROMPT% echo $?
0
&lt;/pre&gt;

To copy the file back to your resource use:&lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% globus-url-copy gsiftp://%UCL_CE%/~/%UCL_CE%.test.0 file:///tmp/%UCL_CE%.test.1
%UCL_PROMPT% echo $?
0
&lt;/pre&gt;

Finally let&#39;s compare the _original_ with the _copy_ received back from the remote resource: &lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% diff /tmp/%UCL_CE%.test.0  /tmp/%UCL_CE%.test.1
%UCL_PROMPT% echo $?
0
&lt;/pre&gt;

%NOTE% The =file= protocol in the *URI* is used for files on a local file system. In this case no authentication is performed with the local resource before the file is read or written. Replacing =file= by =gsiftp= always requires a %LINK_GLOSSARY_GRIDFTP% server running at the resource specified in the URI.


---++ File Transfer using !UberFTP
=uberftp= is another command to transfer files using %LINK_GLOSSARY_GRIDFTP%. 

&lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT%uberftp %UCL_CE%  ls
220 GSI FTP door ready
200 User fnalgrid logged in
drwx------  1 fnalgrid   fnalgrid            512 Jan 26  2010 some_dir
&lt;/pre&gt;
&lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT%uberftp %UCL_CE%  &quot;ls %RED%some_dir%ENDCOLOR%&quot;
220 GSI FTP door ready
200 User fnalgrid logged in
-r--------  1 fnalgrid   fnalgrid             15 Jan 26  2010 some_file
&lt;/pre&gt;
&lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT%uberftp %UCL_CE%  &quot;cat %RED%some_dir/some_file%ENDCOLOR%&quot;
220 GSI FTP door ready
200 User fnalgrid logged in
Some text from some_file
&lt;/pre&gt;


---++ File Transfer using LCG-Utils
[[Documentation.Release3.LcgUtilities][LCG-Utils]] is a set of programs that can transfer files from a !GridFTP or SRM %LINK_GLOSSARY_SE%.

   1. ls &lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% lcg-ls -D srmv2 -b srm://red-srm1.unl.edu:8443/srm/v2/server?SFN=/mnt/hadoop/
/mnt/hadoop/Trash
/mnt/hadoop/backups
/mnt/hadoop/chukwa
/mnt/hadoop/dropfiles
/mnt/hadoop/hello_world
/mnt/hadoop/images
/mnt/hadoop/logs
/mnt/hadoop/lost+found
/mnt/hadoop/public
/mnt/hadoop/scratch
/mnt/hadoop/system
/mnt/hadoop/tmp
/mnt/hadoop/user
&lt;/pre&gt;
   2. Transfer &lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% lcg-cp -D srmv2 -b srm://red-srm1.unl.edu:8443/srm/v2/server?SFN=/mnt/hadoop/dropfiles/hello_world file://`pwd`/hello_world
%UCL_PROMPT% cat hello_world
hello world!
%UCL_PROMPT% rm hello_world 
&lt;/pre&gt;

---++ SRM-Fermi
SRM-Fermi is a set of programs that can transfer files from a !GridFTP or SRM %LINK_GLOSSARY_SE%.

   1. ls &lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% srmls srm://red-srm1.unl.edu:8443/srm/v2/server?SFN=/mnt/hadoop/
  /mnt/hadoop//
      /mnt/hadoop/Trash/
      /mnt/hadoop/backups/
      /mnt/hadoop/chukwa/
      /mnt/hadoop/dropfiles/
      /mnt/hadoop/hello_world
      /mnt/hadoop/images/
      /mnt/hadoop/logs/
      /mnt/hadoop/lost+found/
      /mnt/hadoop/public/
      /mnt/hadoop/scratch/
      /mnt/hadoop/system/
      /mnt/hadoop/tmp/
      /mnt/hadoop/user/ 
&lt;/pre&gt;
   1. Transfer &lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% srmcp srm://red-srm1.unl.edu:8443/srm/v2/server?SFN=/mnt/hadoop/dropfiles/hello_world file:///`pwd`/hello_world
%UCL_PROMPT% cat hello_world 
hello world!
%UCL_PROMPT% rm hello_world 
&lt;/pre&gt;

---++ SRM LBNL
SRM-LBNL is a set of programs that can transfer files from a !GridFTP or SRM %LINK_GLOSSARY_SE%.
These are similar to SRM-Fermi and very verbose (click on the link to see the output).

   1. ls &lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% srm-ls srm://red-srm1.unl.edu:8443/srm/v2/server?SFN=/mnt/hadoop/ 
...see long output below...
&lt;/pre&gt;   %TWISTY{
mode=&quot;div&quot;
showlink=&quot;Show command output...&quot;
hidelink=&quot;Hide command output...&quot;
showimgleft=&quot;%ICONURLPATH{toggleopen-small}%&quot;
hideimgleft=&quot;%ICONURLPATH{toggleclose-small}%&quot;
}%  &lt;pre class=&quot;screen&quot;&gt;
srm-ls   2.2.2.1.0   Mon Jul 11 10:31:14 PDT 2011
BeStMan and SRM-Clients Copyright(c) 2007-2011,
Lawrence Berkeley National Laboratory. All rights reserved.
Support at SRM@LBL.GOV and documents at http://sdm.lbl.gov/bestman

 
BUILT  Fri Jul 15 13:24:22 EDT 2011  on  glidein.unl.edu
SRM-CLIENT: Connecting to serviceurl httpg://red-srm1.unl.edu:8443/srm/v2/server

SRM-DIR: Mon Jul 25 18:59:23 CDT 2011 Calling srmLsRequest

SRM-DIR: ..........................
	Status    : SRM_SUCCESS
	Explanation : null
	Request token=null

	SURL=/mnt/hadoop/
	Bytes=null
	FileType=DIRECTORY
	StorageType=null
	Status=SRM_SUCCESS
	Explanation=Read from disk..
	FileLocality=ONLINE

	   SURL=/mnt/hadoop/Trash
	   Bytes=null
	   FileType=DIRECTORY
	   StorageType=null
	   Status=SRM_SUCCESS
	   Explanation=Read from disk..

	   SURL=/mnt/hadoop/backups
	   Bytes=null
	   FileType=DIRECTORY
	   StorageType=null
	   Status=SRM_SUCCESS
	   Explanation=Read from disk..

	   SURL=/mnt/hadoop/chukwa
	   Bytes=null
	   FileType=DIRECTORY
	   StorageType=null
	   Status=SRM_SUCCESS
	   Explanation=Read from disk..

	   SURL=/mnt/hadoop/dropfiles
	   Bytes=null
	   FileType=DIRECTORY
	   StorageType=null
	   Status=SRM_SUCCESS
	   Explanation=Read from disk..

	   SURL=/mnt/hadoop/hello_world
	   Bytes=13
	   FileType=FILE
	   StorageType=null
	   Status=SRM_SUCCESS
	   Explanation=Read from disk..

	   SURL=/mnt/hadoop/images
	   Bytes=null
	   FileType=DIRECTORY
	   StorageType=null
	   Status=SRM_SUCCESS
	   Explanation=Read from disk..

	   SURL=/mnt/hadoop/logs
	   Bytes=null
	   FileType=DIRECTORY
	   StorageType=null
	   Status=SRM_SUCCESS
	   Explanation=Read from disk..

	   SURL=/mnt/hadoop/lost+found
	   Bytes=null
	   FileType=DIRECTORY
	   StorageType=null
	   Status=SRM_SUCCESS
	   Explanation=Read from disk..

	   SURL=/mnt/hadoop/public
	   Bytes=null
	   FileType=DIRECTORY
	   StorageType=null
	   Status=SRM_SUCCESS
	   Explanation=Read from disk..

	   SURL=/mnt/hadoop/scratch
	   Bytes=null
	   FileType=DIRECTORY
	   StorageType=null
	   Status=SRM_SUCCESS
	   Explanation=Read from disk..

	   SURL=/mnt/hadoop/system
	   Bytes=null
	   FileType=DIRECTORY
	   StorageType=null
	   Status=SRM_SUCCESS
	   Explanation=Read from disk..

	   SURL=/mnt/hadoop/tmp
	   Bytes=null
	   FileType=DIRECTORY
	   StorageType=null
	   Status=SRM_SUCCESS
	   Explanation=Read from disk..

	   SURL=/mnt/hadoop/user
	   Bytes=null
	   FileType=DIRECTORY
	   StorageType=null
	   Status=SRM_SUCCESS
	   Explanation=Read from disk..

SRM-DIR: Printing text report now ...
SRM-CLIENT*REQUEST_STATUS=SRM_SUCCESS
SRM-CLIENT*SURL=/mnt/hadoop/
SRM-CLIENT*FILETYPE=DIRECTORY
SRM-CLIENT*FILE_STATUS=SRM_SUCCESS
SRM-CLIENT*FILE_EXPLANATION=Read from disk..
SRM-CLIENT*FILELOCALITY=ONLINE
SRM-CLIENT*SURL=/mnt/hadoop/Trash
SRM-CLIENT*FILETYPE=DIRECTORY
SRM-CLIENT*FILE_STATUS=SRM_SUCCESS
SRM-CLIENT*FILE_EXPLANATION=Read from disk..
SRM-CLIENT*SURL=/mnt/hadoop/backups
SRM-CLIENT*FILETYPE=DIRECTORY
SRM-CLIENT*FILE_STATUS=SRM_SUCCESS
SRM-CLIENT*FILE_EXPLANATION=Read from disk..
SRM-CLIENT*SURL=/mnt/hadoop/chukwa
SRM-CLIENT*FILETYPE=DIRECTORY
SRM-CLIENT*FILE_STATUS=SRM_SUCCESS
SRM-CLIENT*FILE_EXPLANATION=Read from disk..
SRM-CLIENT*SURL=/mnt/hadoop/dropfiles
SRM-CLIENT*FILETYPE=DIRECTORY
SRM-CLIENT*FILE_STATUS=SRM_SUCCESS
SRM-CLIENT*FILE_EXPLANATION=Read from disk..
SRM-CLIENT*SURL=/mnt/hadoop/hello_world
SRM-CLIENT*BYTES=13
SRM-CLIENT*FILETYPE=FILE
SRM-CLIENT*FILE_STATUS=SRM_SUCCESS
SRM-CLIENT*FILE_EXPLANATION=Read from disk..
SRM-CLIENT*SURL=/mnt/hadoop/images
SRM-CLIENT*FILETYPE=DIRECTORY
SRM-CLIENT*FILE_STATUS=SRM_SUCCESS
SRM-CLIENT*FILE_EXPLANATION=Read from disk..
SRM-CLIENT*SURL=/mnt/hadoop/logs
SRM-CLIENT*FILETYPE=DIRECTORY
SRM-CLIENT*FILE_STATUS=SRM_SUCCESS
SRM-CLIENT*FILE_EXPLANATION=Read from disk..
SRM-CLIENT*SURL=/mnt/hadoop/lost+found
SRM-CLIENT*FILETYPE=DIRECTORY
SRM-CLIENT*FILE_STATUS=SRM_SUCCESS
SRM-CLIENT*FILE_EXPLANATION=Read from disk..
SRM-CLIENT*SURL=/mnt/hadoop/public
SRM-CLIENT*FILETYPE=DIRECTORY
SRM-CLIENT*FILE_STATUS=SRM_SUCCESS
SRM-CLIENT*FILE_EXPLANATION=Read from disk..
SRM-CLIENT*SURL=/mnt/hadoop/scratch
SRM-CLIENT*FILETYPE=DIRECTORY
SRM-CLIENT*FILE_STATUS=SRM_SUCCESS
SRM-CLIENT*FILE_EXPLANATION=Read from disk..
SRM-CLIENT*SURL=/mnt/hadoop/system
SRM-CLIENT*FILETYPE=DIRECTORY
SRM-CLIENT*FILE_STATUS=SRM_SUCCESS
SRM-CLIENT*FILE_EXPLANATION=Read from disk..
SRM-CLIENT*SURL=/mnt/hadoop/tmp
SRM-CLIENT*FILETYPE=DIRECTORY
SRM-CLIENT*FILE_STATUS=SRM_SUCCESS
SRM-CLIENT*FILE_EXPLANATION=Read from disk..
SRM-CLIENT*SURL=/mnt/hadoop/user
SRM-CLIENT*FILETYPE=DIRECTORY
SRM-CLIENT*FILE_STATUS=SRM_SUCCESS
SRM-CLIENT*FILE_EXPLANATION=Read from disk..
&lt;/pre&gt;  %ENDTWISTY%
   1. Transfer &lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% srm-copy srm://red-srm1.unl.edu:8443/srm/v2/server?SFN=/mnt/hadoop/dropfiles/hello_world file:///`pwd`/hello_world 
...see long output below...
%UCL_PROMPT% cat hello_world
hello world! 
%UCL_PROMPT% rm hello_world 
&lt;/pre&gt;   %TWISTY{
mode=&quot;div&quot;
showlink=&quot;Show command output...&quot;
hidelink=&quot;Hide command output...&quot;
showimgleft=&quot;%ICONURLPATH{toggleopen-small}%&quot;
hideimgleft=&quot;%ICONURLPATH{toggleclose-small}%&quot;
}%  &lt;pre class=&quot;screen&quot;&gt;
srm-copy   2.2.2.1.0   Mon Jul 11 10:31:14 PDT 2011
BeStMan and SRM-Clients Copyright(c) 2007-2011,
Lawrence Berkeley National Laboratory. All rights reserved.
Support at SRM@LBL.GOV and documents at http://sdm.lbl.gov/bestman

 
BUILT  Fri Jul 15 13:24:22 EDT 2011  on  glidein.unl.edu
SRM-CLIENT: Tue Jul 26 12:01:28 CDT 2011 Connecting to httpg://red-srm1.unl.edu:8443/srm/v2/server

SRM-CLIENT: Tue Jul 26 12:01:29 CDT 2011 Calling SrmPrepareToGet Request now ...
request.token= get:1034871

Request.status=SRM_SUCCESS
Request.explanation=null

SRM-CLIENT: RequestFileStatus for SURL=srm://red-srm1.unl.edu:8443/srm/v2/server?SFN=/mnt/hadoop/dropfiles/hello_world is Ready.
SRM-CLIENT: received TURL=gsiftp://red-gridftp6.unl.edu:2811//mnt/hadoop/dropfiles/hello_world

SRM-CLIENT: Tue Jul 26 12:01:33 CDT 2011 start file transfer
SRM-CLIENT:Source=gsiftp://red-gridftp6.unl.edu:2811//mnt/hadoop/dropfiles/hello_world
SRM-CLIENT:Target=file:////home/dweitzel/hello_world

SRM-CLIENT: Tue Jul 26 12:01:36 CDT 2011 end file transfer for srm://red-srm1.unl.edu:8443/srm/v2/server?SFN=/mnt/hadoop/dropfiles/hello_world

SRM-CLIENT: Tue Jul 26 12:01:36 CDT 2011 Calling releaseFile

SRM-CLIENT:  ...Calling srmReleaseFiles...
	status=SRM_SUCCESS
	explanation=null
	status=SRM_SUCCESS
	explanation=null

SRM-CLIENT: Request completed with success

SRM-CLIENT: Printing text report now ...

SRM-CLIENT*REQUESTTYPE=get
SRM-CLIENT*TOTALFILES=1
SRM-CLIENT*TOTAL_SUCCESS=1
SRM-CLIENT*TOTAL_FAILED=0
SRM-CLIENT*REQUEST_TOKEN=get:1034871
SRM-CLIENT*REQUEST_STATUS=SRM_SUCCESS
SRM-CLIENT*SOURCEURL[0]=srm://red-srm1.unl.edu:8443/srm/v2/server?SFN=/mnt/hadoop/dropfiles/hello_world
SRM-CLIENT*TARGETURL[0]=file:////home/dweitzel/hello_world
SRM-CLIENT*TRANSFERURL[0]=gsiftp://red-gridftp6.unl.edu:2811//mnt/hadoop/dropfiles/hello_world
SRM-CLIENT*ACTUALSIZE[0]=13
SRM-CLIENT*FILE_STATUS[0]=SRM_FILE_PINNED
&lt;/pre&gt;   %ENDTWISTY%

https://twiki.grid.iu.edu/bin/view/Trash/ReleaseDocumentationValidateClients
---+ Test Discovery Tools 
The OSG Discovery Tools query OSG information system, BDII, to discover information about %LINK_GLOSSARY_CE%s and %LINK_GLOSSARY_SE%s.

&lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% get_os_versions --vo Engage --match &quot;ScientificSLF Lederman&quot;

Site Name           Compute Element ID                                          OS Version                    
FNAL_FERMIGRID      fermigridosg1.fnal.gov:2119/jobmanager-condor-default       ScientificSLF Lederman 5.5    
FNAL_GPGRID_1       fnpcosg1.fnal.gov:2119/jobmanager-condor-default            ScientificSLF Lederman 5.3    
FNAL_GPGRID_1       fnpcosg1.fnal.gov:2119/jobmanager-condor-group_engage       ScientificSLF Lederman 5.3    
Found OS ScientificSLF Lederman 5.5 for Engage VO at site FNAL_FERMIGRID 
&lt;/pre&gt;
&lt;pre class=&quot;screen&quot;&gt;
%UCL_PROMPT% get_surl --vo Engage --show_site_name

SITE NAME                     SURL                                                                                                
UCSDT2                        srm://bsrm-1.t2.ucsd.edu:8443/srm/v2/server?SFN=/hadoop/engage/TESTFILE                             
UCR-HEP                       srm://charm.ucr.edu:10443/srm/v2/server?SFN=/data/bottom/cms/TESTFILE             
CIT_CMS_T2                    srm://cit-se.ultralight.org:8443/srm/v2/server?SFN=/mnt/hadoop/osg/engage/TESTFILE                  
GLOW                          srm://cmssrm.hep.wisc.edu:8443/srm/v2/server?SFN=/osg/vo/engage/TESTFILE                            
..
&lt;/pre&gt;

#OtherInfoTest
---++ Other Information System Tools
There are many other tools that can query different components of the OSG information system.  The following examples are directed the OSG-ITB repositories (=osg-ress-4.fnal.gov=, the production one is =osg-ress-1.fnal.gov=).
More information can be found in [[Documentation.FindAvailableResource][find available resources]].

[[Documentation.GlossaryR#DefsRess][ReSS]] ([[https://osg-ress-1.fnal.gov:8443/ReSS/][here a Web page]]) can be queried using Condor and !ClassAds: &lt;pre class=screen&gt;%UCL_PROMPT% condor_status -pool osg-ress-4.fnal.gov -format &#39;%s\n&#39; GlueSiteName | sort | uniq
&lt;b&gt;CIT_ITB_1
ITB_INSTALL_TEST_2
ITB_INSTALL_TEST_3
CMS-BURT-ITB
...&lt;/b&gt;
&lt;/pre&gt;

[[Documentation.GlossaryB#DefsBDII][BDII]] can be queried with =ldapsearch=:
   1. If you have no ldapsearch, you can install =openldap-clients= it with yum: &lt;pre class=rootscreen&gt;%UCL_PROMPT% yum install openldap-clients
&lt;/pre&gt;
   1. Query: &lt;pre class=screen&gt;%UCL_PROMPT% ldapsearch -x -LLL -p 2170 -h is-itb.grid.iu.edu -b mds-vo-name=LBNL_VTB,mds-vo-name=local,o=grid
&lt;b&gt;dn: mds-vo-name=LBNL_VTB,mds-vo-name=local,o=grid
objectClass: GlueTop
 
dn: GlueSEUniqueID=osp1.lbl.gov,mds-vo-name=LBNL_VTB,mds-vo-name=local,o=grid
...&lt;/b&gt;
&lt;/pre&gt;

LCG tools (=lcg-info= and =lcg-infosites=) can be used  for queries to the BDII as well:
&lt;pre class=screen&gt;%UCL_PROMPT% lcg-info --list-ce --bdii is-itb.grid.iu.edu:2170 --vo osg
&lt;b&gt;- CE: cithep201.ultralight.org:2119/jobmanager-condor-osg
- CE: cms-xen1.fnal.gov:2119/jobmanager-condor-osg
....&lt;/b&gt;

%UCL_PROMPT% lcg-info --list-se --bdii is-itb.grid.iu.edu:2170 --vo osg
&lt;b&gt;- SE: cit-se.ultralight.org
- SE: cms-xen1.fnal.gov
...&lt;/b&gt; 
 
%UCL_PROMPT% lcg-infosites --vo osg -f ce  --is is-itb.grid.iu.edu 
&lt;b&gt;valor del bdii: is-itb.grid.iu.edu:2170
#CPU    Free    Total Jobs      Running Waiting ComputingElement
----------------------------------------------------------
  40      40       0              0        0    osp1.lbl.gov:2119/jobmanager-pbs-batch
   2       0       0              0        0    tb10.grid.iu.edu:2119/jobmanager-condor-osg
1042       2       0              0        0    itb.rcac.purdue.edu:2119/jobmanager-condor-osg
...&lt;/b&gt;

%UCL_PROMPT% lcg-infosites --vo osg -f se  --is is-itb.grid.iu.edu 
&lt;b&gt;Avail Space(Kb) Used Space(Kb)  Type    SEs
----------------------------------------------------------
125             2               n.a     osp1.lbl.gov
28824440        10638628        n.a     tb10.grid.iu.edu
37              242             n.a     itb.rcac.purdue.edu
...&lt;/b&gt;
&lt;/pre&gt;

---+ References
   * Documentation.FindAvailableResource
   * TroubleshootingGuide

---+ Comments

%COMMENT{type=&quot;tableappend&quot;}%


&lt;!-- CONTENT MANAGEMENT PROJECT
############################################################################################################
 DEAR DOCUMENT OWNER
 ===================

 Thank you for claiming ownership for this document! Please fill in your FirstLast name here:
   * Local OWNER = MarcoMambelli

 Please define the document area, choose one of the defined areas from the next line
 DOC_AREA = (ComputeElement|General|Trash/Trash/Integration|Monitoring|Operations|Security|Storage|Trash/Tier3|User|VO)
   * Local DOC_AREA       = General

 define the primary role the document serves, choose one of the defined roles from the next line
 DOC_ROLE = (Developer|Documenter|Scientist|Student|SysAdmin|VOManager)
   * Local DOC_ROLE       = SysAdmin

 Please define the document type, choose one of the defined types from the next line
 DOC_TYPE = (HowTo|Installation|Knowledge|Navigation|Planning|Training|Troubleshooting)
   * Local DOC_TYPE       = Installation
  Please define if this document in general needs to be reviewed before release ( %YES% | %NO% )
   * Local INCLUDE_REVIEW = %YES%

 Please define if this document in general needs to be tested before release ( %YES% | %NO% )
   * Local INCLUDE_TEST   = %YES%

 change to %YES% once the document is ready to be reviewed and back to %NO% if that is not the case
   * Local REVIEW_READY   = %YES%

 change to %YES% once the document is ready to be tested and back to %NO% if that is not the case
   * Local TEST_READY     = %YES%

 change to %YES% only if the document has passed the review and the test (if applicable) and is ready for release
   * Local RELEASE_READY  = %YES%


 DEAR DOCUMENT REVIEWER
 ======================

 Thank for reviewing this document! Please fill in your FirstLast name here:
   * Local REVIEWER       = JamesWeichel
 Please define the review status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local REVIEW_PASSED  = %YES%


 DEAR DOCUMENT TESTER
 ====================

 Thank for testing this document! Please fill in your FirstLast name here:
   * Local TESTER         = JamesWeichel
 Please define the test status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local TEST_PASSED    = %YES%
############################################################################################################
--&gt;

