<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en_US" lang="en_US">
<head>
<link rel="stylesheet" href="https://twiki.opensciencegrid.org/twiki/pub/TWiki/HeadlinesPlugin/style.css" type="text/css" media="all" />
<title> InstallHadoop200SE &lt; Documentation/Release3 &lt; TWiki    </title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
<link rel="icon" href="/twiki/pub/Documentation/Release3/WebPreferences/favicon.ico    " type="image/x-icon" />
<link rel="shortcut icon" href="/twiki/pub/Documentation/Release3/WebPreferences/favicon.ico    " type="image/x-icon" />
<link rel="alternate" href="https://twiki.opensciencegrid.org/bin/edit/Documentation/Release3/InstallHadoop200SE?_T=16 Feb 2017" type="application/x-wiki" title="edit InstallHadoop200SE" />
<meta name="SCRIPTURLPATH" content="/bin" />
<meta name="SCRIPTSUFFIX" content="" />
<meta name="TEXT_JUMP" content="Jump" />
<meta name="TEXT_SEARCH" content="Search" />
<meta name="TEXT_NUM_TOPICS" content="Number of topics:" />
<meta name="TEXT_MODIFY_SEARCH" content="Modify search" />
<meta name="robots" content="noindex" /><link rel="alternate" type="application/rss+xml" title="RSS Feed" href="/bin/view/Documentation/Release3/WebRss" />    
<base href="https://twiki.opensciencegrid.org/bin/view/Documentation/Release3/InstallHadoop200SE"></base>
<!--BEHAVIOURCONTRIB--><script type="text/javascript" src="/twiki/pub/TWiki/BehaviourContrib/behaviour.compressed.js"></script>
<script type="text/javascript" src="/twiki/pub/TWiki/TWikiJavascripts/twikilib.js"></script>
<script type="text/javascript" src="/twiki/pub/TWiki/TWikiJavascripts/twikiWindow.js"></script>
<script type="text/javascript" src="/twiki/pub/TWiki/TWikiJavascripts/twikiEvent.js"></script>
<script type="text/javascript" src="/twiki/pub/TWiki/TWikiJavascripts/twikiHTML.js"></script>
<script type="text/javascript" src="/twiki/pub/TWiki/TWikiJavascripts/twikiCSS.js"></script>
<script type="text/javascript" src="/twiki/pub/TWiki/TWikiJavascripts/twikiForm.js"></script>
<script type="text/javascript" src="/twiki/pub/TWiki/PatternSkin/pattern.js"></script><style type="text/css" media="all">
@import url('/twiki/pub/TWiki/TWikiTemplates/base.css');
</style><script type="text/javascript" src="/twiki/pub/TWiki/TWikiJavascripts/twikiStyles.js"></script><style type="text/css" media="all">


</style>
<style type="text/css" media="all">
@import url("/twiki/pub/TWiki/TWikiNetSkin/layout.css");
@import url("/twiki/pub/TWiki/TWikiNetSkin/style.css");
@import url("/twiki/pub/TWiki/TWikiNetSkin/colors.css");
@import url("/twiki/pub/TWiki/TWikiNetSkin/rounded_corners.css");
</style>
<style type="text/css" media="all">
	/* Styles that are set using variables */
	#patternLeftBar .patternWebIndicator,
	.patternBookView .twikiTopRow {
		background-color:#FFFFFF;
	}
	.patternBookView {
		border-color:#FFFFFF;
	}
	.patternPreviewPage #patternMain {
		/* uncomment to set the preview image */
		/*background-image:url("/twiki/pub/TWiki/PreviewBackground/preview2bg.gif    ");*/
	}
	
</style><style type="text/css" media="all">



</style>
<style type="text/css" media="all">
	@import url("/twiki/pub/TWiki/TWikiNetSkin/print.css");
</style><!--TWISTYPLUGIN_TWISTY--><style type="text/css" media="all">
@import url("https://twiki.opensciencegrid.org/twiki/pub/TWiki/TwistyContrib/twist.css");
</style>
<script type='text/javascript' src='https://twiki.opensciencegrid.org/twiki/pub/TWiki/BehaviourContrib/behaviour.compressed.js'></script>
<script type="text/javascript" src="https://twiki.opensciencegrid.org/twiki/pub/TWiki/TWikiJavascripts/twikilib.js"></script>
<script type="text/javascript" src="https://twiki.opensciencegrid.org/twiki/pub/TWiki/TWikiJavascripts/twikiPref.js"></script>
<script type="text/javascript" src="https://twiki.opensciencegrid.org/twiki/pub/TWiki/TWikiJavascripts/twikiCSS.js"></script>
<script type="text/javascript" src="https://twiki.opensciencegrid.org/twiki/pub/TWiki/TwistyContrib/twist.compressed.js"></script>
<script type="text/javascript">
// <![CDATA[
var styleText = '<style type="text/css" media="all">.twikiMakeVisible{display:inline;}.twikiMakeVisibleInline{display:inline;}.twikiMakeVisibleBlock{display:block;}.twikiMakeHidden{display:none;}</style>';
document.write(styleText);
// ]]>
</script>

<!--GOOGLEANALYTICSPLUGIN--><!-- Google Analytics script -->
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-69012-21']);
  _gaq.push(['_setDomainName', 'none']);
  _gaq.push(['_setAllowLinker', true]);
  _gaq.push(['_trackPageview']);
  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>

<!--TABLEPLUGIN_table4--><style type="text/css" media="all">
.tableSortIcon img {padding-left:.3em; vertical-align:text-bottom;}
</style></head>
<body class="patternViewPage patternPrintPage">
<a name="PageTop"></a>
<div id="patternScreen">
<div id="patternPageShadow">
<div id="patternPage">
<div id="patternOuter">
<div id="patternFloatWrap">
<div id="patternMain">
<div id="patternMainContents">
<div class="patternContent"><div class="patternTopic"> <h1><a name="Hadoop_2_0_0_CDH4"></a>  <strong>Hadoop 2.0.0 (CDH4)</strong> </h1>
<p />
<div class="twikiToc"> <ul>
<li> <a href="?cover=print#Preparation"> Preparation</a> <ul>
<li> <a href="?cover=print#Introduction"> Introduction</a>
</li> <li> <a href="?cover=print#Note_on_upgrading_from_Hadoop_0"> Note on upgrading from Hadoop 0.20</a>
</li></ul> 
</li> <li> <a href="?cover=print#Requirements"> Requirements</a> <ul>
<li> <a href="?cover=print#Architecture"> Architecture</a>
</li> <li> <a href="?cover=print#Host_and_OS"> Host and OS</a>
</li> <li> <a href="?cover=print#Users"> Users</a>
</li> <li> <a href="?cover=print#Certificates"> Certificates</a>
</li> <li> <a href="?cover=print#Networking"> Networking</a>
</li></ul> 
</li> <li> <a href="?cover=print#Install_the_Yum_Repositories_req"> Install the Yum Repositories required by OSG</a> <ul>
<li> <a href="?cover=print#Install_EPEL"> Install EPEL</a>
</li> <li> <a href="?cover=print#Install_the_Yum_priorities_packa"> Install the Yum priorities package</a>
</li> <li> <a href="?cover=print#Install_OSG_Repositories"> Install OSG Repositories</a>
</li></ul> 
</li> <li> <a href="?cover=print#Initializing_Certificate_Authori"> Initializing Certificate Authority</a>
</li> <li> <a href="?cover=print#Installation"> Installation</a> <ul>
<li> <a href="?cover=print#Namenode_Installation"> Namenode Installation</a>
</li> <li> <a href="?cover=print#Secondary_Namenode_Installation"> Secondary Namenode Installation</a>
</li> <li> <a href="?cover=print#Datanode_Installation"> Datanode Installation</a>
</li> <li> <a href="?cover=print#Client_FUSE_Installation"> Client/FUSE Installation</a>
</li> <li> <a href="?cover=print#Standalone_Gridftp_Node_Installa"> Standalone Gridftp Node Installation</a>
</li> <li> <a href="?cover=print#SRM_Node_Installation"> SRM Node Installation</a>
</li></ul> 
</li> <li> <a href="?cover=print#Configuration"> Configuration</a> <ul>
<li> <a href="?cover=print#Hadoop_Configuration"> Hadoop Configuration</a>
</li> <li> <a href="?cover=print#FUSE_Client_Configuration"> FUSE Client Configuration</a>
</li> <li> <a href="?cover=print#Creating_VO_and_User_Areas"> Creating VO and User Areas</a>
</li> <li> <a href="?cover=print#GridFTP_Configuration"> GridFTP Configuration</a>
</li> <li> <a href="?cover=print#GridFTP_Gratia_Transfer_Probe_Co"> GridFTP Gratia Transfer Probe Configuration</a>
</li> <li> <a href="?cover=print#BeStMan_Configuration"> BeStMan Configuration</a>
</li> <li> <a href="?cover=print#Hadoop_Storage_Probe_Configurati"> Hadoop Storage Probe Configuration</a>
</li></ul> 
</li> <li> <a href="?cover=print#Running_Services"> Running Services</a>
</li> <li> <a href="?cover=print#Validation_AN1"> Validation</a> <ul>
<li> <a href="?cover=print#GridFTP_Validation"> GridFTP Validation</a>
</li> <li> <a href="?cover=print#BeStMan_Validation"> BeStMan Validation</a>
</li></ul> 
</li> <li> <a href="?cover=print#Installing_Hadoop_Storage_Report"> Installing Hadoop Storage Reports (Optional)</a> <ul>
<li> <a href="?cover=print#Prerequisites"> Prerequisites</a>
</li> <li> <a href="?cover=print#Installation_AN1"> Installation</a>
</li> <li> <a href="?cover=print#Configuration_AN1"> Configuration</a>
</li></ul> 
</li> <li> <a href="?cover=print#Troubleshooting"> Troubleshooting</a> <ul>
<li> <a href="?cover=print#Hadoop"> Hadoop</a>
</li> <li> <a href="?cover=print#FUSE"> FUSE</a>
</li> <li> <a href="?cover=print#GridFTP"> GridFTP</a>
</li></ul> 
</li> <li> <a href="?cover=print#File_Locations"> File Locations</a>
</li> <li> <a href="?cover=print#Known_Issues"> Known Issues</a>
</li> <li> <a href="?cover=print#How_to_get_Help"> How to get Help?</a>
</li> <li> <a href="?cover=print#References"> References</a>
</li> <li> <a href="?cover=print#Comments"> Comments</a>
</li></ul> 
</div>
<p />
<strong>Purpose</strong>: The purpose of this document is to provide Hadoop based SE administrators the information on how to prepare, install and validate the SE.
<p />
on    
on    
<p />
<p /> <dl>
<dt> <img src="/twiki/pub/TWiki/TWikiDocGraphics/warning.gif" alt="ALERT!" title="ALERT!" width="16" height="16" border="0" />     <strong><font color="#ff0000"> WARNING! </font></strong> </dt><dd>  If you are installing Hadoop/Bestman from OSG 3.1, you will need to use <a href="/bin/view/Documentation/Release3/InstallHadoopSE" class="twikiLink">this</a> guide instead.  This guide details installing Hadoop 2.0 from the OSG 3.2 repositories.
</dd></dl> 
<p />
<h1><a name="Preparation"></a> Preparation </h1>
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Introduction"></a> Introduction </span></h2>
<p />
<a href="http://hadoop.apache.org/hdfs/" target="_top">Hadoop Distributed File System</a> (HDFS) is a scalable reliable distributed file system developed in the Apache project. It is based on map-reduce framework and design of the Google file system. The VDT distribution of Hadoop includes all components needed to operate a multi-terabyte storage site. Included are:
<p /> <ul>
<li> An <a href="https://sdm.lbl.gov/srm-wg/doc/SRM.v2.2.html" target="_top">SRM interface</a> for grid access; 
</li> <li> GridFTP-HDFS as transport layer; and  
</li> <li> A <a href="http://fuse.sourceforge.net/" target="_top">FUSE interface</a> for localized POSIX access.
</li> <li> <a href="http://hadoop.apache.org/" target="_top">Apache Hadoop</a>
</li></ul> 
<p />
The OSG packaging and distribution of Hadoop is based on YUM. All components are packaged as RPMs and are available from the OSG repositories.
It is also recommended that you enable <a href="http://fedoraproject.org/wiki/EPEL" target="_top">EPEL</a> repos.
<p />
<p />
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Note_on_upgrading_from_Hadoop_0"></a> Note on upgrading from Hadoop 0.20 </span></h2>
<p />
<p /> <dl>
<dt> <img src="/twiki/pub/TWiki/TWikiDocGraphics/help.gif" alt="HELP" title="HELP" width="16" height="16" border="0" />     <strong><font color="#ff0000"> NOTE </font></strong> </dt><dd>  If upgrading, make sure to follow these instructions <font color="#ff0000">BEFORE</font> any other instructions in this document.
</dd></dl> 
<p /> <ol>
<li> First, you must upgrade to the newest version of Hadoop-0.20.  Older versions may have dependency and upgrade problems.  Make sure that your version is at least <code>hadoop-0.20-0.20.2+737-26</code> (or newer) on all nodes.  (The important number is the 26.  Older release numbers may have upgrade problems).  You may need to specify this version specifically to ensure that the correct version is installed.  ie. <code>yum upgrade hadoop-0.20-0.20.2+737-26</code>.
</li> <li> Next, make sure all configuration and important files are backed up in case of catastrophic failure.  In particular, backup a copy of <code>hdfs-site.xml</code>, <code>core-site.xml</code> and important namenode files.
</li> <li> Now, upgrade to hadoop-2.0.0 using <code>yum upgrade hadoop</code>
</li> <li> Also, make sure to bring in any new packages using the relevant meta-package, such as <code>yum install osg-se-hadoop-namenode</code>, <code>yum install osg-se-hadoop-datanode</code> or <code>yum install osg-se-hadoop-srm</code>.
</li> <li> On the namenode, run <code>hadoop namenode -upgrade</code> to upgrade the meta-data catalog.
</li> <li> Follow the configuration instructions below for each node.  In particular, restore or modify <code>hdfs-site.xml</code> and <code>core-site.xml</code> then copy to all nodes.  For any nodes using fuse mounts, note that "hdfs#" should be changed to "hadoop-fuse-dfs#" in <code>/etc/fstab</code>.
</li></ol> 
<p />
<h1><a name="Requirements"></a> Requirements </h1>
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Architecture"></a> Architecture </span></h2>
<p />
<p /> <dl>
<dt> <img src="/twiki/pub/TWiki/TWikiDocGraphics/help.gif" alt="HELP" title="HELP" width="16" height="16" border="0" />     <strong><font color="#ff0000"> NOTE </font></strong> </dt><dd>  There are several important components to a storage element installation.  Throughout this document, it will be stated which node the relevant installation instructions apply to.  It can apply to one of the following:
</dd>  </dl><ul>
<li> <strong>Namenode</strong>:  You will have at least one namenode.  The name node functions as the directory server and coordinator of the hadoop cluster.  It houses all the meta-data for the hadoop cluster.  <font color="#ff0000"> The namenode and secondary namenode need to have a directory that they can both access on a shared filesystem so that they can exchange filesystem checkpoints. </font>
</li> <li> <strong>Secondary Namenode</strong>: This is a secondary machine that periodically merges updates to the HDFS file system back into the fsimage.  This dramatically improves startup and restart times.
</li> <li> <strong>Datanode</strong>:  You will have many datanodes.  Each data node stores large blocks of files to be stored on the hadoop cluster.
</li> <li> <strong>Client</strong>: This is a documentation shorthand that refers to any machine with the hadoop client commands and  <a href="http://fuse.sourceforge.net/" target="_top">FUSE</a> mount.  Any machine that needs a FUSE mount to access data in a POSIX-like fashion will need this.
</li> <li> <strong>GridFTP node</strong>:  This is a node with <a href="http://dev.globus.org/wiki/GridFTP" target="_top">Globus GridFTP</a>.  The GridFTP server for Hadoop can be very memory-hungry, up to 500MB/transfer in the default configuration.  You should plan accordingly to provision enough GridFTP servers to handle the bandwidth that your site can support.
</li> <li>  <strong>SRM node</strong>:  This node will contain the BeStMan SRM frontend for accessing the Hadoop cluster via the SRM protocol.  <a href="https://sdm.lbl.gov/bestman/" target="_top">BeStMan2 SRM</a>
</li></ul> 
<p />
Note that these components are not necessarily mutually exclusive.  For instance, you may consider having your GridFTP server co-located on the SRM node.  Alternatively, you can locate a client (or even a GridFTP node) co-located on each data node.  That way, each data node also acts as an access point to the hadoop cluster.
<p />
Please read the <a href="/bin/view/Storage/HadoopUnderstanding" class="twikiLink">planning document</a> to understand different components of the system. 
<p />
<p /> <dl>
<dt> <img src="/twiki/pub/TWiki/TWikiDocGraphics/help.gif" alt="HELP" title="HELP" width="16" height="16" border="0" />     <strong><font color="#ff0000"> NOTE </font></strong> </dt><dd>   Total installation time, on an average, should not exceed 8 to 24 man-hours. If your site needs further assistance to help expedite, please email <a href="mailto&#58;osg&#45;storage&#64;opensciencegrid&#46;org">osg-storage&#64;opensciencegrid.org</a> and <a href="mailto&#58;osg&#45;hadoop&#64;opensciencegrid&#46;org&#46;">osg-hadoop&#64;opensciencegrid.org.</a>
</dd></dl> 
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Host_and_OS"></a> Host and OS </span></h2>
<p />
Hadoop will run anywhere that Java is supported (including Solaris).  However, these instructions are for RedHat derivants (including Scientific Linux) because of the RPM based installation.  The current supported Operating Systems supported by the OSG are Red Hat Enterprise Linux 5, 6, 7, and variants (see <a href="/bin/view/Documentation/Release3/SupportedOperatingSystems" class="twikiLink">details...</a>). 
<p />
The HDFS prerequisites are: <ul>
<li> Minimum of 1 headnode (the namenode)
</li> <li> At least one node which will hold data, preferably at least 2.  Most sites will have 20 to 200 datanodes.
</li> <li> Working Yum and RPM installation on every system.
</li> <li> <code>fuse</code> kernel module and <code>fuse-libs</code>.
</li> <li> Java RPM.  If java isn't already installed we supply the Oracle jdk 1.6.0 rpm and it will come in as a dependency.  Oracle jdk is currently the only jdk supported by OSG so we highly recommend you use the version supplied.
</li></ul> 
<p />
<strong>Compatibility Note</strong> Note that versions of OpenAFS less than 1.4.7 and greater than 1.4.1 create nameless groups on Linux; these groups confuse Hadoop and prevent its components from starting up successfully. If you plan to install Hadoop on a Linux OpenAFS client, make sure you're running at least OpenAFS 1.4.7.
<p />
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Users"></a> Users </span></h2>
<p />
This installation will create following users unless they are already created.
<p />
<p />
<table cellspacing="0" cellpadding="0" border="0" class="twikinetWrapperTable" rules="none">
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableT twikinetWrapperTableTL"></td>
<td class="twikinetWrapperTableT twikinetWrapperTableTR"></td>
</tr>
<tr class="twikinetWrapperTableRow">
<td colspan="2" class="twikinetWrapperTableMain">
<table cellspacing="0" id="table1" cellpadding="0" class="twikiTable" rules="cols" border="1">
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<th bgcolor="#d8dde4" valign="top" class="twikiTableCol0 twikiFirstCol"> <a rel="nofollow" href="/bin/view/Documentation/Release3/InstallHadoop200SE?cover=print;sortcol=0;table=1;up=0#sorted_table" title="Sort by this column"><font color="#252b37">User</font></a> </th>
			<th bgcolor="#d8dde4" valign="top" class="twikiTableCol1 twikiLastCol"> <a rel="nofollow" href="/bin/view/Documentation/Release3/InstallHadoop200SE?cover=print;sortcol=1;table=1;up=0#sorted_table" title="Sort by this column"><font color="#252b37">Comment</font></a> </th>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> <code>bestman</code> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1 twikiLastCol"> Used by Bestman SRM server (needs sudo access). </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol twikiLast"> <code>hdfs</code> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1 twikiLastCol twikiLast"> Used by Hadoop to store data blocks and meta-data </td>
		</tr></table>
</td>
</tr>
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableB twikinetWrapperTableBL"></td>
<td class="twikinetWrapperTableB twikinetWrapperTableBR"></td>
</tr>
</table>
<p />
<p />
<p />
For this package to function correctly, you will have to create the users 
needed for grid operation.  Any user that can be authenticated should be created.
<p />
For grid-mapfile users, each line of the grid-mapfile is a certificate/user pair.  Each user in this file should be created on the server.
<p />
For gums users, this means that each user that can be authenticated by gums should be created on the server.
<p />
Note that these users must be kept in sync with the authentication method.  For instance, if new users or rules are added in gums, then new users should also be added here.
<p />
<p />
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Certificates"></a> Certificates </span></h2>
<p />
<p />
<table cellspacing="0" cellpadding="0" border="0" class="twikinetWrapperTable" rules="none">
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableT twikinetWrapperTableTL"></td>
<td class="twikinetWrapperTableT twikinetWrapperTableTR"></td>
</tr>
<tr class="twikinetWrapperTableRow">
<td colspan="2" class="twikinetWrapperTableMain">
<table cellspacing="0" id="table2" cellpadding="0" class="twikiTable" rules="cols" border="1">
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<th bgcolor="#d8dde4" valign="top" class="twikiTableCol0 twikiFirstCol"> <a rel="nofollow" href="/bin/view/Documentation/Release3/InstallHadoop200SE?cover=print;sortcol=0;table=2;up=0#sorted_table" title="Sort by this column"><font color="#252b37">Certificate</font></a> </th>
			<th bgcolor="#d8dde4" valign="top" class="twikiTableCol1"> <a rel="nofollow" href="/bin/view/Documentation/Release3/InstallHadoop200SE?cover=print;sortcol=1;table=2;up=0#sorted_table" title="Sort by this column"><font color="#252b37">User that owns certificate</font></a> </th>
			<th bgcolor="#d8dde4" valign="top" class="twikiTableCol2 twikiLastCol"> <a rel="nofollow" href="/bin/view/Documentation/Release3/InstallHadoop200SE?cover=print;sortcol=2;table=2;up=0#sorted_table" title="Sort by this column"><font color="#252b37">Path to certificate</font></a> </th>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> Host certificate </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> <code>root</code> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> <code>/etc/grid-security/hostcert.pem</code> <br> <code>/etc/grid-security/hostkey.pem</code> </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol twikiLast"> Bestman service certificate </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1 twikiLast"> <code>bestman</code> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol twikiLast"> <code>/etc/grid-security/bestman/bestmancert.pem</code> <br> <code>/etc/grid-security/bestman/bestmankey.pem</code> </td>
		</tr></table>
</td>
</tr>
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableB twikinetWrapperTableBL"></td>
<td class="twikinetWrapperTableB twikinetWrapperTableBR"></td>
</tr>
</table>
<p />
<p />
<a href="/bin/view/Documentation/Release3/InstallCertScripts" class="twikiLink">Instructions</a> to request a service certificate.
<p />
You will also need a copy of CA certificates (see below).  
Note that the <code>osg-se-hadoop-srm</code> and <code>osg-se-hadoop-gridftp</code> package will automatically install a certificate package 
but will not necessarily pick the cert package you expect.  For instance, certain installs
will prefer the <code>osg-ca-scripts</code> package to fulfill this requirement, which installs a set of scripts
to automatically update the certificates, but does not initialize the CA certs by default (you have to run it first).
For this reason, you may want to specifically install the cert package of your choice first, before installing Hadoop.
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Networking"></a> Networking </span></h2>
<p />
<p />
<p />
<!-- No variables can be defined because will not be visible in the including document
Need this because double quotes used in Y in TWikiPreferences or ICON cause problems (replaced with single ones) <ul>
<li> Set ALTy = <img src='/twiki/pub/TWiki/TWikiDocGraphics/choice-yes.gif' alt='Y' title='Y' width='16' height='16' border='0' />    
</li></ul> 
ALTy replacend inline whenever the icon is needed.
-->
For more details on overall Firewall configuration, please see our <a href="/bin/view/Documentation/Release3/FirewallInformation" class="twikiLink">Firewall documentation</a>.
<p />
<table cellspacing="0" cellpadding="0" border="0" class="twikinetWrapperTable" rules="none">
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableT twikinetWrapperTableTL"></td>
<td class="twikinetWrapperTableT twikinetWrapperTableTR"></td>
</tr>
<tr class="twikinetWrapperTableRow">
<td colspan="2" class="twikinetWrapperTableMain">
      <table cellspacing="0" id="table3" cellpadding="0" class="twikiTable" rules="cols" border="1"> 
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<th bgcolor="#d8dde4" valign="top" class="twikiTableCol0 twikiFirstCol"> <a rel="nofollow" href="/bin/view/Documentation/Release3/InstallHadoop200SE?cover=print;sortcol=0;table=3;up=0#sorted_table" title="Sort by this column"><font color="#252b37">Service Name</font></a> </th>
			<th bgcolor="#d8dde4" valign="top" class="twikiTableCol1"> <a rel="nofollow" href="/bin/view/Documentation/Release3/InstallHadoop200SE?cover=print;sortcol=1;table=3;up=0#sorted_table" title="Sort by this column"><font color="#252b37">Protocol</font></a> </th>
			<th bgcolor="#d8dde4" valign="top" class="twikiTableCol2"> <a rel="nofollow" href="/bin/view/Documentation/Release3/InstallHadoop200SE?cover=print;sortcol=2;table=3;up=0#sorted_table" title="Sort by this column"><font color="#252b37">Port Number</font></a> </th>
			<th bgcolor="#d8dde4" valign="top" class="twikiTableCol3"> <a rel="nofollow" href="/bin/view/Documentation/Release3/InstallHadoop200SE?cover=print;sortcol=3;table=3;up=0#sorted_table" title="Sort by this column"><font color="#252b37">Inbound</font></a> </th>
			<th bgcolor="#d8dde4" valign="top" class="twikiTableCol4"> <a rel="nofollow" href="/bin/view/Documentation/Release3/InstallHadoop200SE?cover=print;sortcol=4;table=3;up=0#sorted_table" title="Sort by this column"><font color="#252b37">Outbound</font></a> </th>
			<th bgcolor="#d8dde4" valign="top" class="twikiTableCol5 twikiLastCol"> <a rel="nofollow" href="/bin/view/Documentation/Release3/InstallHadoop200SE?cover=print;sortcol=5;table=3;up=0#sorted_table" title="Sort by this column"><font color="#252b37">Comment</font></a> </th>
		</tr> 
		<tr class="twikiTableEven twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> <a href="/bin/view/Documentation/GlossaryG#DefsGridResourceAllocationAndManagement" class="twikiAnchorLink">GRAM</a> callback </td>
			<td bgcolor="#ffffff" align="center" valign="top" class="twikiTableCol1"> tcp </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2"> <code>GLOBUS_TCP_PORT_RANGE</code> </td>
			<td bgcolor="#ffffff" align="center" valign="top" class="twikiTableCol3"> <img src='/twiki/pub/TWiki/TWikiDocGraphics/choice-yes.gif' alt='Y' title='Y' width='16' height='16' border='0' /> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol4"> &nbsp; </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol5 twikiLastCol"> contiguous range of ports </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> <a href="/bin/view/Documentation/GlossaryG#DefsGridResourceAllocationAndManagement" class="twikiAnchorLink">GRAM</a> callback </td>
			<td bgcolor="#f2f3f6" align="center" valign="top" class="twikiTableCol1"> tcp </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2"> <code>GLOBUS_TCP_SOURCE_RANGE</code> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol3"> &nbsp; </td>
			<td bgcolor="#f2f3f6" align="center" valign="top" class="twikiTableCol4"> <img src='/twiki/pub/TWiki/TWikiDocGraphics/choice-yes.gif' alt='Y' title='Y' width='16' height='16' border='0' /> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol5 twikiLastCol"> contiguous range of ports </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> <a href="/bin/view/Documentation/GlossaryG#DefsGridFTP" class="twikiAnchorLink">GridFTP</a> </td>
			<td bgcolor="#ffffff" align="center" valign="top" class="twikiTableCol1"> tcp </td>
			<td bgcolor="#ffffff" align="right" valign="top" class="twikiTableCol2"> 2811 and <code>GLOBUS_TCP_SOURCE_RANGE</code> </td>
			<td bgcolor="#ffffff" align="center" valign="top" class="twikiTableCol3"> <img src='/twiki/pub/TWiki/TWikiDocGraphics/choice-yes.gif' alt='Y' title='Y' width='16' height='16' border='0' /> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol4"> &nbsp; </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol5 twikiLastCol"> contiguous range of ports </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> <a href="/bin/view/Documentation/GlossaryS#DefsSrm" class="twikiAnchorLink">Storage Resource Manager</a> </td>
			<td bgcolor="#f2f3f6" align="center" valign="top" class="twikiTableCol1"> tcp </td>
			<td bgcolor="#f2f3f6" align="center" valign="top" class="twikiTableCol2"> 8080 </td>
			<td bgcolor="#f2f3f6" align="center" valign="top" class="twikiTableCol3"> <img src='/twiki/pub/TWiki/TWikiDocGraphics/choice-yes.gif' alt='Y' title='Y' width='16' height='16' border='0' /> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol4"> &nbsp; </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol5 twikiLastCol"> &nbsp; </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol twikiLast"> <a href="/bin/view/Documentation/GlossaryS#DefsSrm" class="twikiAnchorLink">Storage Resource Manager</a> </td>
			<td bgcolor="#ffffff" align="center" valign="top" class="twikiTableCol1 twikiLast"> tcp </td>
			<td bgcolor="#ffffff" align="center" valign="top" class="twikiTableCol2 twikiLast"> 8443 </td>
			<td bgcolor="#ffffff" align="center" valign="top" class="twikiTableCol3 twikiLast"> <img src='/twiki/pub/TWiki/TWikiDocGraphics/choice-yes.gif' alt='Y' title='Y' width='16' height='16' border='0' /> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol4 twikiLast"> &nbsp; </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol5 twikiLastCol twikiLast"> &nbsp; </td>
		</tr> </table>
</td>
</tr>
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableB twikinetWrapperTableBL"></td>
<td class="twikinetWrapperTableB twikinetWrapperTableBR"></td>
</tr>
</table>
<p />
<p />
<p />
<p />
<p />
<p />
<h1><a name="Install_the_Yum_Repositories_req"></a> Install the Yum Repositories required by OSG </h1>
<p />
The OSG RPMs currently support Red Hat Enterprise Linux 5, 6, 7, and variants (see <a href="/bin/view/Documentation/Release3/SupportedOperatingSystems" class="twikiLink">details...</a>).
<p />
OSG RPMs are distributed via the OSG yum repositories. Some packages depend on packages distributed via the <a href="http://fedoraproject.org/wiki/EPEL" target="_top">EPEL</a> repositories. So both repositories must be enabled.
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Install_EPEL"></a> Install EPEL </span></h2>
<p /> <ul>
<li> Install the EPEL repository, if not already present. <strong>Note:</strong> This enables EPEL by default. Choose the right version to match your OS version. <pre class="rootscreen">
<font color="#ff0000"># EPEL 5 (For RHEL 5, CentOS 5, and SL 5) </font>
[root@client ~]$ curl -O https://dl.fedoraproject.org/pub/epel/epel-release-latest-5.noarch.rpm
[root@client ~]$ rpm -Uvh epel-release-latest-5.noarch.rpm
<font color="#ff0000"># EPEL 6 (For RHEL 6, CentOS 6, and SL 6) </font>
[root@client ~]$ rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-6.noarch.rpm
<font color="#ff0000"># EPEL 7 (For RHEL 7, CentOS 7, and SL 7) </font>
[root@client ~]$ rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm</pre>       <strong>WARNING</strong>: if you have your own mirror or configuration of the EPEL repository, you <strong>MUST</strong> verify that the OSG repository has a better yum priority than EPEL (<a href="/bin/view/Documentation/Release3/InstallBestPractices#YumPriorities" class="twikiAnchorLink">details</a>). Otherwise, you will have strange dependency resolution (<em>depsolving</em>) issues.
</li></ul> 
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Install_the_Yum_priorities_packa"></a> Install the Yum priorities package </span></h2>
<p />
For packages that exist in both OSG and EPEL repositories, it is important to prefer the OSG ones or else OSG software installs may fail. Installing the Yum priorities package enables the repository priority system to work.
<p /> <ol>
<li> <p>Choose the correct package name based on your operating system’s major version:</p> <ul>
<li> For EL&nbsp;5 systems, use <code>yum-priorities</code>
</li> <li> For EL&nbsp;6 and EL&nbsp;7 systems, use <code>yum-plugin-priorities</code>
</li></ul> 
</li> <li> <p>Install the Yum priorities package:</p>       <pre class="rootscreen">[root@client ~]$ yum install <em>PACKAGE</em></pre>       <p>Replace <em><code>PACKAGE</code></em> with the package name from the previous step.</p>
</li> <li> <p>Ensure that <code>/etc/yum.conf</code> has the following line in the <code>[main]</code> section (particularly when using ROCKS), thereby enabling Yum plugins, including the priorities one:</p>       <pre class="file">plugins=1</pre>       <strong>NOTE</strong>: If you do not have a required key you can force the installation using <code>--nogpgcheck</code>; e.g., <code>yum install --nogpgcheck yum-priorities</code>.
</li></ol> 
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Install_OSG_Repositories"></a> Install OSG Repositories </span></h2>
<p />
<!--   1. <p>First, determine which OSG series you will be installing; 3.1 or 3.2.  The OSG 3.1 and 3.2 series are each well tested and contain the entire OSG software stack.  The 3.1 series continues to support all packages that have been released throughout its lifetime, while the 3.2 series contains newer versions of software (including HTCondor, Hadoop, glideinWMS) and removes support for obsolete packages (including CEMonitor).  Initially, most packages are identical between 3.1 and 3.2, but we expect the new series to diverge over time. <br/><br/>Note that some packages (eg, Hadoop) do not inter-operate between 3.1 and 3.2, and therefore require all nodes to use the same series.</p> -->
<p />
<ol>
   <li>
      <p>If you are upgrading from OSG 3.1 (or 3.2) to OSG 3.2 (or 3.3), remove the old OSG repository definition files and clean the Yum cache:</p>         <pre class="rootscreen">[root@client ~]$ yum clean all
[root@client ~]$ rpm -e osg-release</pre>       <p>This step ensures that local changes to <code>*.repo</code> files will not block the installation of the new OSG repositories. After this step, <code>*.repo</code> files that have been changed will exist in <code>/etc/yum.repos.d/</code> with the <code>*.rpmsave</code> extension. After installing the new OSG repositories (the next step) you may want to apply any changes made in the <code>*.rpmsave</code> files to the new <code>*.repo</code> files.</p>
   </li>
   <li>
      <p>Install the OSG repositories using one of the following methods depending on your EL version:</p>      <ol>
         <li>
            <p>For EL versions greater than EL5, install the files directly from <code>repo.grid.iu.edu</code>:</p>            <pre class="rootscreen">[root@client ~]$ rpm -Uvh <font color="#ff0000">URL</font></pre>            <p>Where <code><font color="#ff0000">URL</font></code> is one of the following:</p> <table cellspacing="0" cellpadding="0" border="0" class="twikinetWrapperTable" rules="none">
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableT twikinetWrapperTableTL"></td>
<td class="twikinetWrapperTableT twikinetWrapperTableTR"></td>
</tr>
<tr class="twikinetWrapperTableRow">
<td colspan="2" class="twikinetWrapperTableMain">
<table cellspacing="0" id="table4" cellpadding="0" class="twikiTable" rules="cols" border="1">
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<th bgcolor="#d8dde4" valign="top" class="twikiTableCol0 twikiFirstCol"> <a rel="nofollow" href="/bin/view/Documentation/Release3/InstallHadoop200SE?cover=print;sortcol=0;table=4;up=0#sorted_table" title="Sort by this column"><font color="#252b37">Series</font></a> </th>
			<th bgcolor="#d8dde4" align="center" valign="top" class="twikiTableCol1"> <a rel="nofollow" href="/bin/view/Documentation/Release3/InstallHadoop200SE?cover=print;sortcol=1;table=4;up=0#sorted_table" title="Sort by this column"><font color="#252b37">EL6 URL (for RHEL 6, CentOS 6, or SL 6)</font></a> </th>
			<th bgcolor="#d8dde4" align="center" valign="top" class="twikiTableCol2 twikiLastCol"> <a rel="nofollow" href="/bin/view/Documentation/Release3/InstallHadoop200SE?cover=print;sortcol=2;table=4;up=0#sorted_table" title="Sort by this column"><font color="#252b37">EL7 URL (for RHEL 7, CentOS 7, or SL 7)</font></a> </th>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<th bgcolor="#d8dde4" valign="top" class="twikiTableCol0 twikiFirstCol"> <font color="#252b37">OSG 3.2</font> </th>
			<td bgcolor="#ffffff" align="center" valign="top" class="twikiTableCol1"> <code>https://repo.grid.iu.edu/osg/3.2/osg-3.2-el6-release-latest.rpm</code> </td>
			<td bgcolor="#ffffff" align="center" valign="top" class="twikiTableCol2 twikiLastCol"> N/A </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<th bgcolor="#d8dde4" valign="top" class="twikiTableCol0 twikiFirstCol twikiLast"> <font color="#252b37">OSG 3.3</font> </th>
			<td bgcolor="#f2f3f6" align="center" valign="top" class="twikiTableCol1 twikiLast"> <code>https://repo.grid.iu.edu/osg/3.3/osg-3.3-el6-release-latest.rpm</code> </td>
			<td bgcolor="#f2f3f6" align="center" valign="top" class="twikiTableCol2 twikiLastCol twikiLast"> <code>https://repo.grid.iu.edu/osg/3.3/osg-3.3-el7-release-latest.rpm</code> </td>
		</tr></table>
</td>
</tr>
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableB twikinetWrapperTableBL"></td>
<td class="twikinetWrapperTableB twikinetWrapperTableBR"></td>
</tr>
</table>
         </li>
         <li>
            <p>For EL5, download the repo file and install it using the following:</p>
            <pre class="rootscreen">[root@client ~]$ curl -O https://repo.grid.iu.edu/osg/3.2/osg-3.2-el5-release-latest.rpm
[root@client ~]$ rpm -Uvh osg-3.2-el5-release-latest.rpm</pre>
         </li>
      </ol>
   </li>
</ol>
<p />
For more details, please see our <a href="/bin/view/Documentation/Release3/YumRepositories" class="twikiLink">yum repository documentation</a>.
<p />
<p />
<p />
<strong>NOTE:</strong> The versions of Hadoop in OSG series 3.1 and 3.2 (ie, Hadoop 0.20 and 2.0.0) do not inter-operate.  In order to use Hadoop 2.0.0, <em>all</em> nodes in the hadoop system (namenode, secondary namenode, datanodes, srm/gridftp nodes and all client nodes) must update to OSG 3.2 and Hadoop 2.0.0.
<p />
<h1><a name="Initializing_Certificate_Authori"></a> Initializing Certificate Authority </h1>
<p />
This is needed by GridFTP and SRM nodes, but it is recommended for all nodes in the cluster.
<p />
<p />
<h3><a name="Enable_and_Start_fetch_crl"></a> Enable and Start <code>fetch-crl</code> </h3>
To enable fetch-crl (fetch Certificate Revocation Lists) services by default on the node:
<pre class="rootscreen">
<font color="#ff0000"># For RHEL 5, CentOS 5, and SL5 </font>
[root@client ~]$ /sbin/chkconfig fetch-crl3-boot on
[root@client ~]$ /sbin/chkconfig fetch-crl3-cron on
<font color="#ff0000"># For RHEL 6, CentOS 6, and SL6, or OSG 3 _older_ than 3.1.15 </font>
[root@client ~]$ /sbin/chkconfig fetch-crl-boot on
[root@client ~]$ /sbin/chkconfig fetch-crl-cron on
<font color="#ff0000"># For RHEL 7, CentOS 7, and SL7 </font>
[root@client ~]$ systemctl enable fetch-crl-boot
[root@client ~]$ systemctl enable fetch-crl-cron
</pre>
To start fetch-crl:
<pre class="rootscreen">
<font color="#ff0000"># For RHEL 5, CentOS 5, and SL5 </font>
[root@client ~]$ /sbin/service fetch-crl3-boot start
[root@client ~]$ /sbin/service fetch-crl3-cron start
<font color="#ff0000"># For RHEL 6, CentOS 6, and SL6, or OSG 3 _older_ than 3.1.15 </font>
[root@client ~]$ /sbin/service fetch-crl-boot start
[root@client ~]$ /sbin/service fetch-crl-cron start
<font color="#ff0000"># For RHEL 7, CentOS 7, and SL7 </font>
[root@client ~]$ systemctl start fetch-crl-boot
[root@client ~]$ systemctl start fetch-crl-cron
</pre>
<strong>NOTE</strong>: while it is necessary to start <code>fetch-crl-cron</code> in order to have it active, <code>fetch-crl-boot</code> is started automatically at boot time if enabled. The start command will run <code>fetch-crl-boot</code> at the moment when it is invoked and it may take some time to complete.
<p />
<h3><a name="Configure_fetch_crl"></a> Configure <code>fetch-crl</code> </h3>
To modify the times that fetch-crl-cron runs, edit <code>/etc/cron.d/fetch-crl</code> (or <code>/etc/cron.d/fetch-crl3</code> depending on the version you have).
<p />
<p />
By default, <code>fetch-crl</code> connects directly to the remote CA; this is inefficient and potentially harmful if done simultaneously by many nodes (e.g. all the worker nodes of a big cluster).  We recommend you provide a HTTP proxy (such as squid) the worker nodes can connect to. <a href="/bin/view/Documentation/Release3/InstallFrontierSquid" class="twikiLink">Here</a> are instructions to install a squid proxy.
<p />
To configure fetch-crl to use an HTTP proxy server: <ul>
<li> If using <code>fetch-crl</code> version 2 (the <code>fetch-crl</code> package on RHEL5 only), then create the file  <code>/etc/sysconfig/fetch-crl</code> and add the following line: <pre class="file">
export http_proxy=<font color="#ff0000">http://your.squid.fqdn:port</font>
</pre> Adjust the URL appropriately for your proxy server.
</li> <li> If using <code>fetch-crl</code> version 3 on RHEL5 via the <code>fetch-crl3</code> package or on RHEL6/RHEL7 via the <code>fetch-crl</code> package, then create or edit the file <code>/etc/fetch-crl3.conf</code> (RHEL5) or <code>/etc/fetch-crl.conf</code> (RHEL6/RHEL7) and add the following line: <pre class="file">
http_proxy=<font color="#ff0000">http://your.squid.fqdn:port</font>
</pre> Again, adjust the URL appropriately for your proxy server.
</li></ul> 
<p />
Note that the <code><b>nosymlinks</b></code> option in the configuration files refers to ignoring links within the certificates directory (e.g. two different names for the same file). It is perfectly fine if the path of the CA certificates directory itself (<code>infodir</code>) is a link to a directory.
<p />
Any modifications to the configuration file will be preserved during an RPM update.
<p />
For more details, please see our <a href="/bin/view/Documentation/Release3/InstallCertAuth" class="twikiLink">fetch-crl documentation</a>.
<p />
<p />
Current versions of fetch-crl and fetch-crl3 produce more output. It is possible to send the output to syslog instead of the default email system. To do so: <ol>
<li> Change the configuration file to enable syslog: <pre class="file">
logmode = syslog
syslogfacility = daemon</pre>
</li> <li> Make sure the file <code>/var/log/daemon</code> exists, e.g. touching the file
</li> <li> Change <code>/etc/logrotate.d</code> files to rotate it 
</li></ol> 
<p />
<p />
<p />
<p />
<h1><a name="Installation"></a> Installation </h1>
<p />
Installation depends on the node you are installing:
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Namenode_Installation"></a> Namenode Installation </span></h2>
<pre class="rootscreen">
[root@client ~]$ yum install osg-se-hadoop-namenode
</pre>
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Secondary_Namenode_Installation"></a> Secondary Namenode Installation </span></h2>
<pre class="rootscreen">
[root@client ~]$ yum install osg-se-hadoop-secondarynamenode
</pre>
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Datanode_Installation"></a> Datanode Installation </span></h2>
<pre class="rootscreen">
[root@client ~]$ yum install osg-se-hadoop-datanode
</pre>
<p />
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Client_FUSE_Installation"></a> Client/FUSE Installation </span></h2>
<p />
<pre class="rootscreen">
[root@client ~]$ yum install osg-se-hadoop-client
</pre>
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Standalone_Gridftp_Node_Installa"></a> Standalone Gridftp Node Installation </span></h2>
<p />
<pre class="rootscreen">
[root@client ~]$ yum install osg-se-hadoop-gridftp
</pre>
<p />
If you are using GUMS authorization, the follow rpms need to be installed as well:
<p />
<pre class="rootscreen">
[root@client ~]$ yum install lcmaps-plugins-gums-client
[root@client ~]$ yum install lcmaps-plugins-basic
</pre>
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="SRM_Node_Installation"></a> SRM Node Installation </span></h2>
<p />
<pre class="rootscreen">
[root@client ~]$ yum install osg-se-hadoop-srm
</pre>
<p />
<p /> <dl>
<dt> <img src="/twiki/pub/TWiki/TWikiDocGraphics/help.gif" alt="HELP" title="HELP" width="16" height="16" border="0" />     <strong><font color="#ff0000"> NOTE </font></strong> </dt><dd>  If you are using a single system to host the SRM software and the gridftp node, you'll also need to install the <code>osg-se-hadoop-gridftp</code> rpm as well.
</dd></dl> 
<p />
<h1><a name="Configuration"></a> Configuration </h1>
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Hadoop_Configuration"></a> Hadoop Configuration </span></h2>
<p />
<p /> <dl>
<dt> <img src="/twiki/pub/TWiki/TWikiDocGraphics/help.gif" alt="HELP" title="HELP" width="16" height="16" border="0" />     <strong><font color="#ff0000"> NOTE </font></strong> </dt><dd>  Needed by: Hadoop namenode, Hadoop datanodes, Hadoop client, GridFTP, SRM
</dd></dl> 
<p />
Hadoop configuration is needed by every node in the hadoop cluster.  However, in most cases, you can do the configuration once and copy it to all nodes in the cluster (possibly using your favorite configuration management tool).  Special configuration for various special components is given in the below sections.
<p />
Hadoop configuration is stored in <code>/etc/hadoop/conf</code>.  However, by default, these files are mostly blank.  OSG provides a sample configuration in <code>/etc/hadoop/conf.osg</code> with most common values filled in.  You will need to copy these into <code>/etc/hadoop/conf</code> before they become active. Please let us know if there are any common values that should be added/changed across the whole grid.  You will likely need to modify <code>hdfs-site.xml</code> and <code>core-site.xml</code>.  Review all the settings in these files, but listed below are common settings to modify:
<p />
<table cellspacing="0" cellpadding="0" border="0" class="twikinetWrapperTable" rules="none">
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableT twikinetWrapperTableTL"></td>
<td class="twikinetWrapperTableT twikinetWrapperTableTR"></td>
</tr>
<tr class="twikinetWrapperTableRow">
<td colspan="2" class="twikinetWrapperTableMain">
<table cellspacing="0" id="table5" cellpadding="0" class="twikiTable" rules="cols" border="1">
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> File </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> Setting </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2"> Example </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol3 twikiLastCol"> Comments </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> <code>core-site.xml</code> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> fs.default.name </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2"> hdfs://namenode.domain.tld.:9000 </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol3 twikiLastCol"> This is the address of the namenode </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> <code>core-site.xml</code> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> hadoop.tmp.dir </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2"> /data/scratch </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol3 twikiLastCol"> Scratch temp directory used by Hadoop </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> <code>core-site.xml</code> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> hadoop.log.dir </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2"> /var/log/hadoop-hdfs </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol3 twikiLastCol"> Log directory used by Hadoop </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> <code>core-site.xml</code> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> dfs.umaskmode </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2"> 002 </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol3 twikiLastCol"> umask for permissions used by default </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> <code>hdfs-site.xml</code> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> dfs.block.size </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2"> 134217728 </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol3 twikiLastCol"> Block size: 128MB by default </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> <code>hdfs-site.xml</code> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> dfs.replication </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2"> 2 </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol3 twikiLastCol"> Default replication factor.  Generally the same as dfs.replication.min/max </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> <code>hdfs-site.xml</code> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> dfs.datanode.du.reserved </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2"> 100000000 </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol3 twikiLastCol"> How much free space hadoop will reserve for non-Hadoop usage </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> <code>hdfs-site.xml</code> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> dfs.datanode.handler.count </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2"> 20 </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol3 twikiLastCol"> Number of server threads for datanodes.  Increase if you have many more client connections </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> <code>hdfs-site.xml</code> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> dfs.namenode.handler.count </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2"> 40 </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol3 twikiLastCol"> Number of server threads for namenodes.  Increase if you need more connections </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol twikiLast"> <code>hdfs-site.xml</code> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1 twikiLast"> dfs.http.address </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLast"> namenode.domain.tld.:50070 </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol3 twikiLastCol twikiLast"> Web address for dfs health monitoring page </td>
		</tr></table>
</td>
</tr>
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableB twikinetWrapperTableBL"></td>
<td class="twikinetWrapperTableB twikinetWrapperTableBR"></td>
</tr>
</table>
<p />
See <a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml" target="_top">http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml</a> for more parameters to configure.
<p />
<p /> <dl>
<dt> <img src="/twiki/pub/TWiki/TWikiDocGraphics/help.gif" alt="HELP" title="HELP" width="16" height="16" border="0" />     <strong><font color="#ff0000"> NOTE </font></strong> </dt><dd>  Namenodes must have a <code>/etc/hosts_exclude</code> present
</dd></dl> 
<p />
<h3><a name="Special_namenode_instructions_fo"></a> Special namenode instructions for brand new installs </h3>
<p />
If this is a new installation (<font color="#ff0000">and only if this is a brand new installation</font>), you should run the following command as the <code>hdfs</code> user. (Otherwise, be sure to <code>chown</code> your storage directory to hdfs after running):
<p />
<pre class="screen">
hadoop namenode -format
</pre>
<p />
This will initialize the storage directory on your namenode
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="FUSE_Client_Configuration"></a> FUSE Client Configuration </span></h2>
<p />
<p /> <dl>
<dt> <img src="/twiki/pub/TWiki/TWikiDocGraphics/help.gif" alt="HELP" title="HELP" width="16" height="16" border="0" />     <strong><font color="#ff0000"> NOTE </font></strong> </dt><dd>  Needed by: Hadoop client and SRM node.  Recommended but not neccessary for GridFTP nodes.
</dd></dl> 
<p />
A FUSE mount is required on any node that you would like to use standard POSIX-like commands on the Hadoop filesystem.  FUSE (or "file system in user space") is a way to access Hadoop using typical UNIX directory commands (ie POSIX-like access).  Note that not all advanced functions of a full POSIX-compliant file system are necessarily available.
<p />
FUSE is typically installed as part of this installation, but, if you are running a customized or non-standard system, make sure that the fuse kernel module is installed and loaded with <code>modprobe fuse</code>.  
<p />
You can add the FUSE to be mounted at boot time by adding the following line to <code>/etc/fstab</code>:
<pre class="file">
hadoop-fuse-dfs# <font color="#ff0000">/mnt/hadoop</font> fuse server=<font color="#ff0000">namenode.host</font>,port=9000,rdbuffer=131072,allow_other 0 0
</pre>
Be sure to change the <code>/mnt/hadoop</code> mount point and <code>namenode.host</code> to match your local configuration.  To match the help documents, we recommend using <code>/mnt/hadoop</code> as your mountpoint.
<p />
Once your <code>/etc/fstab</code> is updated, to mount FUSE run:
<p />
<pre class="rootscreen">
[root@client ~]$ mkdir /mnt/hadoop
[root@client ~]$ mount /mnt/hadoop
</pre>
<p />
When mounting the HDFS FUSE mount, you will see the following harmless warnings printed to the screen:
<p />
<pre class="rootscreen">
# mount /mnt/hadoop
INFO fuse_options.c:162 Adding FUSE arg /mnt/hadoop
INFO fuse_options.c:110 Ignoring option allow_other
</pre>
<p />
If you have troubles mounting FUSE refer to <a href="/bin/view/Documentation/Release3/InstallHadoop200SE#TroubFuseDeb" class="twikiCurrentTopicLink twikiAnchorLink">Running FUSE in Debug Mode</a> in the Troubleshooting section.
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Creating_VO_and_User_Areas"></a> Creating VO and User Areas </span></h2>
<p />
<p /> <dl>
<dt> <img src="/twiki/pub/TWiki/TWikiDocGraphics/help.gif" alt="HELP" title="HELP" width="16" height="16" border="0" />     <strong><font color="#ff0000"> NOTE </font></strong> </dt><dd>  Grid Users are needed by GridFTP and SRM nodes.  VO areas are common to all nodes.
</dd></dl> 
<p />
<p />
For this package to function correctly, you will have to create the users 
needed for grid operation.  Any user that can be authenticated should be created.
<p />
For grid-mapfile users, each line of the grid-mapfile is a certificate/user pair.  Each user in this file should be created on the server.
<p />
For gums users, this means that each user that can be authenticated by gums should be created on the server.
<p />
Note that these users must be kept in sync with the authentication method.  For instance, if new users or rules are added in gums, then new users should also be added here.
<p />
<p />
Prior to starting basic day-to-day operations, it is important to create dedicated areas for each VO and/or user. This is similar to user management in simple UNIX filesystems. Create (and maintain) usernames and groups with UIDs and GIDs on <strong>all nodes</strong>. These are maintained in basic system files such as <code>/etc/passwd</code> and <code>/etc/group</code>.
<p />
<p /> <dl>
<dt> <img src="/twiki/pub/TWiki/TWikiDocGraphics/help.gif" alt="HELP" title="HELP" width="16" height="16" border="0" />     <strong><font color="#ff0000"> NOTE </font></strong> </dt><dd>  In the examples below It is assumed a FUSE mount is set to <code>/mnt/hadoop</code>.  As an alternative <code>hadoop fs</code> commands could have been used.
</dd></dl> 
<p />
For clean HDFS operations and filesystem management:
<p />
(a) Create top-level VO subdirectories under <code>/mnt/hadoop</code>.
<p />
Example: 
<p />
<pre class="rootscreen">
[root@client ~]$ mkdir /mnt/hadoop/cms
[root@client ~]$ mkdir /mnt/hadoop/dzero
[root@client ~]$ mkdir /mnt/hadoop/sbgrid
[root@client ~]$ mkdir /mnt/hadoop/fermigrid
[root@client ~]$ mkdir /mnt/hadoop/cmstest
[root@client ~]$ mkdir /mnt/hadoop/osg
</pre>
<p />
(b) Create individual top-level user areas, under each VO area, as needed.
<p />
<pre class="rootscreen">
[root@client ~]$ mkdir -p /mnt/hadoop/cms/store/user/tanyalevshina
[root@client ~]$ mkdir -p /mnt/hadoop/cms/store/user/michaelthomas
[root@client ~]$ mkdir -p /mnt/hadoop/cms/store/user/brianbockelman
[root@client ~]$ mkdir -p /mnt/hadoop/cms/store/user/douglasstrain
[root@client ~]$ mkdir -p /mnt/hadoop/cms/store/user/abhisheksinghrana
</pre>
<p />
(c) Adjust username:group ownership of each area. 
<p />
<pre class="rootscreen">
[root@client ~]$ chown -R cms:cms /mnt/hadoop/cms
[root@client ~]$ chown -R sam:sam /mnt/hadoop/dzero

[root@client ~]$ chown -R michaelthomas:cms /mnt/hadoop/cms/store/user/michaelthomas
</pre>
<p />
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="GridFTP_Configuration"></a> GridFTP Configuration </span></h2>
<p />
gridftp-hdfs reads the Hadoop configuration file to learn how to talk to Hadoop.  By now, you should have followed the instruction for installing hadoop as detailed in the previous section as well as created the proper users/directories.  
<p />
The default settings in <code>/etc/gridftp.conf</code> along with <code>/etc/gridftp.d/gridftp-hdfs.conf</code> are used by the init.d script and should be ok for most installations.
The file <code>/etc/gridftp-hdfs/gridftp-debug.conf</code> is used by <code>/usr/bin/gridftp-hdfs-standalone</code> for starting up the GridFTP server in a testing mode.
Any additional config files under <code>/etc/gridftp.d</code> will be used for both the init.d and standalone GridFTP server.
<code>/etc/sysconfig/gridftp-hdfs</code> contains additional site-specific environment variables that are used by the gridftp-hdfs dsi module in both the init.d and standalone GridFTP server.
Some of the environment variables that can be used in <code>/etc/sysconfig/gridftp-hdfs</code> include:
<p />
<table cellspacing="0" cellpadding="0" border="0" class="twikinetWrapperTable" rules="none">
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableT twikinetWrapperTableTL"></td>
<td class="twikinetWrapperTableT twikinetWrapperTableTR"></td>
</tr>
<tr class="twikinetWrapperTableRow">
<td colspan="2" class="twikinetWrapperTableMain">
<table cellspacing="0" id="table6" cellpadding="0" class="twikiTable" rules="cols" border="1">
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> Option Name </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> Needs Editing? </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> Suggested value </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> GRIDFTP_HDFS_REPLICA_MAP </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> No </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> File containing a list of paths and replica values for setting the default # of replicas for specific file paths </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> GRIDFTP_BUFFER_COUNT </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> No </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> The number of 1MB memory buffers used to reorder data streams before writing them to Hadoop </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> GRIDFTP_FILE_BUFFER_COUNT </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> No </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> The number of 1MB file-based buffers used to reorder data streams before writing them to Hadoop </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> GRIDFTP_SYSLOG </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> No </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> Set this to 1 in case if you want to send transfer activity data to syslog (only used for the <span class="twikiNewLink">HadoopViz<a href="/bin/edit/Documentation/Release3/HadoopViz?topicparent=Documentation/Release3.InstallHadoop200SE" rel="nofollow" title="HadoopViz (this topic does not yet exist; you can create it)">?</a></span> application) </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> GRIDFTP_HDFS_MOUNT_POINT </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> Maybe </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> The location of the FUSE mount point used during the Hadoop installation.  Defaults to /mnt/hadoop.  This is needed so that gridftp-hdfs can convert fuse paths on the incoming URL to native Hadoop paths. <strong>Note:</strong> this does not imply you need FUSE mounted on GridFTP nodes! </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> GRIDFTP_LOAD_LIMIT </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> No </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> GridFTP will refuse to start new transfers if the load on the GridFTP host is higher than this number; defaults to 20. </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol twikiLast"> TMPDIR </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1 twikiLast"> Maybe </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol twikiLast"> The temp directory where the file-based buffers are stored.  Defaults to /tmp. </td>
		</tr></table>
</td>
</tr>
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableB twikinetWrapperTableBL"></td>
<td class="twikinetWrapperTableB twikinetWrapperTableBR"></td>
</tr>
</table>
<p />
<code>/etc/sysconfig/gridftp-hdfs</code> is also a good place to increase per-process resource limits. For example, many installations will require more than the default number of open files (<code>ulimit -n</code>).
<p />
Lastly, you will need to configure an authorization mechanism for GridFTP.  Two options are available: Gums and gridmap-file.
<p />
<h3><a name="GridFTP_Authorization_Gums"></a> GridFTP Authorization: Gums </h3>
<p />
<p />
By default, GridFTP uses a gridmap file, found in <code>/etc/grid-security/gridmap-file</code>.
If you want to use GUMS security (recommended), you will need to enable it using the following steps:
<p />
First, edit <code>/etc/grid-security/gsi-authz.conf</code> and uncomment the globus callout.
<pre class="file">
globus_mapping liblcas_lcmaps_gt4_mapping.so lcmaps_callout
</pre> 
Note that this used to be the full path to the library (<code>/usr/lib64</code> or <code>/usr/lib</code>), but now we 
rely on the linker for proper resolution in this file.
<p />
Next edit <code>/etc/lcmaps.db</code> to edit your gums information:
<pre class="file">

...
gumsclient = "lcmaps_gums_client.mod"
             "-resourcetype ce"
             "-actiontype execute-now"
             "-capath /etc/grid-security/certificates"
             "-cert   /etc/grid-security/hostcert.pem"
             "-key    /etc/grid-security/hostkey.pem"
             "--cert-owner root"
# Change this URL to your GUMS server
             "--endpoint https://<font color="#ff0000">gums.fnal.gov:8443</font>/gums/services/GUMSXACMLAuthorizationServicePort"
</pre> 
<p />
If you would like to run SAZ, you will need to enable the relevant lines in the above file as well (more documentation to be added later).
<p />
<p />
To troubleshoot LCMAPS authorization, you can add the following to <code>/etc/sysconfig/gridftp-hdfs</code> and choose a higher debug level:
<pre class="file">
# level 0: no messages, 1: errors, 2: also warnings, 3: also notices,
#  4: also info, 5: maximum debug
LCMAPS_DEBUG_LEVEL=2
</pre>
Output goes to <code>/var/log/messages</code> by default. 
<p />
<h3><a name="GridFTP_Authorization_Gridmap_fi"></a> GridFTP Authorization: Gridmap-file </h3>
<p />
<p />
By default, GridFTP uses a gridmap file, found in <code>/etc/grid-security/grid-mapfile</code>.
This file is not generated by default.  There are two ways you can generate this file.
You can generate this file manually, by including DN/username combinations.  This is most
useful for debugging.  Otherwise, you can install edg-mkgridmap, which will periodically contact a list of VOMS servers that you specify. It assembles a list of users from those servers and creates a grid-mapfile.  This grid-mapfile serves both as a list of authorized users and provides a mapping from user dns to local user ids. 
<p />
To install edg_mkgridmap, perform the following steps
<pre class="rootscreen">
yum install edg-mkgridmap
</pre>
Review <code>/etc/edg-mkgridmap.conf</code> to make sure that it has all VOs that you are interested in and also to comment out any VOs that you do not wish to support. 
<pre class="rootscreen">
vi /etc/edg-mkgridmap.conf
</pre>
This utility <code>edg-mkgridmap</code> runs as a cronjob <code>/etc/cron.d/edg-mkgridmap-cron</code> (by default every 6 hours). You can also run <code>edg-mkgridmap</code> manually to see that it generates <code>/etc/grid-security/grid-mapfile</code>.  
<pre class="rootscreen">
edg-mkgridmap
</pre>
Then, you can enable/start the service.
<pre class="rootscreen">
/sbin/service edg-mkgridmap start
/sbin/chkconfig edg-mkgridmap on
</pre>
<p />
You can read more on this page:
<a href="/bin/view/Documentation/Release3/InstallComputeElement#5_2_Using_edg_mkgridmap_for_auth" class="twikiAnchorLink">edg_mkgridmap (on the CE)</a>
<p />
<p />
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="GridFTP_Gratia_Transfer_Probe_Co"></a> GridFTP Gratia Transfer Probe Configuration </span></h2>
<p />
<p /> <dl>
<dt> <img src="/twiki/pub/TWiki/TWikiDocGraphics/help.gif" alt="HELP" title="HELP" width="16" height="16" border="0" />     <strong><font color="#ff0000"> NOTE </font></strong> </dt><dd>  Needed by GridFTP node only.
</dd></dl> 
<p />
The Gratia probe requires the file <code>user-vo-map</code> to exist and be up to date. This file is created and updated by the <code>gums-client</code> package that comes in as a dependency of <code>osg-se-hadoop-gridftp</code> or <code>osg-gridftp-hdfs</code>.  Assuming you installed GridFTP using the <code>osg-se-hadoop-gridftp</code> rpm, the Gratia Transfer Probe will already be installed.
<p />
<p />
<p />
Here are the most relevant file and directory locations:
<p />
<table cellspacing="0" cellpadding="0" border="0" class="twikinetWrapperTable" rules="none">
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableT twikinetWrapperTableTL"></td>
<td class="twikinetWrapperTableT twikinetWrapperTableTR"></td>
</tr>
<tr class="twikinetWrapperTableRow">
<td colspan="2" class="twikinetWrapperTableMain">
<table cellspacing="0" id="table7" cellpadding="0" class="twikiTable" rules="cols" border="1">
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> Purpose </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> Needs Editing? </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> Location </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> Probe Configuration </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> Yes </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> /etc/gratia/gridftp-transfer/ProbeConfig </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> Probe Executables </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> No </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> /usr/share/gratia/gridftp-transfer </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> Log files </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> No </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> /var/log/gratia </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> Temporary files </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> No </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> /var/lib/gratia/tmp </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol twikiLast"> Gums configuration </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1 twikiLast"> Yes </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol twikiLast"> /etc/gums/gums-client.properties </td>
		</tr></table>
</td>
</tr>
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableB twikinetWrapperTableBL"></td>
<td class="twikinetWrapperTableB twikinetWrapperTableBR"></td>
</tr>
</table>
<p />
The RPM installs the Gratia probe into the system crontab, but does not configure it.  The configuration of the probe is controlled by the file
<p />
<pre>
/etc/gratia/gridftp-transfer/ProbeConfig
</pre>
<p />
This is usually one XML node spread over multiple lines.  Note that comments (#) have no effect on this file.  You will need to edit the following:
<p />
<table cellspacing="0" cellpadding="0" border="0" class="twikinetWrapperTable" rules="none">
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableT twikinetWrapperTableTL"></td>
<td class="twikinetWrapperTableT twikinetWrapperTableTR"></td>
</tr>
<tr class="twikinetWrapperTableRow">
<td colspan="2" class="twikinetWrapperTableMain">
<table cellspacing="0" id="table8" cellpadding="0" class="twikiTable" rules="cols" border="1">
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> Attribute </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> Needs Editing </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> Value </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> ProbeName </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> Maybe </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> This should be set to "gridftp-transfer:&lt;hostname&gt;", where &lt;hostname&gt; is the fully-qualified domain name of your gridftp host. </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> CollectorHost </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> Maybe </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> Set to the hostname and port of the central collector.  By default it sends to the OSG collector.  See below. </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> SiteName </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> Yes </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> Set to the resource group name of your site as registered in OIM. </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> GridftpLogDir </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> Yes </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> Set to /var/log, or wherever your current gridftp logs are located </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> Grid </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> Maybe </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> Set to "ITB" if this is a test resource; otherwise, leave as OSG. </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> UserVOMapFile </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> No </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> This should be set to /var/lib/osg/user-vo-map; see below for information about this file. </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> SuppressUnknownVORecords </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> Maybe </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> Set to 1 to suppress any records that can't be matched to a VO; 0 is strongly recommended. </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> SuppressNoDNRecords </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> Maybe </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> Set to 1 to suppress records that can't be matched to a DN; 0 is strongly recommended. </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol twikiLast"> EnableProbe </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1 twikiLast"> Yes </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol twikiLast"> Set to 1 to enable the probe. </td>
		</tr></table>
</td>
</tr>
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableB twikinetWrapperTableBL"></td>
<td class="twikinetWrapperTableB twikinetWrapperTableBR"></td>
</tr>
</table>
<p />
<h3><a name="Selecting_a_collector_host"></a> Selecting a collector host </h3>
<p />
The collector is the central server which logs the GridFTP transfers into a database.  There are usually three options:
<p /> <ol>
<li> <strong>OSG Transfer Collector</strong>: This is the primary collector for transfers in the OSG.  Use CollectorHost="gratia-osg-prod.opensciencegrid.org:80".
</li> <li> <strong>OSG-ITB Transfer Collector</strong>: This is the test collector for transfers in the OSG.  Use CollectorHost=" gratia-osg-itb.opensciencegrid.org:80".
</li> <li> <strong>Site local collector</strong>: If your site has set up its own collector, then your admin will be able to give you an endpoint to use.  Typically, this is along the lines of CollectorHost="collector.example.com:8880".
</li></ol> 
<p />
<strong>Note:</strong> if you are installing on an itb site, use <strong>gratia-osg-itb.opensciencegrid.org</strong> instead of "gratia-osg-transfer.opensciencegrid.org* above.
<p />
<p />
<h3><a name="Using_GUMS_authorization_mode"></a> Using GUMS authorization mode </h3>
<p />
The <code>user-vo-map</code> file is a simple, space-separated format that contains 2 columns; the first is a unix username and the second is the VO which that username correspond to.  In order to create it you need to configure the gums client.
<p />
The primary configuration file for the gums-client utilities is located in <code>/etc/gums/gums-client.properties</code>.  The two properties that you must change are:
<p />
<table cellspacing="0" cellpadding="0" border="0" class="twikinetWrapperTable" rules="none">
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableT twikinetWrapperTableTL"></td>
<td class="twikinetWrapperTableT twikinetWrapperTableTR"></td>
</tr>
<tr class="twikinetWrapperTableRow">
<td colspan="2" class="twikinetWrapperTableMain">
<table cellspacing="0" id="table9" cellpadding="0" class="twikiTable" rules="cols" border="1">
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> Attribute </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> Needs Editing </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> Value </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> gums.location </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> Yes </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> This should be set to the admin URL for your gums server, usually of the form gums.location=https://GUMS_HOSTNAME:8443/gums/services/GUMSAdmin </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol twikiLast"> gums.authz </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1 twikiLast"> Yes </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol twikiLast"> This should be set to the authorization interface URL for your gums server, usually of the form gums.authz=https://GUMS_HOSTNAME:8443/gums/services/GUMSXACMLAuthorizationServicePort </td>
		</tr></table>
</td>
</tr>
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableB twikinetWrapperTableBL"></td>
<td class="twikinetWrapperTableB twikinetWrapperTableBR"></td>
</tr>
</table>
<p />
After the gums client is configured to generate the file run the following once by hand:
<p />
<pre class="rootscreen">
[root@client ~]$ gums-host-cron
</pre>
<p />
<code>user-vo-map</code> should be created in the following location:
<p />
<pre>/var/lib/osg/user-vo-map</pre>
<p />
To have cron regularly update this file start the following service:
<p />
<pre class="rootscreen">
[root@client ~]$ service gums-client-cron start
</pre>
<p />
Make sure the <strong>UserVOMapFile</strong> field is set to this location in
<p />
<pre>/etc/gratia/gridftp-transfer/ProbeConfig</pre>
<p />
Without <code>user-vo-map</code> , all gridftp transfers will show up as belonging to the VO "Unknown".
<p />
<p />
<h3><a name="Using_Gridmap_based_authorizatio"></a> Using Gridmap based authorization mode </h3>
<p />
Note: If you are using this mode for authorization, make sure the files /etc/grid-security/gsi-authz.conf and /etc/grid-security/prima-authz.conf do not exist.
<p />
In order to enable generation of grid-mapfile and  osg-user-vo-map.txt by using the edg-mkgridmap cron process to get information form VOMS servers do the following:
<pre class="rootscreen">
edg-mkgridmap 
</pre>
If you have not installed this package, you will need to run <code>yum install edg-mkgridmap</code> first.
<p />
<p />
<p />
<h3><a name="Validation"></a> Validation </h3>
<p />
<p />
<p />
Run the Gratia probe once by hand to check for functionality:
<p />
<pre class="rootscreen">
[root@client ~]$ /usr/share/gratia/gridftp-transfer/GridftpTransferProbeDriver
</pre>
<p />
Look for any abnormal termination and report it if it is a non-trivial site issue.  Look in the log files in <code>/var/log/gratia/&lt;date&gt;.log</code> and make sure there are no error messages printed.
<p />
<p />
<p />
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="BeStMan_Configuration"></a> BeStMan Configuration </span></h2>
<p />
<p />
<p />
There are two authorization options:
<p /> <ul>
<li> Gridmap file
</li> <li> GUMS authentication server
</li></ul> 
<p />
Please choose one of these and follow the instructions in one of the two following sections.
<p />
<p />
<h3><a name="Configuring_Gridmap_Support"></a> Configuring Gridmap Support </h3>
<p />
By default, GridFTP uses a gridmap file, found in <code>/etc/grid-security/grid-mapfile</code>.
This file is not generated by default.  There are two ways you can generate this file.
You can generate this file manually, by including DN/username combinations.  This is most
useful for debugging.  Otherwise, you can use edg-mkgridmap, which will periodically contact a list of VOMS servers that you specify. It assembles a list of users from those servers and creates a grid-mapfile.  This grid-mapfile serves both as a list of authorized users and provides a mapping from user dns to local user ids.  edg-mkgridmap is already installed with OSG BeStMan SE packages.
<p />
In order to use edg-mkgridmap, review <code>/etc/edg-mkgridmap.conf</code> to make sure that it has all VOs that you are interested in and also to comment out any VOs that you do not wish to support. 
<pre class="rootscreen">
vi /etc/edg-mkgridmap.conf
</pre>
This utility <code>edg-mkgridmap</code> runs as a cronjob <code>/etc/cron.d/edg-mkgridmap-cron</code> (by default every 6 hours). You can also run <code>edg-mkgridmap</code> manually to see that it generates <code>/etc/grid-security/grid-mapfile</code>.  
<pre class="rootscreen">
edg-mkgridmap
</pre>
Then, you can enable/start the service.
<pre class="rootscreen">
/sbin/service edg-mkgridmap start
/sbin/chkconfig edg-mkgridmap on
</pre>
<p />
Next, you will have to modify <code>/etc/bestman2/conf/bestman2.rc</code> and change 
GridMapFileName from <code>/etc/bestman2/conf/grid-mapfile.empty</code> to:
<pre class="file">
GridMapFileName=/etc/grid-security/grid-mapfile
</pre>
<p />
In <code>/etc/sysconfig/bestman2</code>, change 
<pre class="file">
BESTMAN_GUMS_ENABLED=no
</pre>
<p />
<h3><a name="Configuring_GUMS_support"></a> Configuring GUMS support </h3>
<p />
<p />
By default, GridFTP uses a gridmap file, found in <code>/etc/grid-security/gridmap-file</code>.
If you want to use GUMS security (recommended), you will need to enable it using the following steps:
<p />
First, edit <code>/etc/grid-security/gsi-authz.conf</code> and uncomment the globus callout.
<pre class="file">
globus_mapping liblcas_lcmaps_gt4_mapping.so lcmaps_callout
</pre> 
Note that this used to be the full path to the library (<code>/usr/lib64</code> or <code>/usr/lib</code>), but now we 
rely on the linker for proper resolution in this file.
<p />
Next edit <code>/etc/lcmaps.db</code> to edit your gums information:
<pre class="file">

...
gumsclient = "lcmaps_gums_client.mod"
             "-resourcetype ce"
             "-actiontype execute-now"
             "-capath /etc/grid-security/certificates"
             "-cert   /etc/grid-security/hostcert.pem"
             "-key    /etc/grid-security/hostkey.pem"
             "--cert-owner root"
# Change this URL to your GUMS server
             "--endpoint https://<font color="#ff0000">gums.fnal.gov:8443</font>/gums/services/GUMSXACMLAuthorizationServicePort"
</pre> 
<p />
If you would like to run SAZ, you will need to enable the relevant lines in the above file as well (more documentation to be added later).
<p />
<p />
You will need to modify the following settings in <code>/etc/sysconfig/bestman2</code>
<pre class="file">
BESTMAN_GUMSCERTPATH=/etc/grid-security/bestman/bestmancert.pem
BESTMAN_GUMSKEYPATH=/etc/grid-security/bestman/bestmankey.pem
...
</pre>
<p />
You will need to modify the following settings in <code>/etc/bestman2/conf/bestman2.rc</code>
<pre class="file">
GUMSserviceURL=https://GUMS_HOST:8443/gums/services/GUMSXACMLAuthorizationServicePort
</pre>
<p />
<p />
<p />
<p />
<h3><a name="BeStManHadoop_specific_configura"></a> BeStManHadoop-specific configuration </h3>
<p />
BeStMan2 SRM uses the Hadoop FUSE mount to perform namespace operations, such as mkdir, rm, and ls.  As per the Hadoop install instructions, edit <code>/etc/sysconfig/hadoop</code> and run <code>service hadoop-firstboot start</code>.  It is <strong>not</strong> necessary (or even recommended) to start any hadoop services with <code>service hadoop start</code>.
<p />
Make sure that you modify <code>localPathListAllowed</code> to use the Hadoop mount  in <code>/etc/bestman2/conf/bestman2.rc</code>.
<p />
<h3><a name="Modify_etc_sudoers"></a> Modify /etc/sudoers </h3>
<p />
<p />
<p />
BeStman requires the "sudo" command in order to write information as the proper user.
You will need to give the bestman user the proper permissions to run these commands.
<p />
Modify <code>/etc/sudoers</code> and comment the following line.
<pre class="file">
#Defaults    requiretty
</pre>
<p />
Then add the following lines at the end of the <code>/etc/sudoers</code> file.
<pre class="file">
Cmnd_Alias SRM_CMD = /bin/rm, /bin/mkdir, /bin/rmdir, /bin/mv, /bin/cp, /bin/ls
Runas_Alias SRM_USR = ALL, !root
bestman   ALL=(SRM_USR) NOPASSWD: SRM_CMD
</pre>
<p />
<p />
<p />
<h3><a name="Copy_certificates_to_bestman_loc"></a> Copy certificates to bestman location </h3>
<p />
BeStMan2 is preconfigured to look for the <strong>host</strong> certificate and key in <code>/etc/grid-security/bestman/bestman*.pem</code>.
Either, these files <strong>must</strong> exist and be <strong>owned</strong> by the <strong>bestman</strong> user, or you must change the settings in <code>bestman2.rc</code>.
Note that you must use host certificates here or lcg-utils may experience issues.
<p />
<p />
<p />
BeStMan requires a certificate pair to function.  In order to use lcg-utils, this must be a host
certificate (rather than a service certificate).  The following shows how to copy your certificates
<pre class="rootscreen">
cp /etc/grid-security/hostkey.pem /etc/grid-security/bestman/bestmankey.pem
cp /etc/grid-security/hostcert.pem /etc/grid-security/bestman/bestmancert.pem
chown -R bestman:bestman /etc/grid-security/bestman/
</pre> 
Then modify <strong>CertFileName</strong>, <strong>KeyFileName</strong> in <code>/etc/bestman2/conf/bestman2.rc</code>.
<p />
<p />
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Hadoop_Storage_Probe_Configurati"></a> Hadoop Storage Probe Configuration </span></h2>
<p />
<p /> <dl>
<dt> <img src="/twiki/pub/TWiki/TWikiDocGraphics/help.gif" alt="HELP" title="HELP" width="16" height="16" border="0" />     <strong><font color="#ff0000"> NOTE </font></strong> </dt><dd>  This is only needed by the Hadoop Namenode
</dd></dl> 
<p />
Here are the most relevant file and directory locations:
<p />
<table cellspacing="0" cellpadding="0" border="0" class="twikinetWrapperTable" rules="none">
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableT twikinetWrapperTableTL"></td>
<td class="twikinetWrapperTableT twikinetWrapperTableTR"></td>
</tr>
<tr class="twikinetWrapperTableRow">
<td colspan="2" class="twikinetWrapperTableMain">
<table cellspacing="0" id="table10" cellpadding="0" class="twikiTable" rules="cols" border="1">
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> Purpose </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> Needs Editing? </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> Location </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> Probe Configuration </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> Yes </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> /etc/gratia/hadoop-storage/ProbeConfig </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> Probe Executable </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> No </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> /usr/share/gratia/hadoop-storage/hadoop_storage_probe </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> Log files </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> No </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> /var/log/gratia </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol twikiLast"> Temporary files </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1 twikiLast"> No </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol twikiLast"> /var/lib/gratia/tmp </td>
		</tr></table>
</td>
</tr>
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableB twikinetWrapperTableBL"></td>
<td class="twikinetWrapperTableB twikinetWrapperTableBR"></td>
</tr>
</table>
<p />
The RPM installs the Gratia probe into the system crontab, but does not configure it.  The configuration of the probe is controlled by two files
<p />
<pre>
/etc/gratia/hadoop-storage/ProbeConfig
/etc/gratia/hadoop-storage/storage.cfg
</pre>
<p />
<h3><a name="ProbeConfig"></a> ProbeConfig </h3>
This is usually one XML node spread over multiple lines.  Note that comments (#) have no effect on this file.  You will need to edit the following:
<p />
<table cellspacing="0" cellpadding="0" border="0" class="twikinetWrapperTable" rules="none">
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableT twikinetWrapperTableTL"></td>
<td class="twikinetWrapperTableT twikinetWrapperTableTR"></td>
</tr>
<tr class="twikinetWrapperTableRow">
<td colspan="2" class="twikinetWrapperTableMain">
<table cellspacing="0" id="table11" cellpadding="0" class="twikiTable" rules="cols" border="1">
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> Attribute </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> Needs Editing </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> Value </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> CollectorHost </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> Maybe </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> Set to the hostname and port of the central collector.  By default it sends to the OSG collector.  You probably do not want to change it. </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> SiteName </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> Yes </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> Set to the resource group name of your SE as registered in OIM. </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> Grid </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> Maybe </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> Set to "ITB" if this is a test resource; otherwise, leave as OSG. </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol twikiLast"> EnableProbe </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1 twikiLast"> Yes </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol twikiLast"> Set to 1 to enable the probe. </td>
		</tr></table>
</td>
</tr>
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableB twikinetWrapperTableBL"></td>
<td class="twikinetWrapperTableB twikinetWrapperTableBR"></td>
</tr>
</table>
<p />
<h3><a name="storage_cfg"></a> storage.cfg </h3>
This file controls which paths in HDFS should be monitored.  This is in the Windows INI format.
<p />
<strong>Note: for the current version of the storage.cfg, there is an error, and you may need to delete the "probe/" subdirectory for the ProbeConfig location</strong>
<pre class="file">
ProbeConfig = /etc/gratia/<font color="#ff0000">probe/</font>hadoop-storage/ProbeConfig
</pre>
<p />
For each logical "area" (arbitrarily defined by you), specify both a given name and a list of paths that belong to that area.  Unix globs are accepted.
<p />
To configure an area named "CMS /store" that monitors the space usage in the paths /user/cms/store/*, one would add the following to the storage.cfg file.
<p />
<pre class="file">
[Area CMS /store]
Name = CMS /store
Path = /user/cms/store/*
Trim = /user/cms
</pre>
<p />
For each such area, add a section to your configuration file.
<p />
<h4><a name="Example_file"></a> Example file </h4>
Below is a configuration file that includes three distinct areas.  Note that you shouldn't have to touch the [Gratia] section if you edited the ProbeConfig above:
<p />
<pre class="file">
[Gratia]
gratia_location = /opt/vdt/gratia
ProbeConfig = %(gratia_location)s/probe/hadoop-storage/ProbeConfig

[Area /store]
Name = CMS /store
Path = /store/*

[Area /store/user]
Name = CMS /store/user
Path = /store/user/*

[Area /user]
Name = Hadoop /user
Path = /user/*
</pre>
<p />
<strong>*NOTE These lines in the [gratia] section are wrong and need to be changed to the following by hand for now until the rpm is updated:</strong>
<pre class="file">
gratia_location = /etc/gratia
ProbeConfig = %(gratia_location)s/hadoop-storage/ProbeConfig
</pre>
<p />
<p />
<h1><a name="Running_Services"></a> Running Services </h1>
<p />
Namenode:
<pre class="rootscreen">
#Starting namenode
service hadoop-hdfs-namenode start
#Stopping namenode
service hadoop-hdfs-namenode stop
</pre>
<p />
Secondary Namenode:
<pre class="rootscreen">
#Starting secondary namenode
service hadoop-hdfs-secondarynamenode start
#Stopping secondary namenode
service hadoop-hdfs-secondarynamenode stop
</pre>
<p />
<p />
Datanode:
<pre class="rootscreen">
#Starting namenode
service hadoop-hdfs-datanode start
#Stopping namenode
service hadoop-hdfs-datanode stop
</pre>
<p />
GridFTP:
<p />
<p />
Starting GridFTP:
<pre class="rootscreen">
[root@client ~]$ service globus-gridftp-server start
</pre> 
<p />
<p />
SRM (BeStMan):
<p />
<pre class="rootscreen">
[root@client ~]$ service bestman2 start
</pre> 
To start Bestman automatically at boot time
<pre class="rootscreen">
[root@client ~]$ chkconfig bestman2 on
</pre>
<p />
<p />
<p />
<a name="HadoopValidation"></a>
<h1><a name="Validation_AN1"></a> Validation </h1>
<p />
The first thing you may want to do after installing and starting your <strong>Namenode</strong> is to verify that the web interface works.  In your web browser go to:
<p />
<pre class="file">
http://<font color="#ff0000">namenode.hostname</font>:50070/dfshealth.jsp
</pre>
<p />
Get familiar with Hadoop commands.  Run hadoop with no arguments to see the list of commands.
<p />
<pre class="screen">
[user@client ~]$ hadoop
<div class="twistyPlugin twikiMakeVisibleInline">  <span id="twistyIdDocumentation/Release3InstallHadoop200SE1show" class="twistyRememberSetting twistyStartHide twistyTrigger twikiUnvisited twistyInited0"><a href="#"><img src="/twiki/pub/TWiki/TWikiDocGraphics/toggleopen-small.gif" border="0" alt="" /><span class="twikiLinkLabel twikiUnvisited">Show Full Output</span></a> </span> <span id="twistyIdDocumentation/Release3InstallHadoop200SE1hide" class="twistyRememberSetting twistyStartHide twistyTrigger twikiUnvisited twistyHidden twistyInited0"><a href="#"><img src="/twiki/pub/TWiki/TWikiDocGraphics/toggleclose-small.gif" border="0" alt="" /><span class="twikiLinkLabel twikiUnvisited">Hide Full Output</span></a> </span>  </div><!--/twistyPlugin twikiMakeVisibleInline--> <div class="twistyPlugin"><div id="twistyIdDocumentation/Release3InstallHadoop200SE1toggle" class="twistyRememberSetting twistyStartHide twistyContent twikiMakeHidden twistyInited0">
Usage: hadoop [--config confdir] COMMAND
where COMMAND is one of:
  namenode -format     format the DFS filesystem
  secondarynamenode    run the DFS secondary namenode
  namenode             run the DFS namenode
  datanode             run a DFS datanode
  dfsadmin             run a DFS admin client
  mradmin              run a Map-Reduce admin client
  fsck                 run a DFS filesystem checking utility
  fs                   run a generic filesystem user client
  balancer             run a cluster balancing utility
  fetchdt              fetch a delegation token from the NameNode
  jobtracker           run the MapReduce job Tracker node
  pipes                run a Pipes job
  tasktracker          run a MapReduce task Tracker node
  job                  manipulate MapReduce jobs
  queue                get information regarding JobQueues
  version              print the version
  jar <jar>            run a jar file
  distcp <srcurl> <desturl> copy file or directories recursively
  archive -archiveName NAME -p <parent path> <src>* <dest> create a hadoop archive
  oiv                  apply the offline fsimage viewer to an fsimage
  classpath            prints the class path needed to get the
                       Hadoop jar and the required libraries
  daemonlog            get/set the log level for each daemon
 or
  CLASSNAME            run the class named CLASSNAME
Most commands print help when invoked w/o parameters.
</div></div> <!--/twistyPlugin-->
</pre>
<p />
For a list of supported filesystem commands:
<p />
<pre class="screen">
[user@client ~]$ hadoop fs
<div class="twistyPlugin twikiMakeVisibleInline">  <span id="twistyIdDocumentation/Release3InstallHadoop200SE2show" class="twistyRememberSetting twistyStartHide twistyTrigger twikiUnvisited twistyInited0"><a href="#"><img src="/twiki/pub/TWiki/TWikiDocGraphics/toggleopen-small.gif" border="0" alt="" /><span class="twikiLinkLabel twikiUnvisited">Show Full Output</span></a> </span> <span id="twistyIdDocumentation/Release3InstallHadoop200SE2hide" class="twistyRememberSetting twistyStartHide twistyTrigger twikiUnvisited twistyHidden twistyInited0"><a href="#"><img src="/twiki/pub/TWiki/TWikiDocGraphics/toggleclose-small.gif" border="0" alt="" /><span class="twikiLinkLabel twikiUnvisited">Hide Full Output</span></a> </span>  </div><!--/twistyPlugin twikiMakeVisibleInline--> <div class="twistyPlugin"><div id="twistyIdDocumentation/Release3InstallHadoop200SE2toggle" class="twistyRememberSetting twistyStartHide twistyContent twikiMakeHidden twistyInited0">
Usage: java FsShell
           [-ls <path>]
           [-lsr <path>]
           [-df [<path>]]
           [-du <path>]
           [-dus <path>]
           [-count[-q] <path>]
           [-mv <src> <dst>]
           [-cp <src> <dst>]
           [-rm [-skipTrash] <path>]
           [-rmr [-skipTrash] <path>]
           [-expunge]
           [-put <localsrc> ... <dst>]
           [-copyFromLocal <localsrc> ... <dst>]
           [-moveFromLocal <localsrc> ... <dst>]
           [-get [-ignoreCrc] [-crc] <src> <localdst>]
           [-getmerge <src> <localdst> [addnl]]
           [-cat <src>]
           [-text <src>]
           [-copyToLocal [-ignoreCrc] [-crc] <src> <localdst>]
           [-moveToLocal [-crc] <src> <localdst>]
           [-mkdir <path>]
           [-setrep [-R] [-w] <rep> <path/file>]
           [-touchz <path>]
           [-test -[ezd] <path>]
           [-stat [format] <path>]
           [-tail [-f] <file>]
           [-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
           [-chown [-R] [OWNER][:[GROUP]] PATH...]
           [-chgrp [-R] GROUP PATH...]
           [-help [cmd]]

Generic options supported are
-conf <configuration file>     specify an application configuration file
-D <property=value>            use value for given property
-fs <local|namenode:port>      specify a namenode
-jt <local|jobtracker:port>    specify a job tracker
-files <comma separated list of files>    specify comma separated files to be copied to the map reduce cluster
-libjars <comma separated list of jars>    specify comma separated jar files to include in the classpath.
-archives <comma separated list of archives>    specify comma separated archives to be unarchived on the compute machines.

The general command line syntax is
bin/hadoop command [genericOptions] [commandOptions]
</div></div> <!--/twistyPlugin-->
</pre>
<p />
An online guide is also available at <a href="http://hadoop.apache.org/common/docs/current/commands_manual.html" target="_top">Apache Hadoop commands manual</a>.
You can use Hadoop commands to perform filesystem operations with more consistency.
<p />
Example, to look into the internal hadoop namespace:
<p />
<pre class="screen">
[user@client ~]$ hadoop fs -ls /
Found 1 items
drwxrwxr-x   - engage engage          0 2011-07-25 06:32 /engage
</pre>
<p />
Example, to adjust ownership of filesystem areas (there is usually no need to specify the mount itself <code>/mnt/hadoop</code> in Hadoop commands):
<p />
<pre class="rootscreen">
[root@client ~]$ hadoop fs -chown -R engage:engage /engage
</pre>
<p />
Example, compare <code>hadoop fs</code> command vs. using FUSE mount:
<pre class="screen">
[user@client ~]$ hadoop fs -ls /engage
Found 3 items
-rw-rw-r--   2 engage engage  733669376 2011-06-15 16:55 /engage/CentOS-5.6-x86_64-LiveCD.iso
-rw-rw-r--   2 engage engage  215387183 2011-06-15 16:28 /engage/condor-7.6.1-x86_rhap_5-stripped.tar.gz
-rw-rw-r--   2 engage engage    9259360 2011-06-15 16:32 /engage/glideinWMS_v2_5_1.tgz

[user@client ~]$ ls -l /mnt/hadoop/engage
total 935855
-rw-rw-r-- 1 engage engage 733669376 Jun 15 16:55 CentOS-5.6-x86_64-LiveCD.iso
-rw-rw-r-- 1 engage engage 215387183 Jun 15 16:28 condor-7.6.1-x86_rhap_5-stripped.tar.gz
-rw-rw-r-- 1 engage engage   9259360 Jun 15 16:32 glideinWMS_v2_5_1.tgz
</pre>
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="GridFTP_Validation"></a> GridFTP Validation </span></h2>
<p />
<p /> <dl>
<dt> <img src="/twiki/pub/TWiki/TWikiDocGraphics/help.gif" alt="HELP" title="HELP" width="16" height="16" border="0" />     <strong><font color="#ff0000"> NOTE </font></strong> </dt><dd>  The commands used to verify GridFTP below assume you have access to a node where you can first generate a valid proxy using <code>voms-proxy-init</code> or <code>grid-proxy-init</code>.  Obtaining grid credentials is beyond the scope of this document.
</dd></dl> 
<p />
<pre class="screen">
[user@client ~]$ globus-url-copy file:///home/users/jdost/test.txt gsiftp://devg-7.t2.ucsd.edu:2811/mnt/hadoop/engage/test.txt
</pre>
<p />
If you are having troubles running GridFTP refer to <a href="/bin/view/Documentation/Release3/InstallHadoop200SE#GridFTPStand" class="twikiCurrentTopicLink twikiAnchorLink">Starting GridFTP in Standalone Mode</a> in the Troubleshooting section.
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="BeStMan_Validation"></a> BeStMan Validation </span></h2>
<p />
There are three ways of validating BeStMan:
  * <a href="/bin/view/Documentation/Release3/SrmTester" class="twikiLink">SrmTester</a>: BeStMan testing application
  * <a href="/bin/view/Documentation/Release3/InstallRSV" class="twikiLink">InstallRSV</a>: RSV monitoring tools
  * BestMan client tools
<p />
See the relevant pages for the first two options.  This section will detail some basic client commands to validate.  You will need grid credentials in order to test using client tools.  
<p />
<pre class="screen">
srm-ping srm://BeStMan_host:secured_http_port/srm/v2/server
srm-copy file:////tmp/test1  srm://BeStMan_host:secured_http_port/srm/v2/server\?SFN=/mnt/hadoop/VONAME/test_1
</pre>
<p />
The <code>srm-ping</code> tool should return a valid mapping <code>gumsIDMapped</code> that is not null
<p />
<p />
<p />
<p />
<p />
<h1><a name="Installing_Hadoop_Storage_Report"></a> Installing Hadoop Storage Reports (Optional) </h1>
<p />
<strong>*NOTE the GratiaReporting rpm has not yet been migrated to the new osg repos and this section is subject to change.  Please skip this section until this warning goes away or request Nebraska to host your reports</strong>
<p />
<p /> <dl>
<dt> <img src="/twiki/pub/TWiki/TWikiDocGraphics/help.gif" alt="HELP" title="HELP" width="16" height="16" border="0" />     <strong><font color="#ff0000"> NOTE </font></strong> </dt><dd>  The Hadoop Storage Reports may be installed on any node that has access to a local Gratia Collector 
</dd></dl> 
<p />
The Hadoop storage reports provides a daily report on the status and usage of your SE.  This serves as a handy tool for both site administrators and site executives.  An example report is copied at the end of this guide.
<p />
<div class="twistyPlugin twikiMakeVisibleInline">  <span id="twistyIdDocumentation/Release3InstallHadoop200SE3show" class="twistyTrigger twikiUnvisited twistyHidden twistyInited"><a href="#"><img src="/twiki/pub/TWiki/TWikiDocGraphics/toggleopen-small.gif" border="0" alt="" /><span class="twikiLinkLabel twikiUnvisited">Click here for Hadoop Storage Reports information</span></a> </span> <span id="twistyIdDocumentation/Release3InstallHadoop200SE3hide" class="twistyTrigger twikiUnvisited twistyHidden twistyInited"><a href="#"><img src="/twiki/pub/TWiki/TWikiDocGraphics/toggleclose-small.gif" border="0" alt="" /><span class="twikiLinkLabel twikiUnvisited">Hide the example</span></a> </span>  </div><!--/twistyPlugin twikiMakeVisibleInline--> <div class="twistyPlugin"><div id="twistyIdDocumentation/Release3InstallHadoop200SE3toggle" class="twistyContent twikiMakeHidden twistyInited">
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Prerequisites"></a> Prerequisites </span></h2>
<p /> <ol>
<li> A working HDFS installation
</li> <li> A local <a href="/bin/view/Trash/ReleaseDocumentationGratiaSiteCollector" class="twikiLink">Gratia Collector</a> installed
</li> <li> A Hadoop Storage Probe installed and configured to point to the local Gratia Collector
</li></ol> 
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Installation_AN1"></a> Installation </span></h2>
<p />
<pre class="rootscreen">
&#91;root&#64;client ~]$ yum install GratiaReporting
</pre>
<p />
Updates can be installed with:
<p />
<pre class="rootscreen">
&#91;root&#64;client ~]$ yum upgrade GratiaReporting
</pre>
<p />
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Configuration_AN1"></a> Configuration </span></h2>
<p />
This RPM uses Linux-standard file locations.  Here are the most relevant file and directory locations:
<p />
<table cellspacing="0" cellpadding="0" border="0" class="twikinetWrapperTable" rules="none">
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableT twikinetWrapperTableTL"></td>
<td class="twikinetWrapperTableT twikinetWrapperTableTR"></td>
</tr>
<tr class="twikinetWrapperTableRow">
<td colspan="2" class="twikinetWrapperTableMain">
<table cellspacing="0" id="table12" cellpadding="0" class="twikiTable" rules="cols" border="1">
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> Purpose </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> Needs Editing? </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> Location </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> Report Configuration </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> Yes </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> /etc/gratia_reporting </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> Cron template </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> Yes </td>
			<td bgcolor="#ffffff" align="right" valign="top" class="twikiTableCol2 twikiLastCol"> /etc/gratia_reporting/gratia_reporting/gratia_reporting.cron (move to /etc/cron.d) </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> Logging Configuration </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> No </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> /etc/gratia_reporting/logging.cfg </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol twikiLast"> Log files </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1 twikiLast"> No </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol twikiLast"> /var/log/gratia_reporting.log </td>
		</tr></table>
</td>
</tr>
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableB twikinetWrapperTableBL"></td>
<td class="twikinetWrapperTableB twikinetWrapperTableBR"></td>
</tr>
</table>
<p />
<h3><a name="Configuration_file"></a> Configuration file </h3>
Copy the file <code>/etc/gratia_reporting/reporting.cfg</code> to a new filename in <code>/etc/gratia_reporting</code> (for example, <code>/etc/gratia_reporting/reporting_cms.cfg</code>).  You will do this once for every report you want to send out.
<p />
<table cellspacing="0" cellpadding="0" border="0" class="twikinetWrapperTable" rules="none">
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableT twikinetWrapperTableTL"></td>
<td class="twikinetWrapperTableT twikinetWrapperTableTR"></td>
</tr>
<tr class="twikinetWrapperTableRow">
<td colspan="2" class="twikinetWrapperTableMain">
<table cellspacing="0" id="table13" cellpadding="0" class="twikiTable" rules="cols" border="1">
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> Attribute </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> Needs Editing </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> Value </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> SiteName </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> Yes </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> Set to the resource group name of your SE as registered in OIM. </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> database </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> Maybe </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> Set to the database section containing the login details for your Gratia Collector (a few, non-functioning examples sections are included). Installing a Gratia Collector is <a href="/bin/view/Trash/ReleaseDocumentationGratiaSiteCollector" class="twikiLink">covered here</a>, but ask around on osg-hadoop: Nebraska will usually run these reports for you if requested. </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> toNames </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> Yes </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> Python list for the "to names" for the report email. </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> toEmails </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> Yes </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> Python list for the "to emails" for the report email. </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> smtphost </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> Maybe </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> Hostname of a SMTP server that accepts email from this host. </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> fromName </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> Maybe </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> Set to the "from name" for the report email. </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol twikiLast"> fromEmail </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1 twikiLast"> Maybe </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol twikiLast"> Set to the "from email" for the report email. </td>
		</tr></table>
</td>
</tr>
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableB twikinetWrapperTableBL"></td>
<td class="twikinetWrapperTableB twikinetWrapperTableBR"></td>
</tr>
</table>
<p />
<h3><a name="Cron"></a> Cron </h3>
Copy the file <code>/etc/gratia_reporting/gratia_reporting.cron</code> to <code>/etc/cron.d</code>.  There is one line per report; comment out all except the hadoop report.  It is the line containing <code>-n hadoop</code>.  Update the line to point at your new configuration file.
<p />
</div></div> <!--/twistyPlugin-->
<p />
<div class="twistyPlugin twikiMakeVisibleInline">  <span id="twistyIdDocumentation/Release3InstallHadoop200SE4show" class="twistyRememberSetting twistyStartHide twistyTrigger twikiUnvisited twistyInited0"><a href="#"><img src="/twiki/pub/TWiki/TWikiDocGraphics/toggleopen-small.gif" border="0" alt="" /><span class="twikiLinkLabel twikiUnvisited">Show Full Output</span></a> </span> <span id="twistyIdDocumentation/Release3InstallHadoop200SE4hide" class="twistyRememberSetting twistyStartHide twistyTrigger twikiUnvisited twistyHidden twistyInited0"><a href="#"><img src="/twiki/pub/TWiki/TWikiDocGraphics/toggleclose-small.gif" border="0" alt="" /><span class="twikiLinkLabel twikiUnvisited">Hide Full Output</span></a> </span>  </div><!--/twistyPlugin twikiMakeVisibleInline--> <div class="twistyPlugin"><div id="twistyIdDocumentation/Release3InstallHadoop200SE4toggle" class="twistyRememberSetting twistyStartHide twistyContent twikiMakeHidden twistyInited0">
This is a sample report from the Nebraska HDFS instance.
<pre class="file">
============================================================
  The Hadoop Chronicle | 85 % | 2009-09-25
============================================================

--------------------
| Global Storage   |
-----------------------------------------------------
|                  |  Today  | Yesterday | One Week |
-----------------------------------------------------
| Total Space (GB) | 311,470 |   357,818 |  368,711 |
| Free Space (GB)  |  47,304 |    93,719 |  128,391 |
| Used Space (GB)  | 264,166 |   264,100 |  240,320 |
| Used Percentage  |     85% |       74% |      65% |
-----------------------------------------------------
--------------
| CMS /store |
-------------------------------------------------------------------------------------------------------------------------------------
|           Path           | Size(GB) | 1 Day Change | 7 Day Change | Remaining | # Files | 1 Day Change | 7 Day Change | Remaining |
-------------------------------------------------------------------------------------------------------------------------------------
| /store/user              |      771 |            0 | UNKNOWN      | NO QUOTA  |   4,859 |            0 | UNKNOWN      | NO QUOTA  |
| /store/mc                |   95,865 |         -353 | UNKNOWN      | NO QUOTA  |  86,830 |         -171 | UNKNOWN      | NO QUOTA  |
| /store/test              |        0 |            0 | UNKNOWN      | NO QUOTA  |     569 |           25 | UNKNOWN      | NO QUOTA  |
| /store/results           |      237 |            0 | UNKNOWN      | NO QUOTA  |     198 |            0 | UNKNOWN      | NO QUOTA  |
| /store/phedex_monarctest |      729 |            0 | UNKNOWN      | NO QUOTA  |     257 |            0 | UNKNOWN      | NO QUOTA  |
| /store/unmerged          |    3,681 |            3 | UNKNOWN      | NO QUOTA  |  35,687 |           23 | UNKNOWN      | NO QUOTA  |
| /store/CSA07             |        0 |            0 | UNKNOWN      | NO QUOTA  |       0 |            0 | UNKNOWN      | NO QUOTA  |
| /store/data              |        0 |            0 | UNKNOWN      | NO QUOTA  |       0 |            0 | UNKNOWN      | NO QUOTA  |
| /store/PhEDEx_LoadTest07 |        0 |          -21 | UNKNOWN      | NO QUOTA  |       1 |          -22 | UNKNOWN      | NO QUOTA  |
-------------------------------------------------------------------------------------------------------------------------------------

-------------------
| CMS /store/user |
----------------------------------------------------------------------------------------------------------------------------------
|          Path         | Size(GB) | 1 Day Change | 7 Day Change | Remaining | # Files | 1 Day Change | 7 Day Change | Remaining |
----------------------------------------------------------------------------------------------------------------------------------
| /store/user/hpi       |        0 |            0 | UNKNOWN      |     1,099 |      15 |            0 | UNKNOWN      |     9,985 |
| /store/user/gattebury |        0 |            0 | UNKNOWN      |     1,100 |       1 |            0 | UNKNOWN      |     9,999 |
| /store/user/mkirn     |        0 |            0 | UNKNOWN      |     1,100 |       3 |            0 | UNKNOWN      |     9,997 |
| /store/user/spadhi    |       12 |            0 | UNKNOWN      |     1,062 |   1,114 |            0 | UNKNOWN      |     8,886 |
| /store/user/creed     |        0 |            0 | UNKNOWN      |     1,100 |       0 |            0 | UNKNOWN      |    10,000 |
| /store/user/rossman   |        0 |            0 | UNKNOWN      |     1,099 |       5 |            0 | UNKNOWN      |     9,995 |
| /store/user/eluiggi   |        0 |            0 | UNKNOWN      |     1,099 |       6 |            0 | UNKNOWN      |     9,994 |
| /store/user/ewv       |        7 |            0 | UNKNOWN      |     1,081 |     284 |            0 | UNKNOWN      |     9,716 |
| /store/user/test      |        0 |            0 | UNKNOWN      | NO QUOTA  |     167 |            0 | UNKNOWN      |     9,833 |
| /store/user/schiefer  |      751 |            0 | UNKNOWN      |     1,044 |   3,264 |            0 | UNKNOWN      |     6,736 |
----------------------------------------------------------------------------------------------------------------------------------

----------------
| Hadoop /user |
----------------------------------------------------------------------------------------------------------------------------------
|       Path      | Size(GB) | 1 Day Change | 7 Day Change | Remaining | # Files | 1 Day Change | 7 Day Change |    Remaining    |
----------------------------------------------------------------------------------------------------------------------------------
| /user/djbender  |        0 |            0 | UNKNOWN      | NO QUOTA  |       1 |            0 | UNKNOWN      | NO QUOTA        |
| /user/lhcb      |        0 |            0 | UNKNOWN      |        54 |       0 |            0 | UNKNOWN      | NO QUOTA        |
| /user/dzero     |      897 |            0 | UNKNOWN      |       347 |  89,376 |            0 | UNKNOWN      |         410,624 |
| /user/bloom     |      454 |            0 | UNKNOWN      | NO QUOTA  |   1,410 |            0 | UNKNOWN      | NO QUOTA        |
| /user/uscms01   |  101,384 |         -362 | UNKNOWN      | NO QUOTA  | 129,739 |         -141 | UNKNOWN      | NO QUOTA        |
| /user/cdf       |        0 |            0 | UNKNOWN      | NO QUOTA  |       6 |            0 | UNKNOWN      | 536,870,911,994 |
| /user/osg       |        1 |            0 | UNKNOWN      | NO QUOTA  |       3 |            0 | UNKNOWN      |   5,368,709,117 |
| /user/dweitzel  |       20 |            0 | UNKNOWN      | NO QUOTA  |   2,282 |            0 | UNKNOWN      | NO QUOTA        |
| /user/gattebury |        5 |            0 | UNKNOWN      | NO QUOTA  |  10,002 |            0 | UNKNOWN      | NO QUOTA        |
| /user/brian     |       72 |            0 | UNKNOWN      | NO QUOTA  |   2,697 |            0 | UNKNOWN      | NO QUOTA        |
| /user/usatlas   |        0 |            0 | UNKNOWN      | NO QUOTA  |       0 |            0 | UNKNOWN      | NO QUOTA        |
| /user/powers    |        1 |            1 | UNKNOWN      | NO QUOTA  |     211 |          211 | UNKNOWN      | NO QUOTA        |
| /user/ifisk     |        0 |            0 | UNKNOWN      | NO QUOTA  |       1 |            0 | UNKNOWN      | NO QUOTA        |
| /user/gpn       |      261 |           -5 | UNKNOWN      |     1,360 |   3,805 |            1 | UNKNOWN      |         996,195 |
| /user/engage    |      461 |          367 | UNKNOWN      | NO QUOTA  |      16 |           13 | UNKNOWN      |         999,984 |
| /user/clundst   |        0 |            0 | UNKNOWN      | NO QUOTA  |       6 |            0 | UNKNOWN      | NO QUOTA        |
| /user/che       |        0 |            0 | UNKNOWN      | NO QUOTA  |      13 |            0 | UNKNOWN      | NO QUOTA        |
| /user/store     |        0 |            0 | UNKNOWN      | NO QUOTA  |       0 |            0 | UNKNOWN      | NO QUOTA        |
| /user/dteam     |        0 |            0 | UNKNOWN      |        53 |      18 |            0 | UNKNOWN      | NO QUOTA        |
| /user/root      |        0 |            0 | UNKNOWN      | NO QUOTA  |       1 |            0 | UNKNOWN      | NO QUOTA        |
----------------------------------------------------------------------------------------------------------------------------------

-------------
| FSCK Data |
-------------
 Total size:	114592906796932 B (Total open files size: 38923141120 B)
 Total dirs:	41293
 Total files:	295431 (Files currently being written: 38)
 Total blocks (validated):	1356788 (avg. block size 84458962 B) (Total open file blocks (not validated): 297)
 Minimally replicated blocks:	1356788 (100.0 %)
 Over-replicated blocks:	1 (7.370348E-5 %)
 Under-replicated blocks:	0 (0.0 %)
 Mis-replicated blocks:		0 (0.0 %)
 Default replication factor:	3
 Average block replication:	2.2943976
 Corrupt blocks:		0
 Missing replicas:		0 (0.0 %)
 Number of data-nodes:		101
 Number of racks:		1
The filesystem under path '/' is HEALTHY
</pre>
<p />
</div></div> <!--/twistyPlugin-->
<p />
<h1><a name="Troubleshooting"></a> Troubleshooting </h1>
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="Hadoop"></a> Hadoop </span></h2>
<p />
To view all of the currently configured settings of Hadoop from the web interface, enter the following url in your browser:
<p />
<pre class="file">
http://<font color="#ff0000">namenode.hostname</font>:50070/conf
</pre>
<p />
You will see the entire configuration in XML format, for example:
<p />
<div class="twistyPlugin twikiMakeVisibleInline">  <span id="twistyIdDocumentation/Release3InstallHadoop200SE5show" class="twistyRememberSetting twistyStartHide twistyTrigger twikiUnvisited twistyInited0"><a href="#"><img src="/twiki/pub/TWiki/TWikiDocGraphics/toggleopen-small.gif" border="0" alt="" /><span class="twikiLinkLabel twikiUnvisited">Show Full Output</span></a> </span> <span id="twistyIdDocumentation/Release3InstallHadoop200SE5hide" class="twistyRememberSetting twistyStartHide twistyTrigger twikiUnvisited twistyHidden twistyInited0"><a href="#"><img src="/twiki/pub/TWiki/TWikiDocGraphics/toggleclose-small.gif" border="0" alt="" /><span class="twikiLinkLabel twikiUnvisited">Hide Full Output</span></a> </span>  </div><!--/twistyPlugin twikiMakeVisibleInline--> <div class="twistyPlugin"><div id="twistyIdDocumentation/Release3InstallHadoop200SE5toggle" class="twistyRememberSetting twistyStartHide twistyContent twikiMakeHidden twistyInited0">
<pre class="file">
&#60;?xml version&#61;&#34;1.0&#34; encoding&#61;&#34;UTF-8&#34; standalone&#61;&#34;no&#34;?&#62;&#60;configuration&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;fs.s3n.impl&#60;/name&#62;&#60;value&#62;org.apache.hadoop.fs.s3native.NativeS3FileSystem&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.task.cache.levels&#60;/name&#62;&#60;value&#62;2&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;map.sort.class&#60;/name&#62;&#60;value&#62;org.apache.hadoop.util.QuickSort&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-site.xml--&#62;&#60;name&#62;hadoop.tmp.dir&#60;/name&#62;&#60;value&#62;/data1/hadoop//scratch&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;hadoop.native.lib&#60;/name&#62;&#60;value&#62;true&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.namenode.decommission.nodes.per.interval&#60;/name&#62;&#60;value&#62;5&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.https.need.client.auth&#60;/name&#62;&#60;value&#62;false&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;ipc.client.idlethreshold&#60;/name&#62;&#60;value&#62;4000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.system.dir&#60;/name&#62;&#60;value&#62;${hadoop.tmp.dir}/mapred/system&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.datanode.data.dir.perm&#60;/name&#62;&#60;value&#62;755&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.job.tracker.persist.jobstatus.hours&#60;/name&#62;&#60;value&#62;0&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-site.xml--&#62;&#60;name&#62;dfs.namenode.logging.level&#60;/name&#62;&#60;value&#62;all&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.datanode.address&#60;/name&#62;&#60;value&#62;0.0.0.0:50010&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;io.skip.checksum.errors&#60;/name&#62;&#60;value&#62;false&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.block.access.token.enable&#60;/name&#62;&#60;value&#62;false&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from Unknown--&#62;&#60;name&#62;fs.default.name&#60;/name&#62;&#60;value&#62;hdfs://nagios.t2.ucsd.edu:9000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.child.tmp&#60;/name&#62;&#60;value&#62;./tmp&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;fs.har.impl.disable.cache&#60;/name&#62;&#60;value&#62;true&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.skip.reduce.max.skip.groups&#60;/name&#62;&#60;value&#62;0&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.safemode.threshold.pct&#60;/name&#62;&#60;value&#62;0.999f&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.heartbeats.in.second&#60;/name&#62;&#60;value&#62;100&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-site.xml--&#62;&#60;name&#62;dfs.namenode.handler.count&#60;/name&#62;&#60;value&#62;40&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.blockreport.initialDelay&#60;/name&#62;&#60;value&#62;0&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.jobtracker.instrumentation&#60;/name&#62;&#60;value&#62;org.apache.hadoop.mapred.JobTrackerMetricsInst&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.tasktracker.dns.nameserver&#60;/name&#62;&#60;value&#62;default&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;io.sort.factor&#60;/name&#62;&#60;value&#62;10&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.task.timeout&#60;/name&#62;&#60;value&#62;600000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.max.tracker.failures&#60;/name&#62;&#60;value&#62;4&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;hadoop.rpc.socket.factory.class.default&#60;/name&#62;&#60;value&#62;org.apache.hadoop.net.StandardSocketFactory&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.job.tracker.jobhistory.lru.cache.size&#60;/name&#62;&#60;value&#62;5&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;fs.hdfs.impl&#60;/name&#62;&#60;value&#62;org.apache.hadoop.hdfs.DistributedFileSystem&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.skip.map.auto.incr.proc.count&#60;/name&#62;&#60;value&#62;true&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.block.access.key.update.interval&#60;/name&#62;&#60;value&#62;600&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapreduce.job.complete.cancel.delegation.tokens&#60;/name&#62;&#60;value&#62;true&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;io.mapfile.bloom.size&#60;/name&#62;&#60;value&#62;1048576&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapreduce.reduce.shuffle.connect.timeout&#60;/name&#62;&#60;value&#62;180000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.safemode.extension&#60;/name&#62;&#60;value&#62;30000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-site.xml--&#62;&#60;name&#62;tasktracker.http.threads&#60;/name&#62;&#60;value&#62;50&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.job.shuffle.merge.percent&#60;/name&#62;&#60;value&#62;0.66&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;fs.ftp.impl&#60;/name&#62;&#60;value&#62;org.apache.hadoop.fs.ftp.FTPFileSystem&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.output.compress&#60;/name&#62;&#60;value&#62;false&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-site.xml--&#62;&#60;name&#62;io.bytes.per.checksum&#60;/name&#62;&#60;value&#62;4096&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.healthChecker.script.timeout&#60;/name&#62;&#60;value&#62;600000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;topology.node.switch.mapping.impl&#60;/name&#62;&#60;value&#62;org.apache.hadoop.net.ScriptBasedMapping&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.https.server.keystore.resource&#60;/name&#62;&#60;value&#62;ssl-server.xml&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.reduce.slowstart.completed.maps&#60;/name&#62;&#60;value&#62;0.05&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.reduce.max.attempts&#60;/name&#62;&#60;value&#62;4&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;fs.ramfs.impl&#60;/name&#62;&#60;value&#62;org.apache.hadoop.fs.InMemoryFileSystem&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.block.access.token.lifetime&#60;/name&#62;&#60;value&#62;600&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.skip.map.max.skip.records&#60;/name&#62;&#60;value&#62;0&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.name.edits.dir&#60;/name&#62;&#60;value&#62;${dfs.name.dir}&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;hadoop.security.group.mapping&#60;/name&#62;&#60;value&#62;org.apache.hadoop.security.ShellBasedUnixGroupsMapping&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.job.tracker.persist.jobstatus.dir&#60;/name&#62;&#60;value&#62;/jobtracker/jobsInfo&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-site.xml--&#62;&#60;name&#62;hadoop.log.dir&#60;/name&#62;&#60;value&#62;/var/log/hadoop&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;fs.s3.buffer.dir&#60;/name&#62;&#60;value&#62;${hadoop.tmp.dir}/s3&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-site.xml--&#62;&#60;name&#62;dfs.block.size&#60;/name&#62;&#60;value&#62;134217728&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;job.end.retry.attempts&#60;/name&#62;&#60;value&#62;0&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;fs.file.impl&#60;/name&#62;&#60;value&#62;org.apache.hadoop.fs.LocalFileSystem&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.output.compression.type&#60;/name&#62;&#60;value&#62;RECORD&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.local.dir.minspacestart&#60;/name&#62;&#60;value&#62;0&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.datanode.ipc.address&#60;/name&#62;&#60;value&#62;0.0.0.0:50020&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.permissions&#60;/name&#62;&#60;value&#62;true&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;topology.script.number.args&#60;/name&#62;&#60;value&#62;100&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;io.mapfile.bloom.error.rate&#60;/name&#62;&#60;value&#62;0.005&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.max.tracker.blacklists&#60;/name&#62;&#60;value&#62;4&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.task.profile.maps&#60;/name&#62;&#60;value&#62;0-2&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.datanode.https.address&#60;/name&#62;&#60;value&#62;0.0.0.0:50475&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-site.xml--&#62;&#60;name&#62;dfs.umaskmode&#60;/name&#62;&#60;value&#62;002&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.userlog.retain.hours&#60;/name&#62;&#60;value&#62;24&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-site.xml--&#62;&#60;name&#62;dfs.secondary.http.address&#60;/name&#62;&#60;value&#62;gratia-1:50090&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-site.xml--&#62;&#60;name&#62;dfs.replication.max&#60;/name&#62;&#60;value&#62;32&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.job.tracker.persist.jobstatus.active&#60;/name&#62;&#60;value&#62;false&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;hadoop.security.authorization&#60;/name&#62;&#60;value&#62;false&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;local.cache.size&#60;/name&#62;&#60;value&#62;10737418240&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.min.split.size&#60;/name&#62;&#60;value&#62;0&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.namenode.delegation.token.renew-interval&#60;/name&#62;&#60;value&#62;86400000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-site.xml--&#62;&#60;name&#62;mapred.map.tasks&#60;/name&#62;&#60;value&#62;7919&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.child.java.opts&#60;/name&#62;&#60;value&#62;-Xmx200m&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.https.client.keystore.resource&#60;/name&#62;&#60;value&#62;ssl-client.xml&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from Unknown--&#62;&#60;name&#62;dfs.namenode.startup&#60;/name&#62;&#60;value&#62;REGULAR&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.job.queue.name&#60;/name&#62;&#60;value&#62;default&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.job.tracker.retiredjobs.cache.size&#60;/name&#62;&#60;value&#62;1000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.https.address&#60;/name&#62;&#60;value&#62;0.0.0.0:50470&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-site.xml--&#62;&#60;name&#62;dfs.balance.bandwidthPerSec&#60;/name&#62;&#60;value&#62;2000000000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;ipc.server.listen.queue.size&#60;/name&#62;&#60;value&#62;128&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;job.end.retry.interval&#60;/name&#62;&#60;value&#62;30000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.inmem.merge.threshold&#60;/name&#62;&#60;value&#62;1000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.skip.attempts.to.start.skipping&#60;/name&#62;&#60;value&#62;2&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-site.xml--&#62;&#60;name&#62;fs.checkpoint.dir&#60;/name&#62;&#60;value&#62;/var/hadoop/checkpoint-a&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-site.xml--&#62;&#60;name&#62;mapred.reduce.tasks&#60;/name&#62;&#60;value&#62;1543&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.merge.recordsBeforeProgress&#60;/name&#62;&#60;value&#62;10000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.userlog.limit.kb&#60;/name&#62;&#60;value&#62;0&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;webinterface.private.actions&#60;/name&#62;&#60;value&#62;false&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.max.objects&#60;/name&#62;&#60;value&#62;0&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.job.shuffle.input.buffer.percent&#60;/name&#62;&#60;value&#62;0.70&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;io.sort.spill.percent&#60;/name&#62;&#60;value&#62;0.80&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.map.tasks.speculative.execution&#60;/name&#62;&#60;value&#62;true&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;hadoop.util.hash.type&#60;/name&#62;&#60;value&#62;murmur&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.datanode.dns.nameserver&#60;/name&#62;&#60;value&#62;default&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.blockreport.intervalMsec&#60;/name&#62;&#60;value&#62;3600000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.map.max.attempts&#60;/name&#62;&#60;value&#62;4&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapreduce.job.acl-view-job&#60;/name&#62;&#60;value&#62; &#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.job.tracker.handler.count&#60;/name&#62;&#60;value&#62;10&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.client.block.write.retries&#60;/name&#62;&#60;value&#62;3&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.max.reduces.per.node&#60;/name&#62;&#60;value&#62;-1&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapreduce.reduce.shuffle.read.timeout&#60;/name&#62;&#60;value&#62;180000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.tasktracker.expiry.interval&#60;/name&#62;&#60;value&#62;600000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.https.enable&#60;/name&#62;&#60;value&#62;false&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.jobtracker.maxtasks.per.job&#60;/name&#62;&#60;value&#62;-1&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.jobtracker.job.history.block.size&#60;/name&#62;&#60;value&#62;3145728&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;keep.failed.task.files&#60;/name&#62;&#60;value&#62;false&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.datanode.failed.volumes.tolerated&#60;/name&#62;&#60;value&#62;0&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.task.profile.reduces&#60;/name&#62;&#60;value&#62;0-2&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;ipc.client.tcpnodelay&#60;/name&#62;&#60;value&#62;false&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.output.compression.codec&#60;/name&#62;&#60;value&#62;org.apache.hadoop.io.compress.DefaultCodec&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;io.map.index.skip&#60;/name&#62;&#60;value&#62;0&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;ipc.server.tcpnodelay&#60;/name&#62;&#60;value&#62;false&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.namenode.delegation.key.update-interval&#60;/name&#62;&#60;value&#62;86400000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.running.map.limit&#60;/name&#62;&#60;value&#62;-1&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;jobclient.progress.monitor.poll.interval&#60;/name&#62;&#60;value&#62;1000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.default.chunk.view.size&#60;/name&#62;&#60;value&#62;32768&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;hadoop.logfile.size&#60;/name&#62;&#60;value&#62;10000000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.reduce.tasks.speculative.execution&#60;/name&#62;&#60;value&#62;true&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapreduce.tasktracker.outofband.heartbeat&#60;/name&#62;&#60;value&#62;false&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;fs.s3n.block.size&#60;/name&#62;&#60;value&#62;67108864&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-site.xml--&#62;&#60;name&#62;dfs.datanode.du.reserved&#60;/name&#62;&#60;value&#62;10000000000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;hadoop.security.authentication&#60;/name&#62;&#60;value&#62;simple&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-site.xml--&#62;&#60;name&#62;fs.checkpoint.period&#60;/name&#62;&#60;value&#62;3600&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.running.reduce.limit&#60;/name&#62;&#60;value&#62;-1&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.job.reuse.jvm.num.tasks&#60;/name&#62;&#60;value&#62;1&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.web.ugi&#60;/name&#62;&#60;value&#62;webuser,webgroup&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.jobtracker.completeuserjobs.maximum&#60;/name&#62;&#60;value&#62;100&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.df.interval&#60;/name&#62;&#60;value&#62;60000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.task.tracker.task-controller&#60;/name&#62;&#60;value&#62;org.apache.hadoop.mapred.DefaultTaskController&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-site.xml--&#62;&#60;name&#62;dfs.data.dir&#60;/name&#62;&#60;value&#62;/data1/hadoop//data&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;fs.s3.maxRetries&#60;/name&#62;&#60;value&#62;4&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.datanode.dns.interface&#60;/name&#62;&#60;value&#62;default&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.support.append&#60;/name&#62;&#60;value&#62;true&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapreduce.job.acl-modify-job&#60;/name&#62;&#60;value&#62; &#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.local.dir&#60;/name&#62;&#60;value&#62;${hadoop.tmp.dir}/mapred/local&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;fs.hftp.impl&#60;/name&#62;&#60;value&#62;org.apache.hadoop.hdfs.HftpFileSystem&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-site.xml--&#62;&#60;name&#62;dfs.permissions.supergroup&#60;/name&#62;&#60;value&#62;root&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;fs.trash.interval&#60;/name&#62;&#60;value&#62;0&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;fs.s3.sleepTimeSeconds&#60;/name&#62;&#60;value&#62;10&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.submit.replication&#60;/name&#62;&#60;value&#62;10&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-site.xml--&#62;&#60;name&#62;dfs.replication.min&#60;/name&#62;&#60;value&#62;1&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;fs.har.impl&#60;/name&#62;&#60;value&#62;org.apache.hadoop.fs.HarFileSystem&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.map.output.compression.codec&#60;/name&#62;&#60;value&#62;org.apache.hadoop.io.compress.DefaultCodec&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.tasktracker.dns.interface&#60;/name&#62;&#60;value&#62;default&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.namenode.decommission.interval&#60;/name&#62;&#60;value&#62;30&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from Unknown--&#62;&#60;name&#62;dfs.http.address&#60;/name&#62;&#60;value&#62;nagios:50070&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-site.xml--&#62;&#60;name&#62;mapred.job.tracker&#60;/name&#62;&#60;value&#62;nagios:9000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.heartbeat.interval&#60;/name&#62;&#60;value&#62;3&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;io.seqfile.sorter.recordlimit&#60;/name&#62;&#60;value&#62;1000000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.name.dir&#60;/name&#62;&#60;value&#62;${hadoop.tmp.dir}/dfs/name&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.line.input.format.linespermap&#60;/name&#62;&#60;value&#62;1&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.jobtracker.taskScheduler&#60;/name&#62;&#60;value&#62;org.apache.hadoop.mapred.JobQueueTaskScheduler&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.tasktracker.instrumentation&#60;/name&#62;&#60;value&#62;org.apache.hadoop.mapred.TaskTrackerMetricsInst&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.datanode.http.address&#60;/name&#62;&#60;value&#62;0.0.0.0:50075&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;jobclient.completion.poll.interval&#60;/name&#62;&#60;value&#62;5000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.max.maps.per.node&#60;/name&#62;&#60;value&#62;-1&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.local.dir.minspacekill&#60;/name&#62;&#60;value&#62;0&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.replication.interval&#60;/name&#62;&#60;value&#62;3&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;io.sort.record.percent&#60;/name&#62;&#60;value&#62;0.05&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;fs.kfs.impl&#60;/name&#62;&#60;value&#62;org.apache.hadoop.fs.kfs.KosmosFileSystem&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.temp.dir&#60;/name&#62;&#60;value&#62;${hadoop.tmp.dir}/mapred/temp&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-site.xml--&#62;&#60;name&#62;mapred.tasktracker.reduce.tasks.maximum&#60;/name&#62;&#60;value&#62;4&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-site.xml--&#62;&#60;name&#62;dfs.replication&#60;/name&#62;&#60;value&#62;2&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;fs.checkpoint.edits.dir&#60;/name&#62;&#60;value&#62;${fs.checkpoint.dir}&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.tasktracker.tasks.sleeptime-before-sigkill&#60;/name&#62;&#60;value&#62;5000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.job.reduce.input.buffer.percent&#60;/name&#62;&#60;value&#62;0.0&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.tasktracker.indexcache.mb&#60;/name&#62;&#60;value&#62;10&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapreduce.job.split.metainfo.maxsize&#60;/name&#62;&#60;value&#62;10000000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.skip.reduce.auto.incr.proc.count&#60;/name&#62;&#60;value&#62;true&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;hadoop.logfile.count&#60;/name&#62;&#60;value&#62;10&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;fs.automatic.close&#60;/name&#62;&#60;value&#62;true&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;io.seqfile.compress.blocksize&#60;/name&#62;&#60;value&#62;1000000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-site.xml--&#62;&#60;name&#62;dfs.hosts.exclude&#60;/name&#62;&#60;value&#62;/etc/hadoop-0.20/conf/hosts&#95;exclude&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;fs.s3.block.size&#60;/name&#62;&#60;value&#62;67108864&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.tasktracker.taskmemorymanager.monitoring-interval&#60;/name&#62;&#60;value&#62;5000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.acls.enabled&#60;/name&#62;&#60;value&#62;false&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapreduce.jobtracker.staging.root.dir&#60;/name&#62;&#60;value&#62;${hadoop.tmp.dir}/mapred/staging&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.queue.names&#60;/name&#62;&#60;value&#62;default&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.access.time.precision&#60;/name&#62;&#60;value&#62;3600000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;fs.hsftp.impl&#60;/name&#62;&#60;value&#62;org.apache.hadoop.hdfs.HsftpFileSystem&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.task.tracker.http.address&#60;/name&#62;&#60;value&#62;0.0.0.0:50060&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.reduce.parallel.copies&#60;/name&#62;&#60;value&#62;5&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;io.seqfile.lazydecompress&#60;/name&#62;&#60;value&#62;true&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.safemode.min.datanodes&#60;/name&#62;&#60;value&#62;0&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;io.sort.mb&#60;/name&#62;&#60;value&#62;100&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;ipc.client.connection.maxidletime&#60;/name&#62;&#60;value&#62;10000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.compress.map.output&#60;/name&#62;&#60;value&#62;false&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.task.tracker.report.address&#60;/name&#62;&#60;value&#62;127.0.0.1:0&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.healthChecker.interval&#60;/name&#62;&#60;value&#62;60000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;ipc.client.kill.max&#60;/name&#62;&#60;value&#62;10&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;ipc.client.connect.max.retries&#60;/name&#62;&#60;value&#62;10&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;fs.s3.impl&#60;/name&#62;&#60;value&#62;org.apache.hadoop.fs.s3.S3FileSystem&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.job.tracker.http.address&#60;/name&#62;&#60;value&#62;0.0.0.0:50030&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;io.file.buffer.size&#60;/name&#62;&#60;value&#62;4096&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.jobtracker.restart.recover&#60;/name&#62;&#60;value&#62;false&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;io.serializations&#60;/name&#62;&#60;value&#62;org.apache.hadoop.io.serializer.WritableSerialization&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.task.profile&#60;/name&#62;&#60;value&#62;false&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-site.xml--&#62;&#60;name&#62;dfs.datanode.handler.count&#60;/name&#62;&#60;value&#62;10&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;mapred.reduce.copy.backoff&#60;/name&#62;&#60;value&#62;300&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.replication.considerLoad&#60;/name&#62;&#60;value&#62;true&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-default.xml--&#62;&#60;name&#62;jobclient.output.filter&#60;/name&#62;&#60;value&#62;FAILED&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from hdfs-default.xml--&#62;&#60;name&#62;dfs.namenode.delegation.token.max-lifetime&#60;/name&#62;&#60;value&#62;604800000&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from mapred-site.xml--&#62;&#60;name&#62;mapred.tasktracker.map.tasks.maximum&#60;/name&#62;&#60;value&#62;4&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;io.compression.codecs&#60;/name&#62;&#60;value&#62;org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec&#60;/value&#62;&#60;/property&#62;
&#60;property&#62;&#60;!--Loaded from core-default.xml--&#62;&#60;name&#62;fs.checkpoint.size&#60;/name&#62;&#60;value&#62;67108864&#60;/value&#62;&#60;/property&#62;
&#60;/configuration&#62;
</pre> 
</div></div> <!--/twistyPlugin-->
<p />
Please refer to <a href="https://twiki.grid.iu.edu/bin/view/Storage/HadoopDebug" target="_top">OSG Hadoop debug webpage</a> and <a href="http://wiki.apache.org/hadoop/FAQ" target="_top">Apache Hadoop FAQ webpage</a> for answers to common questions/concerns
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="FUSE"></a> FUSE </span></h2>
<p />
<a name="TroubFuseMod"></a>
<h3><a name="Notes_on_Building_a_FUSE_Module"></a> Notes on Building a FUSE Module </h3>
<p />
If you are running a custom kernel, then be sure to enable the <code>fuse</code> module with <code>CONFIG_FUSE_FS=m</code> in your kernel config.  Building and installing a <code>fuse</code> kernel module for your custom kernel is beyond the scope of this document.
<p />
<strong>Note:</strong> If you cannot find a <code>fuse</code> kernel module to match your kernel, ATRPMs has a <a href="http://people.atrpms.net/~pcavalcanti/LCG_kernel_modules.html" target="_top">guide for using their RPM spec files</a> in order to generate a module.  That page mostly works, although sections are a bit out dated.  Contact the <a href="mailto&#58;osg&#45;hadoop&#64;opensciencegrid&#46;org">osg-hadoop&#64;opensciencegrid.org</a> list if you need help.
<p />
<p />
<p />
<a name="TroubFuseDeb"></a>
<h3><a name="Running_FUSE_in_Debug_Mode"></a> Running FUSE in Debug Mode </h3>
<p />
To start the FUSE mount in debug mode, you can run the FUSE mount command by hand:
<p />
<pre class="rootscreen">
[root@client ~]$  /usr/bin/hadoop-fuse-dfs  /mnt/hadoop -o rw,server=<font color="#ff0000">namenode.host</font>,port=9000,rdbuffer=131072,allow_other -d
</pre>
<p />
Debug output will be printed to stderr, which you will probably want to redirect to a file.  Most FUSE-related problems can be tackled by reading through the stderr and looking for error messages.
<p />
<h2 class="twikinetRoundedAttachments"><span class="twikinetHeader"><a name="GridFTP"></a> GridFTP </span></h2>
<p />
<a name="GridFTPStand"></a>
<h3><a name="Starting_GridFTP_in_Standalone_M"></a> Starting GridFTP in Standalone Mode </h3>
<p />
If you would like to test the gridftp-hdfs server in a debug standalone mode, you can run the command:
<p />
<pre class="rootscreen">
[root@client ~]$ gridftp-hdfs-standalone
</pre>
<p />
The standalone server runs on port 5002, handles a single GridFTP request, and will log output to stdout/stderr.
<p />
<h1><a name="File_Locations"></a> File Locations </h1>
<p />
<table cellspacing="0" cellpadding="0" border="0" class="twikinetWrapperTable" rules="none">
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableT twikinetWrapperTableTL"></td>
<td class="twikinetWrapperTableT twikinetWrapperTableTR"></td>
</tr>
<tr class="twikinetWrapperTableRow">
<td colspan="2" class="twikinetWrapperTableMain">
<table cellspacing="0" id="table14" cellpadding="0" class="twikiTable" rules="cols" border="1">
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> Component </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> File Type </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2"> Location </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol3 twikiLastCol"> Needs editing? </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> Hadoop </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> Log files </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2"> <code>/var/log/hadoop/*</code> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol3 twikiLastCol"> No </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> Hadoop </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> PID files </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2"> <code>/var/run/hadoop/*.pid</code> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol3 twikiLastCol"> No </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> Hadoop </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> init scripts </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2"> <code>/etc/init.d/hadoop</code> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol3 twikiLastCol"> No </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> Hadoop </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> init script config file </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2"> <code>/etc/sysconfig/hadoop</code> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol3 twikiLastCol"> Yes </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> Hadoop </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> runtime config files </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2"> <code>/etc/hadoop/conf/*</code> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol3 twikiLastCol"> Maybe </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> Hadoop </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> System binaries </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2"> <code>/usr/bin/hadoop</code> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol3 twikiLastCol"> No </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> Hadoop </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> JARs </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2"> <code>/usr/lib/hadoop/*</code> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol3 twikiLastCol"> No </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> Hadoop </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> runtime config files </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2"> <code>/etc/hosts_exclude</code> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol3 twikiLastCol"> Yes, must be present on namenodes </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> GridFTP </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> Log files </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2"> <code>/var/log/gridftp-auth.log</code>, <code>/var/log/gridftp.log</code> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol3 twikiLastCol"> No </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> GridFTP </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> init.d script </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2"> <code>/etc/init.d/globus-gridftp-server</code> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol3 twikiLastCol"> No </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> GridFTP </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> runtime config files </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2"> <code>/etc/gridftp-hdfs/*</code>, <code>/etc/sysconfig/gridftp-hdfs</code> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol3 twikiLastCol"> Maybe </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> GridFTP </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> System binaries </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2"> <code>/usr/bin/gridftp-hdfs-standalone</code>, <code>/usr/sbin/globus-gridftp-server</code> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol3 twikiLastCol"> No </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> GridFTP </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> System libraries </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2"> <code>/usr/lib64/libglobus_gridftp_server_hdfs.so*</code> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol3 twikiLastCol"> No </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> GridFTP </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> GUMS client (called by LCMAPS) configuration </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2"> <code>/etc/lcmaps.db</code> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol3 twikiLastCol"> Yes </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol twikiLast"> GridFTP </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1 twikiLast"> CA certificates </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLast"> <code>/etc/grid-security/certificates/*</code> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol3 twikiLastCol twikiLast"> No </td>
		</tr></table>
</td>
</tr>
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableB twikinetWrapperTableBL"></td>
<td class="twikinetWrapperTableB twikinetWrapperTableBR"></td>
</tr>
</table>
<p />
<p />
<table cellspacing="0" cellpadding="0" border="0" class="twikinetWrapperTable" rules="none">
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableT twikinetWrapperTableTL"></td>
<td class="twikinetWrapperTableT twikinetWrapperTableTR"></td>
</tr>
<tr class="twikinetWrapperTableRow">
<td colspan="2" class="twikinetWrapperTableMain">
<table cellspacing="0" id="table15" cellpadding="0" class="twikiTable" rules="cols" border="1">
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<th bgcolor="#d8dde4" valign="top" class="twikiTableCol0 twikiFirstCol"> <a rel="nofollow" href="/bin/view/Documentation/Release3/InstallHadoop200SE?cover=print;sortcol=0;table=15;up=0#sorted_table" title="Sort by this column"><font color="#252b37">Service/Process</font></a> </th>
			<th bgcolor="#d8dde4" valign="top" class="twikiTableCol1"> <a rel="nofollow" href="/bin/view/Documentation/Release3/InstallHadoop200SE?cover=print;sortcol=1;table=15;up=0#sorted_table" title="Sort by this column"><font color="#252b37">Configuration File</font></a> </th>
			<th bgcolor="#d8dde4" valign="top" class="twikiTableCol2 twikiLastCol"> <a rel="nofollow" href="/bin/view/Documentation/Release3/InstallHadoop200SE?cover=print;sortcol=2;table=15;up=0#sorted_table" title="Sort by this column"><font color="#252b37">Description</font></a> </th>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> BeStMan2 </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> <code>/etc/bestman2/conf/bestman2.rc</code> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> Main Configuration file </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol">  </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> <code>/etc/sysconfig/bestman2</code> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> Environment variables used by BeStMan2 </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol">  </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> <code>/etc/sysconfig/bestman2lib</code> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> Environment variables that store values of various client and server libraries used by BeStMan2 </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol">  </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> <code>/etc/bestman2/conf/*</code> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> Other runtime configuration files </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol">  </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> <code>/etc/init.d/bestman2</code> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> init.d startup script </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> GridFTP </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> <code>/etc/sysconfig/globus-gridftp-server</code> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> Environment variables to use </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol twikiLast">  </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1 twikiLast"> <code>/etc/gridftp.conf</code> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol twikiLast"> Startup parameters </td>
		</tr></table>
</td>
</tr>
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableB twikinetWrapperTableBL"></td>
<td class="twikinetWrapperTableB twikinetWrapperTableBR"></td>
</tr>
</table>
<p />
<p />
<table cellspacing="0" cellpadding="0" border="0" class="twikinetWrapperTable" rules="none">
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableT twikinetWrapperTableTL"></td>
<td class="twikinetWrapperTableT twikinetWrapperTableTR"></td>
</tr>
<tr class="twikinetWrapperTableRow">
<td colspan="2" class="twikinetWrapperTableMain">
<table cellspacing="0" id="table16" cellpadding="0" class="twikiTable" rules="cols" border="1">
		<tr class="twikiTableOdd twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<th bgcolor="#d8dde4" valign="top" class="twikiTableCol0 twikiFirstCol"> <a rel="nofollow" href="/bin/view/Documentation/Release3/InstallHadoop200SE?cover=print;sortcol=0;table=16;up=0#sorted_table" title="Sort by this column"><font color="#252b37">Service/Process</font></a> </th>
			<th bgcolor="#d8dde4" valign="top" class="twikiTableCol1"> <a rel="nofollow" href="/bin/view/Documentation/Release3/InstallHadoop200SE?cover=print;sortcol=1;table=16;up=0#sorted_table" title="Sort by this column"><font color="#252b37">Log File</font></a> </th>
			<th bgcolor="#d8dde4" valign="top" class="twikiTableCol2 twikiLastCol"> <a rel="nofollow" href="/bin/view/Documentation/Release3/InstallHadoop200SE?cover=print;sortcol=2;table=16;up=0#sorted_table" title="Sort by this column"><font color="#252b37">Description</font></a> </th>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> BeStMan2 </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> <code>/var/log/bestman2/bestman2.log</code> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> BeStMan2 server log and errors </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> &nbsp; </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> <code>/var/log/bestman2/event.srm.log</code> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> Records all SRM transactions </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol"> GridFTP </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1"> <code>/var/log/gridftp.log</code> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol"> Transfer log </td>
		</tr>
		<tr class="twikiTableOdd twikiTableRowdataBgSorted1 twikiTableRowdataBg1">
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol0 twikiFirstCol"> &nbsp; </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol1"> <code>/var/log/gridftp-auth.log</code> </td>
			<td bgcolor="#f2f3f6" valign="top" class="twikiTableCol2 twikiLastCol"> Authentication log </td>
		</tr>
		<tr class="twikiTableEven twikiTableRowdataBgSorted0 twikiTableRowdataBg0">
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol0 twikiFirstCol twikiLast"> &nbsp; </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol1 twikiLast"> <code>/var/log/messages</code> </td>
			<td bgcolor="#ffffff" valign="top" class="twikiTableCol2 twikiLastCol twikiLast"> Main system log (look here for LCMAPS errors) </td>
		</tr></table>
</td>
</tr>
<tr class="twikinetWrapperTableRow">
<td class="twikinetWrapperTableB twikinetWrapperTableBL"></td>
<td class="twikinetWrapperTableB twikinetWrapperTableBR"></td>
</tr>
</table>
<p />
<p />
<p />
<p />
<h1><a name="Known_Issues"></a> Known Issues </h1>
<p />
<h3><a name="Replicas"></a> Replicas </h3>
<p />
You may need to change the following line in <code>/usr/share/gridftp-hdfs/gridftp-hdfs-environment</code>:
<pre class="file">
export GRIDFTP_HDFS_REPLICAS=2
</pre>
<p />
<h3><a name="copy_FromLocal_java_IOException"></a> copyFromLocal java IOException </h3>
<p />
When trying to copy a local file into Hadoop you may come across the following java exception:
<p />
<pre class="screen">
<div class="twistyPlugin twikiMakeVisibleInline">  <span id="twistyIdDocumentation/Release3InstallHadoop200SE6show" class="twistyRememberSetting twistyStartHide twistyTrigger twikiUnvisited twistyInited0"><a href="#"><img src="/twiki/pub/TWiki/TWikiDocGraphics/toggleopen-small.gif" border="0" alt="" /><span class="twikiLinkLabel twikiUnvisited">Show Full Output</span></a> </span> <span id="twistyIdDocumentation/Release3InstallHadoop200SE6hide" class="twistyRememberSetting twistyStartHide twistyTrigger twikiUnvisited twistyHidden twistyInited0"><a href="#"><img src="/twiki/pub/TWiki/TWikiDocGraphics/toggleclose-small.gif" border="0" alt="" /><span class="twikiLinkLabel twikiUnvisited">Hide Full Output</span></a> </span>  </div><!--/twistyPlugin twikiMakeVisibleInline--> <div class="twistyPlugin"><div id="twistyIdDocumentation/Release3InstallHadoop200SE6toggle" class="twistyRememberSetting twistyStartHide twistyContent twikiMakeHidden twistyInited0">
11/06/24 11:10:50 WARN hdfs.DFSClient: Error Recovery for block null bad datanode[0]
nodes == null
11/06/24 11:10:50 WARN hdfs.DFSClient: Could not get block locations. Source file
"/osg/ddd" - Aborting...
copyFromLocal: java.io.IOException: File /osg/ddd could only be replicated to 0
nodes, instead of 1
11/06/24 11:10:50 ERROR hdfs.DFSClient: Exception closing file /osg/ddd :
org.apache.hadoop.ipc.RemoteException: java.io.IOException: File /osg/ddd could only
be replicated to 0 nodes, instead of 1
        at
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1415)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:588)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:528)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1319)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1315)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at
org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1063)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1313)
</div></div> <!--/twistyPlugin-->
</pre>
<p />
This can occur if you try to install a Datanode on a machine with less than 10GB of disk space available.  This can be changed by lowering the value of the following property in <code>/usr/lib/hadoop-0.20/conf/hdfs-site.xml</code>:
<p />
<pre class="file">
&#60;property&#62;
  &#60;name&#62;dfs.datanode.du.reserved&#60;/name&#62;
  &#60;value&#62;10000000000&#60;/value&#62;
&#60;/property&#62;
</pre>
<p />
Hadoop always requires this amount of disk space to be available for non-hdfs usage on the machine.
<p />
<h1><a name="How_to_get_Help"></a> How to get Help? </h1>
<p />
<p />
If you cannot resolve the problem, there are several ways to receive help:
<p /> <ul>
<li> For bug support and issues, submit a ticket to the <a href="https://ticket.grid.iu.edu/goc" target="_top">Grid Operations Center</a>.
</li> <li> For community support and best-effort software team support contact <a href="mailto&#58;osg&#45;software&#64;opensciencegrid&#46;org&#46;">osg-software&#64;opensciencegrid.org.</a>
</li> <li> For additional community support, contact <a href="mailto&#58;osg&#45;hadoop&#64;opensciencegrid&#46;org&#46;">osg-hadoop&#64;opensciencegrid.org.</a>  Note, this is only best-effort help from OSG Software team.
</li></ul> 
<p />
For a full set of help options, see <a href="/bin/view/Documentation/Release3/HelpProcedure" class="twikiLink">Help Procedure</a>.
<p />
<h1><a name="References"></a> References </h1>
<p /> <ul>
<li> <a href="https://twiki.grid.iu.edu/bin/view/Trash/ReleaseDocumentationHadoopInstallationHandsOn" target="_top">Hadoop Hands On Tutorial</a>.
</li> <li> <a href="/bin/view/Storage/HadoopUpgrade" class="twikiLink">Instructions for Upgrading from Hadoop 0.19 to Hadoop 0.20</a> <ul>
<li> <strong>*NOTE these instructions are subject to change and the upgrade doc linked is intended to upgrade from the caltech hosted 0.19 rpms in the caltech hosted 0.20 rpms, NOT the new rpms hosted in the new OSG repos.</strong>
</li></ul> 
</li></ul> 
<p />
<strong>Benchmarking</strong>
<p /> <ul>
<li> <a href="http://www.iop.org/EJ/article/1742-6596/180/1/012047/jpconf9_180_012047.pdf" target="_top">Using Hadoop as a Grid Storage Element</a>, <i>Journal of Physics Conference Series, 2009</i>.
</li> <li> <a href="http://osg-docdb.opensciencegrid.org/0009/000911/001/Hadoop.pdf" target="_top">Hadoop Distributed File System for the Grid</a>, <i>IEEE Nuclear Science Symposium, 2009</i>.
</li></ul> 
<p />
<h1><a name="Comments"></a> <strong>Comments</strong> </h1>
<form method="post" action="https://twiki.opensciencegrid.org/bin/save/Documentation/Release3/InstallHadoop200SE" enctype="multipart/form-data" name="tableappend0" id="tableappend0">
<p />
<div class="commentPlugin commentPluginPromptBox">
<table><tr valign="middle"><td><textarea  rows="3" cols="70" name="comment" wrap="soft" onfocus="if(this.value=='')this.value=''" onblur="if(this.value=='')this.value=''"></textarea></td><td><input  type="submit" value="Add comment" /></td></tr></table>
</div><!--/commentPlugin-->
<p />
<input type="hidden" name="comment_action" value="save"  />
<input type="hidden" name="comment_type" value="tableappend"  />
<input type="hidden" name="comment_index" value="0"  /></form>
<p />
<!-- CONTENT MANAGEMENT PROJECT
############################################################################################################
 DEAR DOCUMENT OWNER
 <code><b>===============</b></code>
<p />
 Thank you for claiming ownership for this document! Please fill in your <span class="twikiNewLink">FirstLast<a href="/bin/edit/Documentation/Release3/FirstLast?topicparent=Documentation/Release3.InstallHadoop200SE" rel="nofollow" title="FirstLast (this topic does not yet exist; you can create it)">?</a></span> name here: <ul>
<li> Local OWNER = <span class="twikiNewLink">DouglasStrain<a href="/bin/edit/Documentation/Release3/DouglasStrain?topicparent=Documentation/Release3.InstallHadoop200SE" rel="nofollow" title="DouglasStrain (this topic does not yet exist; you can create it)">?</a></span>
</li></ul> 
<p />
 Please define the document area, choose one of the defined areas from the next line
 DOC_AREA = (<span class="twikiNewLink">ComputeElement<a href="/bin/edit/Documentation/Release3/ComputeElement?topicparent=Documentation/Release3.InstallHadoop200SE" rel="nofollow" title="ComputeElement (this topic does not yet exist; you can create it)">?</a></span>|Storage|VO|Security|User|Monitoring|General|Trash/Trash/Integration|Operations|Tier3) <ul>
<li> Local DOC_AREA       = Storage
</li></ul> 
<p />
 define the primary role the document serves, choose one of the defined roles from the next line
 DOC_ROLE = (<span class="twikiNewLink">EndUser<a href="/bin/edit/Documentation/Release3/EndUser?topicparent=Documentation/Release3.InstallHadoop200SE" rel="nofollow" title="EndUser (this topic does not yet exist; you can create it)">?</a></span>|Student|Developer|SysAdmin|VOManager) <ul>
<li> Local DOC_ROLE       = <span class="twikiNewLink">SysAdmin<a href="/bin/edit/Documentation/Release3/SysAdmin?topicparent=Documentation/Release3.InstallHadoop200SE" rel="nofollow" title="SysAdmin (this topic does not yet exist; you can create it)">?</a></span>
</li></ul> 
<p />
 Please define the document type, choose one of the defined types from the next line
 DOC_TYPE = (Troubleshooting|Training|Installation|HowTo|Planning|Navigation|Knowledge) <ul>
<li> Local DOC_TYPE       = Installation  Please define if this document in general needs to be reviewed before release ( 1 | 0 )
</li> <li> Local INCLUDE_REVIEW = 1
</li></ul> 
<p />
 Please define if this document in general needs to be tested before release ( 1 | 0 ) <ul>
<li> Local INCLUDE_TEST   = 1
</li></ul> 
<p />
 change to 1 once the document is ready to be reviewed and back to 0 if that is not the case <ul>
<li> Local REVIEW_READY   = 1
</li></ul> 
<p />
 change to 1 once the document is ready to be tested and back to 0 if that is not the case <ul>
<li> Local TEST_READY     = 1
</li></ul> 
<p />
 change to 1 only if the document has passed the review and the test (if applicable) and is ready for release <ul>
<li> Local RELEASE_READY  = 0
</li></ul> 
<p />
<p />
 DEAR DOCUMENT REVIEWER
 <code><b>==================</b></code>
<p />
 Thank for reviewing this document! Please fill in your <span class="twikiNewLink">FirstLast<a href="/bin/edit/Documentation/Release3/FirstLast?topicparent=Documentation/Release3.InstallHadoop200SE" rel="nofollow" title="FirstLast (this topic does not yet exist; you can create it)">?</a></span> name here: <ul>
<li> Local REVIEWER       =  <span class="twikiNewLink">NehaSharma<a href="/bin/edit/Documentation/Release3/NehaSharma?topicparent=Documentation/Release3.InstallHadoop200SE" rel="nofollow" title="NehaSharma (this topic does not yet exist; you can create it)">?</a></span> Please define the review status for this document to be in progress ( 2 ), failed ( 0 ) or passed ( 1 )
</li> <li> Local REVIEW_PASSED  = 2
</li></ul> 
<p />
<p />
 DEAR DOCUMENT TESTER
 <code><b>================</b></code>
<p />
 Thank for testing this document! Please fill in your <span class="twikiNewLink">FirstLast<a href="/bin/edit/Documentation/Release3/FirstLast?topicparent=Documentation/Release3.InstallHadoop200SE" rel="nofollow" title="FirstLast (this topic does not yet exist; you can create it)">?</a></span> name here: <ul>
<li> Local TESTER         = <span class="twikiNewLink">NehaSharma<a href="/bin/edit/Documentation/Release3/NehaSharma?topicparent=Documentation/Release3.InstallHadoop200SE" rel="nofollow" title="NehaSharma (this topic does not yet exist; you can create it)">?</a></span> Please define the test status for this document to be in progress ( 2 ), failed ( 0 ) or passed ( 1 )
</li> <li> Local TEST_PASSED    = 2
</li></ul> 
############################################################################################################
--></div><!-- /patternTopic-->
<p />
<p />
</div><!-- /patternContent-->
<hr />
This topic: Documentation/Release3<span class='twikiSeparator'>&nbsp;&gt;&nbsp;</span>InstallHadoop200SE</span> <br />    
Topic revision: r26 - 07 Feb 2017 - 20:18:16 - <a href="/bin/view/Main/BrianBockelman" class="twikiLink">BrianBockelman</a>
</div><!-- /patternMainContents-->
</div><!-- /patternMain-->
</div><!-- /patternFloatWrap-->
<div class="clear">&nbsp;</div>
</div><!-- /patternOuter--><div id="patternBottomBar"><div id="patternBottomBarContents"><div id="twikinetBadge"><a href="http://www.twiki.net/"><img src="https://twiki.opensciencegrid.org/twiki/pub/TWiki/TWikiNetSkin/twiki-badge-88x31.gif" alt="TWIKI.NET" width="88" height="31" border="0" /></a></div><!--/twikinetBadge--><div id="patternWebBottomBar"><p>
<font size="-1">
TWiki |
<a href="https://ticket.grid.iu.edu/goc/twiki">Report Bugs</a> |
<a href="https://twiki.grid.iu.edu/bin/view/Operations/IUPrivacyPolicy">Privacy Policy</a>
</p>
<p>
<font size="-2">
<span class="twikiRight"> <a href="http://twiki.org/"><img src="/twiki/pub/TWiki/TWikiLogos/T-logo-80x15.gif" alt="This site is powered by the TWiki collaboration platform" width="80" height="15" title="This site is powered by the TWiki collaboration platform" border="0" /></a></span>Copyright by the contributing authors. All material on this collaboration platform is the property of the contributing authors..
</font>
</p></div><!--/patternWebBottomBar--></div><!-- /patternBottomBarContents--></div><!-- /patternBottomBar-->
</div><!-- /patternPage-->
</div><!-- /patternPageShadow-->
</div><!-- /patternScreen-->
</body></html>
<p />