%DOC_STATUS_TABLE%
---+!! Instructions for Upgrading Hadoop

%TOC{depth=&quot;2&quot;}%

---+ About This Document

%ICON{hand}% This document is intended for System Administrators that want to upgrade their Hadoop install to the new OSG hosted rpms.

%INCLUDE{&quot;Trash/DocumentationTeam/DocConventions&quot; section=&quot;Header&quot;}%
%INCLUDE{&quot;Trash/DocumentationTeam/DocConventions&quot; section=&quot;CommandLine&quot;}%

---+ Applicable Versions

This document is intended for those upgrading from  %RED%Hadoop Version 0.20%ENDCOLOR% hosted by Caltech to  %RED%Hadoop Version 0.20%ENDCOLOR% hosted by the new OSG repositories.  It does *NOT* cover upgrading from  %RED%Hadoop Version 0.19%ENDCOLOR% to %RED%Hadoop Version 0.20%ENDCOLOR%.

---+ Upgrade Procedure

%NOTE% Throughout this document it will be stated which node the relevant instructions apply to.  It can apply to one of the following:
   * *Namenode*
   * *Datanode*
   * *Secondary Namenode*
   * *GridFTP node*
   *  *SRM node*

---++ Initializing the YUM Repository

%NOTE% This must be done on *all nodes*

%INCLUDE{&quot;Documentation.InstallVDTRepo&quot;}%

%NOTE% To reduce later confusion and conflicts, you may want to disable the Caltech repository.
To do this, either remove the previous osg-hadoop rpm or go into /etc/yum.repos.d and disable all entries in osg-hadoop.repo
by changing &quot;enabled=1&quot; to &quot;enabled=0&quot;.

---++ Stop Running Services

---+++ Stopping !BeStMan2

On your *SRM Node* run:

&lt;pre class=&quot;rootscreen&quot;&gt;
%UCL_PROMPT_ROOT% service bestman2 stop
&lt;/pre&gt;

---+++ Stopping Hadoop

On your *Namenode*, *Secondary Namenode*, and *Datanodes* run:

&lt;pre class=&quot;rootscreen&quot;&gt;
%UCL_PROMPT_ROOT% service hadoop stop
&lt;/pre&gt;

---++ Special  !GridFTP Pre-Upgrade Instructions

Upgrading your *GridFTP Node* first requires an extra manual step due to version collisions of the =lcas= and =lcas-lcmaps-gt4-interface= rpms between repos.  To avoid depsolving issues first remove these packages before proceeding with the rest of the upgrade instructions:

&lt;pre class=&quot;rootscreen&quot;&gt;
%UCL_PROMPT_ROOT% yum remove lcas lcas-lcmaps-gt4-interface
&lt;/pre&gt;

Choose &quot;y&quot; when asked to remove packages that depend on these.  Also make note of any warning messages regarding backups of config files, e.g.:

&lt;pre class=&quot;file&quot;&gt;
warning: /etc/lcmaps/lcmaps.db saved as /etc/lcmaps/lcmaps.db.rpmsave
&lt;/pre&gt;

---++ Perform Yum Update

On *all nodes* run:

&lt;pre class=&quot;rootscreen&quot;&gt;
%UCL_PROMPT_ROOT% yum update
&lt;/pre&gt;

Be sure to make note of any warning messages regarding backups of config files saved to =*.rpmsave= and =*.rpmnew= locations.

---++ Special Hadoop Post-Upgrade Instructions

The caltech version of =hadoop-0.20-osg= rpm mistakenly takes ownership of the directory symlink =/var/log/hadoop=.  Running the update will cause the symlink to break.  Before starting =hadoop= services back up be sure to repair it manually on *all nodes*:

&lt;pre class=&quot;rootscreen&quot;&gt;
%UCL_PROMPT_ROOT% ln -sf /etc/alternatives/hadoop-log /var/log/hadoop
&lt;/pre&gt;

The osg versions of =hadoop-0.20= and =hadoop-0.20-osg= rpms no longer run as user =hadoop= but instead run as user =hdfs=.  If your installation uses the old =hadoop= user you will have to chown $HADOOP_DATADIR to user =hdfs= on your *Datanodes*:

&lt;pre class=&quot;rootscreen&quot;&gt;
%UCL_PROMPT_ROOT% chown -R hdfs:hadoop %RED%$HADOOP_DATADIR%ENDCOLOR%
&lt;/pre&gt;

where $HADOOP_DATADIR is defined in =/etc/sysconfig/hadoop=.
 
---++ Install !GridFTP

You must manually install the new version of !GridFTP since it was removed in the previous steps above.

&lt;pre class=&quot;rootscreen&quot;&gt;
%UCL_PROMPT_ROOT% yum install osg-gridftp-hdfs
&lt;/pre&gt;

---+ Configuration Procedure

---++ Update Config Files as Needed

Review any =*.rpmsave= and =*.rpmnew=  files reported in the =yum update= and edit as needed.  A few of these locations have been changed for the new rpms.  The most relevant changes are listed here:

| Service | Old Location | New Location |
| !GridFTP | /etc/lcmaps/lcmaps.db | /etc/lcmaps.db |
| Gratia Transfer Probe | /opt/vdt/gratia/probe/gridftp-transfer/ProbeConfig | /etc/gratia/gridftp-transfer/ProbeConfig |
| Hadoop Storage Probe | /opt/vdt/gratia/probe/hadoop-storage/ProbeConfig | /etc/gratia/hadoop-storage/ProbeConfig |
| Hadoop Storage Probe | /opt/vdt/gratia/probe/hadoop-storage/storage.cfg | /etc/gratia/hadoop-storage/storage.cfg |

---++ Notable Changes for Hadoop

As stated above the new default hadoop user is =hdfs=.  Ensure this is set in =/etc/sysconfig/hadoop=:

&lt;pre class=&quot;file&quot;&gt;
HADOOP_USER=hdfs
&lt;/pre&gt;

 and reconfigure if needed:
&lt;pre class=&quot;rootscreen&quot;&gt;
%UCL_PROMPT_ROOT% service hadoop-firstboot start
&lt;/pre&gt;

---++ Notable Changes for !GridFTP

Note the change in location of the =lcmaps.db= file listed above; review and edit as needed.  Once you update the new file you need to perform this additional step:

Edit =/etc/grid-security/gsi-authz.conf= and uncomment the globus callout:

&lt;pre class=&quot;file&quot;&gt;
globus_mapping /usr/lib64/liblcas_lcmaps_gt4_mapping.so lcmaps_callout
&lt;/pre&gt;

---++ Notable Changes for Gratia Transfer Probe

Note the change in location of the =ProbeConfig= file listed above; review and edit as needed.  In addition, the Transfer Probe no longer uses =osg-user-vo-map-cron= to generate the =user-vo-map= file.  Instead =gums-host-cron= is used.  To ensure the file gets generated, run it first by hand:

&lt;pre class=&quot;rootscreen&quot;&gt;
%UCL_PROMPT_ROOT%  gums-host-cron
&lt;/pre&gt;

=user-vo-map= should be created in the following location:

=/var/lib/osg/user-vo-map=

Ensure =ProbeConfig= is updated to point to the new location of this file in the =UserVOMapFile= field.

To have cron regularly update this file start the following service:

&lt;pre class=&quot;rootscreen&quot;&gt;
%UCL_PROMPT_ROOT%  service gums-client-cron start
&lt;/pre&gt;

---++ Notable Changes for Hadoop Storage Probe

Note the config file location changes listed above; review and edit as needed.  Please ensure the following lines are correct in =storage.cfg=:

&lt;pre class=&quot;file&quot;&gt;
gratia_location = /etc/gratia
ProbeConfig = %(gratia_location)s/hadoop-storage/ProbeConfig
&lt;/pre&gt;

---+ Service Activation

Assuming you finished updating the config files needed you can start up the services.

---++ Starting Hadoop

On your *Namenode*, *Secondary Namenode*, and *Datanodes* run:

&lt;pre class=&quot;rootscreen&quot;&gt;
%UCL_PROMPT_ROOT% service hadoop start
&lt;/pre&gt;

---++ Starting !GridFTP

!GridFTP is no longer controlled by xinetd but is now controlled by a startup daemon.  To start it, on your *GridFTP Node* run:

&lt;pre class=&quot;rootscreen&quot;&gt;
%UCL_PROMPT_ROOT% service globus-gridftp-server start
&lt;/pre&gt;

---++ Starting !BeStMan2

On your *SRM Node* run:

&lt;pre class=&quot;rootscreen&quot;&gt;
%UCL_PROMPT_ROOT% service bestman2 start
&lt;/pre&gt;

---+ Comments
%COMMENT{type=&quot;tableappend&quot;}%

&lt;!-- CONTENT MANAGEMENT PROJECT
############################################################################################################
 DEAR DOCUMENT OWNER
 ===================

 Thank you for claiming ownership for this document! Please fill in your FirstLast name here:
   * Local OWNER = DouglasStrain

 Please define the document area, choose one of the defined areas from the next line
 DOC_AREA = (ComputeElement|General|Trash/Trash/Integration|Monitoring|Operations|Security|Storage|Trash/Tier3|User|VO)
   * Local DOC_AREA       = Storage

 define the primary role the document serves, choose one of the defined roles from the next line
 DOC_ROLE = (Developer|Documenter|Scientist|Student|SysAdmin|VOManager)
   * Local DOC_ROLE       = SysAdmin

 Please define the document type, choose one of the defined types from the next line
 DOC_TYPE = (HowTo|Installation|Knowledge|Navigation|Planning|Training|Troubleshooting)
   * Local DOC_TYPE       = Installation
  Please define if this document in general needs to be reviewed before release ( %YES% | %NO% )
   * Local INCLUDE_REVIEW = %YES%

 Please define if this document in general needs to be tested before release ( %YES% | %NO% )
   * Local INCLUDE_TEST   = %YES%

 change to %YES% once the document is ready to be reviewed and back to %NO% if that is not the case
   * Local REVIEW_READY   = %YES%

 change to %YES% once the document is ready to be tested and back to %NO% if that is not the case
   * Local TEST_READY     = %YES%

 change to %YES% only if the document has passed the review and the test (if applicable) and is ready for release
   * Local RELEASE_READY  = %YES%


 DEAR DOCUMENT REVIEWER
 ======================

 Thank for reviewing this document! Please fill in your FirstLast name here:
   * Local REVIEWER       = NehaSharma
 Please define the review status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local REVIEW_PASSED  = %YES%


 DEAR DOCUMENT TESTER
 ====================

 Thank for testing this document! Please fill in your FirstLast name here:
   * Local TESTER         = NehaSharma
 Please define the test status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local TEST_PASSED    = %YES%
############################################################################################################
--&gt;
-- Main.JamesWeichel - 03 Feb 2010

