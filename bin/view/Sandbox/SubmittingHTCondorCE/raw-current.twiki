---+ Submitting Jobs to an HTCondor CE

%TOC{depth=&quot;3&quot;}%

---++ About This Guide

This document outlines methods of manual submission to an HTCondor CE. It is intended for site administrators wishing to verify the functionality of their HTCondor CE installation and developers writing software to submit jobs to an HTCondor CE (e.g., pilot jobs). 

%NOTE% Most incoming jobs are pilots from factories and that manual submission does not reflect the standard method that jobs are submitted to OSG CE&amp;rsquo;s. 

---++ Submitting Jobs...

There are two main methods for submitting files to an HTCondor CE: using the tools bundled with the =htcondor-ce-client= package and using the =condor_submit= command with a submit file. Both methods will test end-to-end job submission but the former method is simpler while the latter will walk you through writing your own submit file. 

Before attempting to submit jobs, you will need to generate a proxy from a user certificate before running any jobs. To generate a proxy, run the following command on the host you plan on submitting from:

&lt;pre class=&quot;screen&quot;&gt;%UCL_PROMPT% voms-proxy-init&lt;/pre&gt;

---+++ Using HTCondor CE tools

There are two HTCondor CE tools that allow users to test the functionality of their HTCondor CE: [[Documentation.Release3/TroubleshootingHTCondorCE#condor_ce_trace][condor_ce_trace]] and [[Documentation.Release3/TroubleshootingHTCondorCE#condor_ce_run][condor_ce_run]]. The former is the preferred tool as it provides useful feedback if failure occurs while the latter is simply an automated submission tool. These commands may be run from any host that has =htcondor-ce-client= installed, which you may wish to do if you are testing availability of your CE from an external source.

---++++ condor_ce_trace

=condor_ce_trace= is a Python script that uses HTCondor&#39;s Python bindings to run diagnostics, including job submission, against your HTCondor CE. To submit a job with =condor_ce_trace=, run the following command:

&lt;pre class=&quot;screen&quot;&gt;%UCL_PROMPT% condor_ce_trace --debug &lt;span style=&quot;background-color: #D1CAF2;&quot;&gt;condorce.example.com&lt;/span&gt;&lt;/pre&gt;

Replacing the &lt;span style=&quot;background-color: #D1CAF2;&quot;&gt;highlighted&lt;/span&gt; text with the hostname of the CE. On success, you will see =Job status: Completed= and the environment of the job on the worker node it landed on. If you do not get the expected output, refer to the [[https://twiki.opensciencegrid.org/bin/view/Documentation/Release3/TroubleshootingHTCondorCE#condor_ce_trace][troubleshooting guide]].

---++++ condor_ce_run

=condor_ce_run= is a Python script that calls =condor_submit= on a generated submit file and tracks its progress with =condor_q=. To submit a job with =condor_ce_run=, run the following command:

&lt;pre class=&quot;screen&quot;&gt;%UCL_PROMPT% condor_ce_run -r &lt;span style=&quot;background-color: #D1CAF2;&quot;&gt;condorce.example.com&lt;/span&gt;:9619 /bin/env&lt;/pre&gt;

Replacing the &lt;span style=&quot;background-color: #D1CAF2;&quot;&gt;highlighted&lt;/span&gt; text with the hostname of the CE. The command will not return any output until it completes: When it does you will see the environment of the job on the worker noded it landed on. If you do not get the expected output, refer to the [[https://twiki.opensciencegrid.org/bin/view/Documentation/Release3/TroubleshootingHTCondorCE#condor_ce_run][troubleshooting guide]].

---+++ Using a submit file...

If you are familiar with HTCondor, submitting a job to an HTCondor CE using a submit file follows the same procedure as submitting a job to an HTCondor batch system: Write a submit file and use =condor_submit= (or in one of our cases, =condor_ce_submit=) to submit the job. This is by virtue of the fact that HTCondor CE is just a special configuration of HTCondor. The major differences occur in the specific attributes for the submit files outlined below.

---++++ From the CE host

This method uses =condor_ce_submit= to submit directly to an HTCondor CE. The only reason we use =condor_ce_submit= in this case is to take advantage of the already running daemons on the CE host.

   1. Write a submit file, =ce_test.sub=: \
   &lt;pre class=&quot;file&quot;&gt;
# Required for local HTCondor CE submission
universe = vanilla
use_x509userproxy = true
+Owner = undefined

# Files
executable = &lt;span style=&quot;background-color: #FFCCFF;&quot;&gt;ce_test.sh&lt;/span&gt;
output = ce_test.out
error = ce_test.err
log = ce_test.log

# File transfer behavior
ShouldTransferFiles = YES
WhenToTransferOutput = ON_EXIT

# Run job once
queue&lt;/pre&gt; \
   &lt;p&gt;Replacing the &lt;span style=&quot;background-color: #FFCCFF;&quot;&gt;highlighted&lt;/span&gt; text with the path to the executable you wish to run.&lt;/p&gt;
      i. You can use any executable you choose for the =executable= field. If you don&#39;t have one in mind, you may use the following example test script:\
      &lt;pre class=&quot;file&quot;&gt;
#!/bin/bash

date
hostname
env &lt;/pre&gt;
      i. Mark the test script as executable: \
   &lt;pre class=&quot;screen&quot;&gt;%UCL_PROMPT% chmod +x ce_test.sh&lt;/pre&gt;
   1. Submit the job: \
   &lt;pre class=&quot;screen&quot;&gt;%UCL_PROMPT% condor_ce_submit ce_test.sub&lt;/pre&gt;

---++++ From another host

For this method, you will need a functional HTCondor submit node. If you do not have one readily available, you can install the =condor= package from the OSG repository to get a simple submit node:

   1. Follow [[Documentation.Release3/InstallCondor#5_Installation_Procedure][these instructions]] to install HTCondor
   1. Start the =condor= service: \
   &lt;pre class=&quot;rootscreen&quot;&gt;%UCL_PROMPT_ROOT% service condor start&lt;/pre&gt;

   1. Write a submit file, =ce_test.sub=: \
   &lt;pre class=&quot;file&quot;&gt;
# Required for remote HTCondor CE submission
universe = grid 
use_x509userproxy = true
grid_resource = condor %RED condorce.example.com condorce.example.com%ENDCOLOR%:9619

# Files
executable = &lt;span style=&quot;background-color: #FFCCFF;&quot;&gt;ce_test.sh&lt;/span&gt;
output = ce_test.out
error = ce_test.err
log = ce_test.log

# File transfer behavior
ShouldTransferFiles = YES
WhenToTransferOutput = ON_EXIT

# Run job once
queue&lt;/pre&gt; \
   &lt;p&gt;Replacing the &lt;span style=&quot;background-color: #FFCCFF;&quot;&gt;highlighted&lt;/span&gt; text with the path to the executable you wish to run and the %RED%red%ENDCOLOR% text with the hostname of the CE you wish to test.&lt;/p&gt;
      i. You can use any executable you choose for the =executable= field. If you don&#39;t have one in mind, you may use the following example test script:\
      &lt;pre class=&quot;file&quot;&gt;
#!/bin/bash

date
hostname
env &lt;/pre&gt;
      i. Mark the test script as executable: \
   &lt;pre class=&quot;screen&quot;&gt;%UCL_PROMPT% chmod +x ce_test.sh&lt;/pre&gt;
   1. Submit the job: \
   &lt;pre class=&quot;screen&quot;&gt;%UCL_PROMPT% condor_submit ce_test.sub&lt;/pre&gt;

---++++ Tracking job progress

When the job completes, stdout will be placed into =ce_test.out=, stderr will be placed into =ce_test.err=, and HTCondor logging information will be placed in =ce_test.log=. You can track job progress by looking at the condor queue by running the following command on the CE host:

&lt;pre class=&quot;screen&quot;&gt;%UCL_PROMPT% condor_ce_q&lt;/pre&gt;

Using the following table to determine job status:

| *This value in the =ST= column...* | *Means that the job is...* |
| I | idle |
| C | complete |
| X | being removed |
| H | held |
| &lt; | transferring input |
| &gt; | transferring output |

---+++ With custom attributes

Custom attributes can be added to jobs that can then be parsed by the receiving HTCondor CE. These custom attributes are prefixed by =+= and are added to the !JobAd. For example, the following adds the =foo= attribute to your !JobAd and sets it equal to the string =bar=:

&lt;pre class=&quot;file&quot;&gt;+foo=&quot;bar&quot;&lt;/pre&gt;

You can add these to your submit file before the =queue= statement and in =condor_ce_trace= with the =--attribute= option:

&lt;pre class=&quot;screen&quot;&gt;%UCL_PROMPT% condor_ce_trace --attribute=&#39;+foo=&quot;bar&quot;&#39;...&lt;/pre&gt;

Currently, =condor_ce_run= does not support adding extra attributes.

#JobRoutes
---++ How Job Routes Affect Your Job

Upon successful submission of your job, the Job Router takes control of your job by matching it to routes and submitting a transformed job to your batch system. 

---+++ Matching

First, the Job Router checks if your job [[Documentation.Release3/JobRouterRecipes#Filtering_jobs_based_on][matches any routes]]. It does this by checking the routes =Requirements= expression against the job and selecting the first match it comes across in a round robin fashion. If your job does not match any routes, the job will be put on hold and eventually removed from the CE queue without completing.

%NOTE% The !JobRouter matches jobs to routes in a round-robin fashion. This means that if a job can match to multiple routes, it can be routed by any of them! So when writing job routes, make sure that they are exclusive to each other and that your jobs can only match to a single route. 

*Examples*

The following three routes only perform filtering and submission of routed jobs to an HTCondor batch system. The only differences are in the types of jobs that they match:

   * *Route 1:* Matches jobs whose attribute =foo= is equal to =bar=.
   * *Route 2:* Matches jobs whose attribute =foo= is equal to =baz=.
   * *Route 3:* Matches jobs whose attribute =foo= is neither equal to =bar= nor =baz=.

%NOTE% Setting a custom attribute for submission requires the =+= prefix but it is unnecessary in the job routes.

&lt;pre class=&quot;file&quot;&gt;
JOB_ROUTER_ENTRIES = [ \
     TargetUniverse = 5; \
     name = &quot;Route 1&quot;; \
     Requirements = (TARGET.foo =?= &quot;bar&quot;); \
] \
[ \
     TargetUniverse = 5; \
     name = &quot;Route 2&quot;; \
     Requirements = (TARGET.foo =?= &quot;baz&quot;); \
] \
[ \
     TargetUniverse = 5; \
     name = &quot;Route 3&quot;; \
     Requirements = (TARGET.foo =!= &quot;bar&quot;) &amp;&amp; (TARGET.foo =!= &quot;baz&quot;); \
] \
&lt;/pre&gt;

If a user could submitted their job with =+foo=bar=, the job would match =Route 1=.

---+++ Route defaults

[[Documentation.Release3/JobRouterRecipes#Setting_a_default][Route defaults]] can be set for batch system queue, maximum memory, number of cores to request, and maximum walltime. The submitting user can override any of these by setting the corresponding [[#JobAttributes][attribute]] in their job.

*Examples*

The following route takes all incoming jobs and submits them to an HTCondor batch system requesting 1GB of memory.

&lt;pre class=&quot;file&quot;&gt;
JOB_ROUTER_ENTRIES = [ \
     TargetUniverse = 5; \
     name = &quot;Route 1&quot;; \
     set_default_maxMemory = 1000; \
] 
&lt;/pre&gt;

A user could submit their job with the attribute =+maxMemory=2000= and that job would be submitted requesting 2GB memory instead of the default of 1GB.

---++ Reference

Here are some other HTCondor&amp;nbsp;CE documents that might be helpful:

   * HTCondor&amp;nbsp;CE overview and architecture (coming soon)
   * [[InstallHTCondorCE][Installing HTCondor CE]]
   * [[JobRouterRecipes][Configuring HTCondor&amp;nbsp;CE job routes]]
   * [[TroubleshootingHTCondorCE][The HTCondor&amp;nbsp;CE troubleshooting guide]]

#JobAttributes
---+++ Job attributes

The following table is a reference of job attributes that can be included in HTCondor submit files and their !GlobusRSL equivalents. A more comprehensive list of submit file attributes specific to HTCondor CE can be found in the [[http://research.cs.wisc.edu/htcondor/manual/v8.2/condor_submit.html#SECTION0012554000000000000000][HTCondor manual]].

| *HTCondor Attribute* | *Globus RSL* | *Summary* | 
| [[http://research.cs.wisc.edu/htcondor/manual/v8.2/condor_submit.html#82586][arguments]] | arguments | Arguments that will be provided to the executable for the job. |
| [[http://research.cs.wisc.edu/htcondor/manual/v8.2/condor_submit.html#82635][error]] | stderr | Path to the file on the client machine that stores stderr from the job. |
| [[http://research.cs.wisc.edu/htcondor/manual/v8.2/condor_submit.html#82641][executable]] | executable | Path to the file on the client machine that the job will execute. |
| [[http://research.cs.wisc.edu/htcondor/manual/v8.2/condor_submit.html#man-condor-submit-environment][environment]] | environment | Environment variables to add to the job&#39;s environment. |
| [[http://research.cs.wisc.edu/htcondor/manual/v8.2/condor_submit.html#82660][input]] | stdin | Path to the file on the client machine that stores input to be piped into the stdin of the job. |
| +maxMemory | maxMemory | The amount of memory you wish to allocate to the job. |
| +maxWallTime | maxWallTime | The maximum walltime the job is allowed to run before it is removed. |
| [[http://research.cs.wisc.edu/htcondor/manual/v8.2/condor_submit.html#82696][output]] | stdout| Path to the file on the client machine that stores stdout from the job. |
| +remote_queue | queue | Assign job to the target queue in the scheduler. |
| [[http://research.cs.wisc.edu/htcondor/manual/v8.2/condor_submit.html#82911][transfer_input_files]] | file_stage_in | A comma-delimited list of all the files and directories to be transferred into the working directory for the job, before the job is started. |
| [[http://research.cs.wisc.edu/htcondor/manual/v8.2/condor_submit.html#82919][transfer_output_files]] | transfer_output_files | A comma-delimited list of all the files and directories to be transferred back to the client, after the job completes. |
| +xcount | xcount | The number of cores to allocate for the job. |

-- Main.BrianLin - 08 Jan 2015
